\documentclass[11pt]{article}

    \usepackage[breakable]{tcolorbox}
    \usepackage{parskip} % Stop auto-indenting (to mimic markdown behaviour)
    
    \usepackage{iftex}
    \ifPDFTeX
    	\usepackage[T1]{fontenc}
    	\usepackage{mathpazo}
    \else
    	\usepackage{fontspec}
    \fi

    % Basic figure setup, for now with no caption control since it's done
    % automatically by Pandoc (which extracts ![](path) syntax from Markdown).
    \usepackage{graphicx}
    % Maintain compatibility with old templates. Remove in nbconvert 6.0
    \let\Oldincludegraphics\includegraphics
    % Ensure that by default, figures have no caption (until we provide a
    % proper Figure object with a Caption API and a way to capture that
    % in the conversion process - todo).
    \usepackage{caption}
    \DeclareCaptionFormat{nocaption}{}
    \captionsetup{format=nocaption,aboveskip=0pt,belowskip=0pt}

    \usepackage{float}
    \floatplacement{figure}{H} % forces figures to be placed at the correct location
    \usepackage{xcolor} % Allow colors to be defined
    \usepackage{enumerate} % Needed for markdown enumerations to work
    \usepackage{geometry} % Used to adjust the document margins
    \usepackage{amsmath} % Equations
    \usepackage{amssymb} % Equations
    \usepackage{textcomp} % defines textquotesingle
    % Hack from http://tex.stackexchange.com/a/47451/13684:
    \AtBeginDocument{%
        \def\PYZsq{\textquotesingle}% Upright quotes in Pygmentized code
    }
    \usepackage{upquote} % Upright quotes for verbatim code
    \usepackage{eurosym} % defines \euro
    \usepackage[mathletters]{ucs} % Extended unicode (utf-8) support
    \usepackage{fancyvrb} % verbatim replacement that allows latex
    \usepackage{grffile} % extends the file name processing of package graphics 
                         % to support a larger range
    \makeatletter % fix for old versions of grffile with XeLaTeX
    \@ifpackagelater{grffile}{2019/11/01}
    {
      % Do nothing on new versions
    }
    {
      \def\Gread@@xetex#1{%
        \IfFileExists{"\Gin@base".bb}%
        {\Gread@eps{\Gin@base.bb}}%
        {\Gread@@xetex@aux#1}%
      }
    }
    \makeatother
    \usepackage[Export]{adjustbox} % Used to constrain images to a maximum size
    \adjustboxset{max size={0.9\linewidth}{0.9\paperheight}}

    % The hyperref package gives us a pdf with properly built
    % internal navigation ('pdf bookmarks' for the table of contents,
    % internal cross-reference links, web links for URLs, etc.)
    \usepackage{hyperref}
    % The default LaTeX title has an obnoxious amount of whitespace. By default,
    % titling removes some of it. It also provides customization options.
    \usepackage{titling}
    \usepackage{longtable} % longtable support required by pandoc >1.10
    \usepackage{booktabs}  % table support for pandoc > 1.12.2
    \usepackage[inline]{enumitem} % IRkernel/repr support (it uses the enumerate* environment)
    \usepackage[normalem]{ulem} % ulem is needed to support strikethroughs (\sout)
                                % normalem makes italics be italics, not underlines
    \usepackage{mathrsfs}
    

    
    % Colors for the hyperref package
    \definecolor{urlcolor}{rgb}{0,.145,.698}
    \definecolor{linkcolor}{rgb}{.71,0.21,0.01}
    \definecolor{citecolor}{rgb}{.12,.54,.11}

    % ANSI colors
    \definecolor{ansi-black}{HTML}{3E424D}
    \definecolor{ansi-black-intense}{HTML}{282C36}
    \definecolor{ansi-red}{HTML}{E75C58}
    \definecolor{ansi-red-intense}{HTML}{B22B31}
    \definecolor{ansi-green}{HTML}{00A250}
    \definecolor{ansi-green-intense}{HTML}{007427}
    \definecolor{ansi-yellow}{HTML}{DDB62B}
    \definecolor{ansi-yellow-intense}{HTML}{B27D12}
    \definecolor{ansi-blue}{HTML}{208FFB}
    \definecolor{ansi-blue-intense}{HTML}{0065CA}
    \definecolor{ansi-magenta}{HTML}{D160C4}
    \definecolor{ansi-magenta-intense}{HTML}{A03196}
    \definecolor{ansi-cyan}{HTML}{60C6C8}
    \definecolor{ansi-cyan-intense}{HTML}{258F8F}
    \definecolor{ansi-white}{HTML}{C5C1B4}
    \definecolor{ansi-white-intense}{HTML}{A1A6B2}
    \definecolor{ansi-default-inverse-fg}{HTML}{FFFFFF}
    \definecolor{ansi-default-inverse-bg}{HTML}{000000}

    % common color for the border for error outputs.
    \definecolor{outerrorbackground}{HTML}{FFDFDF}

    % commands and environments needed by pandoc snippets
    % extracted from the output of `pandoc -s`
    \providecommand{\tightlist}{%
      \setlength{\itemsep}{0pt}\setlength{\parskip}{0pt}}
    \DefineVerbatimEnvironment{Highlighting}{Verbatim}{commandchars=\\\{\}}
    % Add ',fontsize=\small' for more characters per line
    \newenvironment{Shaded}{}{}
    \newcommand{\KeywordTok}[1]{\textcolor[rgb]{0.00,0.44,0.13}{\textbf{{#1}}}}
    \newcommand{\DataTypeTok}[1]{\textcolor[rgb]{0.56,0.13,0.00}{{#1}}}
    \newcommand{\DecValTok}[1]{\textcolor[rgb]{0.25,0.63,0.44}{{#1}}}
    \newcommand{\BaseNTok}[1]{\textcolor[rgb]{0.25,0.63,0.44}{{#1}}}
    \newcommand{\FloatTok}[1]{\textcolor[rgb]{0.25,0.63,0.44}{{#1}}}
    \newcommand{\CharTok}[1]{\textcolor[rgb]{0.25,0.44,0.63}{{#1}}}
    \newcommand{\StringTok}[1]{\textcolor[rgb]{0.25,0.44,0.63}{{#1}}}
    \newcommand{\CommentTok}[1]{\textcolor[rgb]{0.38,0.63,0.69}{\textit{{#1}}}}
    \newcommand{\OtherTok}[1]{\textcolor[rgb]{0.00,0.44,0.13}{{#1}}}
    \newcommand{\AlertTok}[1]{\textcolor[rgb]{1.00,0.00,0.00}{\textbf{{#1}}}}
    \newcommand{\FunctionTok}[1]{\textcolor[rgb]{0.02,0.16,0.49}{{#1}}}
    \newcommand{\RegionMarkerTok}[1]{{#1}}
    \newcommand{\ErrorTok}[1]{\textcolor[rgb]{1.00,0.00,0.00}{\textbf{{#1}}}}
    \newcommand{\NormalTok}[1]{{#1}}
    
    % Additional commands for more recent versions of Pandoc
    \newcommand{\ConstantTok}[1]{\textcolor[rgb]{0.53,0.00,0.00}{{#1}}}
    \newcommand{\SpecialCharTok}[1]{\textcolor[rgb]{0.25,0.44,0.63}{{#1}}}
    \newcommand{\VerbatimStringTok}[1]{\textcolor[rgb]{0.25,0.44,0.63}{{#1}}}
    \newcommand{\SpecialStringTok}[1]{\textcolor[rgb]{0.73,0.40,0.53}{{#1}}}
    \newcommand{\ImportTok}[1]{{#1}}
    \newcommand{\DocumentationTok}[1]{\textcolor[rgb]{0.73,0.13,0.13}{\textit{{#1}}}}
    \newcommand{\AnnotationTok}[1]{\textcolor[rgb]{0.38,0.63,0.69}{\textbf{\textit{{#1}}}}}
    \newcommand{\CommentVarTok}[1]{\textcolor[rgb]{0.38,0.63,0.69}{\textbf{\textit{{#1}}}}}
    \newcommand{\VariableTok}[1]{\textcolor[rgb]{0.10,0.09,0.49}{{#1}}}
    \newcommand{\ControlFlowTok}[1]{\textcolor[rgb]{0.00,0.44,0.13}{\textbf{{#1}}}}
    \newcommand{\OperatorTok}[1]{\textcolor[rgb]{0.40,0.40,0.40}{{#1}}}
    \newcommand{\BuiltInTok}[1]{{#1}}
    \newcommand{\ExtensionTok}[1]{{#1}}
    \newcommand{\PreprocessorTok}[1]{\textcolor[rgb]{0.74,0.48,0.00}{{#1}}}
    \newcommand{\AttributeTok}[1]{\textcolor[rgb]{0.49,0.56,0.16}{{#1}}}
    \newcommand{\InformationTok}[1]{\textcolor[rgb]{0.38,0.63,0.69}{\textbf{\textit{{#1}}}}}
    \newcommand{\WarningTok}[1]{\textcolor[rgb]{0.38,0.63,0.69}{\textbf{\textit{{#1}}}}}
    
    
    % Define a nice break command that doesn't care if a line doesn't already
    % exist.
    \def\br{\hspace*{\fill} \\* }
    % Math Jax compatibility definitions
    \def\gt{>}
    \def\lt{<}
    \let\Oldtex\TeX
    \let\Oldlatex\LaTeX
    \renewcommand{\TeX}{\textrm{\Oldtex}}
    \renewcommand{\LaTeX}{\textrm{\Oldlatex}}
    % Document parameters
    % Document title
    \title{Zillow-Thesis}
    
    
    
    
    
% Pygments definitions
\makeatletter
\def\PY@reset{\let\PY@it=\relax \let\PY@bf=\relax%
    \let\PY@ul=\relax \let\PY@tc=\relax%
    \let\PY@bc=\relax \let\PY@ff=\relax}
\def\PY@tok#1{\csname PY@tok@#1\endcsname}
\def\PY@toks#1+{\ifx\relax#1\empty\else%
    \PY@tok{#1}\expandafter\PY@toks\fi}
\def\PY@do#1{\PY@bc{\PY@tc{\PY@ul{%
    \PY@it{\PY@bf{\PY@ff{#1}}}}}}}
\def\PY#1#2{\PY@reset\PY@toks#1+\relax+\PY@do{#2}}

\@namedef{PY@tok@w}{\def\PY@tc##1{\textcolor[rgb]{0.73,0.73,0.73}{##1}}}
\@namedef{PY@tok@c}{\let\PY@it=\textit\def\PY@tc##1{\textcolor[rgb]{0.24,0.48,0.48}{##1}}}
\@namedef{PY@tok@cp}{\def\PY@tc##1{\textcolor[rgb]{0.61,0.40,0.00}{##1}}}
\@namedef{PY@tok@k}{\let\PY@bf=\textbf\def\PY@tc##1{\textcolor[rgb]{0.00,0.50,0.00}{##1}}}
\@namedef{PY@tok@kp}{\def\PY@tc##1{\textcolor[rgb]{0.00,0.50,0.00}{##1}}}
\@namedef{PY@tok@kt}{\def\PY@tc##1{\textcolor[rgb]{0.69,0.00,0.25}{##1}}}
\@namedef{PY@tok@o}{\def\PY@tc##1{\textcolor[rgb]{0.40,0.40,0.40}{##1}}}
\@namedef{PY@tok@ow}{\let\PY@bf=\textbf\def\PY@tc##1{\textcolor[rgb]{0.67,0.13,1.00}{##1}}}
\@namedef{PY@tok@nb}{\def\PY@tc##1{\textcolor[rgb]{0.00,0.50,0.00}{##1}}}
\@namedef{PY@tok@nf}{\def\PY@tc##1{\textcolor[rgb]{0.00,0.00,1.00}{##1}}}
\@namedef{PY@tok@nc}{\let\PY@bf=\textbf\def\PY@tc##1{\textcolor[rgb]{0.00,0.00,1.00}{##1}}}
\@namedef{PY@tok@nn}{\let\PY@bf=\textbf\def\PY@tc##1{\textcolor[rgb]{0.00,0.00,1.00}{##1}}}
\@namedef{PY@tok@ne}{\let\PY@bf=\textbf\def\PY@tc##1{\textcolor[rgb]{0.80,0.25,0.22}{##1}}}
\@namedef{PY@tok@nv}{\def\PY@tc##1{\textcolor[rgb]{0.10,0.09,0.49}{##1}}}
\@namedef{PY@tok@no}{\def\PY@tc##1{\textcolor[rgb]{0.53,0.00,0.00}{##1}}}
\@namedef{PY@tok@nl}{\def\PY@tc##1{\textcolor[rgb]{0.46,0.46,0.00}{##1}}}
\@namedef{PY@tok@ni}{\let\PY@bf=\textbf\def\PY@tc##1{\textcolor[rgb]{0.44,0.44,0.44}{##1}}}
\@namedef{PY@tok@na}{\def\PY@tc##1{\textcolor[rgb]{0.41,0.47,0.13}{##1}}}
\@namedef{PY@tok@nt}{\let\PY@bf=\textbf\def\PY@tc##1{\textcolor[rgb]{0.00,0.50,0.00}{##1}}}
\@namedef{PY@tok@nd}{\def\PY@tc##1{\textcolor[rgb]{0.67,0.13,1.00}{##1}}}
\@namedef{PY@tok@s}{\def\PY@tc##1{\textcolor[rgb]{0.73,0.13,0.13}{##1}}}
\@namedef{PY@tok@sd}{\let\PY@it=\textit\def\PY@tc##1{\textcolor[rgb]{0.73,0.13,0.13}{##1}}}
\@namedef{PY@tok@si}{\let\PY@bf=\textbf\def\PY@tc##1{\textcolor[rgb]{0.64,0.35,0.47}{##1}}}
\@namedef{PY@tok@se}{\let\PY@bf=\textbf\def\PY@tc##1{\textcolor[rgb]{0.67,0.36,0.12}{##1}}}
\@namedef{PY@tok@sr}{\def\PY@tc##1{\textcolor[rgb]{0.64,0.35,0.47}{##1}}}
\@namedef{PY@tok@ss}{\def\PY@tc##1{\textcolor[rgb]{0.10,0.09,0.49}{##1}}}
\@namedef{PY@tok@sx}{\def\PY@tc##1{\textcolor[rgb]{0.00,0.50,0.00}{##1}}}
\@namedef{PY@tok@m}{\def\PY@tc##1{\textcolor[rgb]{0.40,0.40,0.40}{##1}}}
\@namedef{PY@tok@gh}{\let\PY@bf=\textbf\def\PY@tc##1{\textcolor[rgb]{0.00,0.00,0.50}{##1}}}
\@namedef{PY@tok@gu}{\let\PY@bf=\textbf\def\PY@tc##1{\textcolor[rgb]{0.50,0.00,0.50}{##1}}}
\@namedef{PY@tok@gd}{\def\PY@tc##1{\textcolor[rgb]{0.63,0.00,0.00}{##1}}}
\@namedef{PY@tok@gi}{\def\PY@tc##1{\textcolor[rgb]{0.00,0.52,0.00}{##1}}}
\@namedef{PY@tok@gr}{\def\PY@tc##1{\textcolor[rgb]{0.89,0.00,0.00}{##1}}}
\@namedef{PY@tok@ge}{\let\PY@it=\textit}
\@namedef{PY@tok@gs}{\let\PY@bf=\textbf}
\@namedef{PY@tok@gp}{\let\PY@bf=\textbf\def\PY@tc##1{\textcolor[rgb]{0.00,0.00,0.50}{##1}}}
\@namedef{PY@tok@go}{\def\PY@tc##1{\textcolor[rgb]{0.44,0.44,0.44}{##1}}}
\@namedef{PY@tok@gt}{\def\PY@tc##1{\textcolor[rgb]{0.00,0.27,0.87}{##1}}}
\@namedef{PY@tok@err}{\def\PY@bc##1{{\setlength{\fboxsep}{\string -\fboxrule}\fcolorbox[rgb]{1.00,0.00,0.00}{1,1,1}{\strut ##1}}}}
\@namedef{PY@tok@kc}{\let\PY@bf=\textbf\def\PY@tc##1{\textcolor[rgb]{0.00,0.50,0.00}{##1}}}
\@namedef{PY@tok@kd}{\let\PY@bf=\textbf\def\PY@tc##1{\textcolor[rgb]{0.00,0.50,0.00}{##1}}}
\@namedef{PY@tok@kn}{\let\PY@bf=\textbf\def\PY@tc##1{\textcolor[rgb]{0.00,0.50,0.00}{##1}}}
\@namedef{PY@tok@kr}{\let\PY@bf=\textbf\def\PY@tc##1{\textcolor[rgb]{0.00,0.50,0.00}{##1}}}
\@namedef{PY@tok@bp}{\def\PY@tc##1{\textcolor[rgb]{0.00,0.50,0.00}{##1}}}
\@namedef{PY@tok@fm}{\def\PY@tc##1{\textcolor[rgb]{0.00,0.00,1.00}{##1}}}
\@namedef{PY@tok@vc}{\def\PY@tc##1{\textcolor[rgb]{0.10,0.09,0.49}{##1}}}
\@namedef{PY@tok@vg}{\def\PY@tc##1{\textcolor[rgb]{0.10,0.09,0.49}{##1}}}
\@namedef{PY@tok@vi}{\def\PY@tc##1{\textcolor[rgb]{0.10,0.09,0.49}{##1}}}
\@namedef{PY@tok@vm}{\def\PY@tc##1{\textcolor[rgb]{0.10,0.09,0.49}{##1}}}
\@namedef{PY@tok@sa}{\def\PY@tc##1{\textcolor[rgb]{0.73,0.13,0.13}{##1}}}
\@namedef{PY@tok@sb}{\def\PY@tc##1{\textcolor[rgb]{0.73,0.13,0.13}{##1}}}
\@namedef{PY@tok@sc}{\def\PY@tc##1{\textcolor[rgb]{0.73,0.13,0.13}{##1}}}
\@namedef{PY@tok@dl}{\def\PY@tc##1{\textcolor[rgb]{0.73,0.13,0.13}{##1}}}
\@namedef{PY@tok@s2}{\def\PY@tc##1{\textcolor[rgb]{0.73,0.13,0.13}{##1}}}
\@namedef{PY@tok@sh}{\def\PY@tc##1{\textcolor[rgb]{0.73,0.13,0.13}{##1}}}
\@namedef{PY@tok@s1}{\def\PY@tc##1{\textcolor[rgb]{0.73,0.13,0.13}{##1}}}
\@namedef{PY@tok@mb}{\def\PY@tc##1{\textcolor[rgb]{0.40,0.40,0.40}{##1}}}
\@namedef{PY@tok@mf}{\def\PY@tc##1{\textcolor[rgb]{0.40,0.40,0.40}{##1}}}
\@namedef{PY@tok@mh}{\def\PY@tc##1{\textcolor[rgb]{0.40,0.40,0.40}{##1}}}
\@namedef{PY@tok@mi}{\def\PY@tc##1{\textcolor[rgb]{0.40,0.40,0.40}{##1}}}
\@namedef{PY@tok@il}{\def\PY@tc##1{\textcolor[rgb]{0.40,0.40,0.40}{##1}}}
\@namedef{PY@tok@mo}{\def\PY@tc##1{\textcolor[rgb]{0.40,0.40,0.40}{##1}}}
\@namedef{PY@tok@ch}{\let\PY@it=\textit\def\PY@tc##1{\textcolor[rgb]{0.24,0.48,0.48}{##1}}}
\@namedef{PY@tok@cm}{\let\PY@it=\textit\def\PY@tc##1{\textcolor[rgb]{0.24,0.48,0.48}{##1}}}
\@namedef{PY@tok@cpf}{\let\PY@it=\textit\def\PY@tc##1{\textcolor[rgb]{0.24,0.48,0.48}{##1}}}
\@namedef{PY@tok@c1}{\let\PY@it=\textit\def\PY@tc##1{\textcolor[rgb]{0.24,0.48,0.48}{##1}}}
\@namedef{PY@tok@cs}{\let\PY@it=\textit\def\PY@tc##1{\textcolor[rgb]{0.24,0.48,0.48}{##1}}}

\def\PYZbs{\char`\\}
\def\PYZus{\char`\_}
\def\PYZob{\char`\{}
\def\PYZcb{\char`\}}
\def\PYZca{\char`\^}
\def\PYZam{\char`\&}
\def\PYZlt{\char`\<}
\def\PYZgt{\char`\>}
\def\PYZsh{\char`\#}
\def\PYZpc{\char`\%}
\def\PYZdl{\char`\$}
\def\PYZhy{\char`\-}
\def\PYZsq{\char`\'}
\def\PYZdq{\char`\"}
\def\PYZti{\char`\~}
% for compatibility with earlier versions
\def\PYZat{@}
\def\PYZlb{[}
\def\PYZrb{]}
\makeatother


    % For linebreaks inside Verbatim environment from package fancyvrb. 
    \makeatletter
        \newbox\Wrappedcontinuationbox 
        \newbox\Wrappedvisiblespacebox 
        \newcommand*\Wrappedvisiblespace {\textcolor{red}{\textvisiblespace}} 
        \newcommand*\Wrappedcontinuationsymbol {\textcolor{red}{\llap{\tiny$\m@th\hookrightarrow$}}} 
        \newcommand*\Wrappedcontinuationindent {3ex } 
        \newcommand*\Wrappedafterbreak {\kern\Wrappedcontinuationindent\copy\Wrappedcontinuationbox} 
        % Take advantage of the already applied Pygments mark-up to insert 
        % potential linebreaks for TeX processing. 
        %        {, <, #, %, $, ' and ": go to next line. 
        %        _, }, ^, &, >, - and ~: stay at end of broken line. 
        % Use of \textquotesingle for straight quote. 
        \newcommand*\Wrappedbreaksatspecials {% 
            \def\PYGZus{\discretionary{\char`\_}{\Wrappedafterbreak}{\char`\_}}% 
            \def\PYGZob{\discretionary{}{\Wrappedafterbreak\char`\{}{\char`\{}}% 
            \def\PYGZcb{\discretionary{\char`\}}{\Wrappedafterbreak}{\char`\}}}% 
            \def\PYGZca{\discretionary{\char`\^}{\Wrappedafterbreak}{\char`\^}}% 
            \def\PYGZam{\discretionary{\char`\&}{\Wrappedafterbreak}{\char`\&}}% 
            \def\PYGZlt{\discretionary{}{\Wrappedafterbreak\char`\<}{\char`\<}}% 
            \def\PYGZgt{\discretionary{\char`\>}{\Wrappedafterbreak}{\char`\>}}% 
            \def\PYGZsh{\discretionary{}{\Wrappedafterbreak\char`\#}{\char`\#}}% 
            \def\PYGZpc{\discretionary{}{\Wrappedafterbreak\char`\%}{\char`\%}}% 
            \def\PYGZdl{\discretionary{}{\Wrappedafterbreak\char`\$}{\char`\$}}% 
            \def\PYGZhy{\discretionary{\char`\-}{\Wrappedafterbreak}{\char`\-}}% 
            \def\PYGZsq{\discretionary{}{\Wrappedafterbreak\textquotesingle}{\textquotesingle}}% 
            \def\PYGZdq{\discretionary{}{\Wrappedafterbreak\char`\"}{\char`\"}}% 
            \def\PYGZti{\discretionary{\char`\~}{\Wrappedafterbreak}{\char`\~}}% 
        } 
        % Some characters . , ; ? ! / are not pygmentized. 
        % This macro makes them "active" and they will insert potential linebreaks 
        \newcommand*\Wrappedbreaksatpunct {% 
            \lccode`\~`\.\lowercase{\def~}{\discretionary{\hbox{\char`\.}}{\Wrappedafterbreak}{\hbox{\char`\.}}}% 
            \lccode`\~`\,\lowercase{\def~}{\discretionary{\hbox{\char`\,}}{\Wrappedafterbreak}{\hbox{\char`\,}}}% 
            \lccode`\~`\;\lowercase{\def~}{\discretionary{\hbox{\char`\;}}{\Wrappedafterbreak}{\hbox{\char`\;}}}% 
            \lccode`\~`\:\lowercase{\def~}{\discretionary{\hbox{\char`\:}}{\Wrappedafterbreak}{\hbox{\char`\:}}}% 
            \lccode`\~`\?\lowercase{\def~}{\discretionary{\hbox{\char`\?}}{\Wrappedafterbreak}{\hbox{\char`\?}}}% 
            \lccode`\~`\!\lowercase{\def~}{\discretionary{\hbox{\char`\!}}{\Wrappedafterbreak}{\hbox{\char`\!}}}% 
            \lccode`\~`\/\lowercase{\def~}{\discretionary{\hbox{\char`\/}}{\Wrappedafterbreak}{\hbox{\char`\/}}}% 
            \catcode`\.\active
            \catcode`\,\active 
            \catcode`\;\active
            \catcode`\:\active
            \catcode`\?\active
            \catcode`\!\active
            \catcode`\/\active 
            \lccode`\~`\~ 	
        }
    \makeatother

    \let\OriginalVerbatim=\Verbatim
    \makeatletter
    \renewcommand{\Verbatim}[1][1]{%
        %\parskip\z@skip
        \sbox\Wrappedcontinuationbox {\Wrappedcontinuationsymbol}%
        \sbox\Wrappedvisiblespacebox {\FV@SetupFont\Wrappedvisiblespace}%
        \def\FancyVerbFormatLine ##1{\hsize\linewidth
            \vtop{\raggedright\hyphenpenalty\z@\exhyphenpenalty\z@
                \doublehyphendemerits\z@\finalhyphendemerits\z@
                \strut ##1\strut}%
        }%
        % If the linebreak is at a space, the latter will be displayed as visible
        % space at end of first line, and a continuation symbol starts next line.
        % Stretch/shrink are however usually zero for typewriter font.
        \def\FV@Space {%
            \nobreak\hskip\z@ plus\fontdimen3\font minus\fontdimen4\font
            \discretionary{\copy\Wrappedvisiblespacebox}{\Wrappedafterbreak}
            {\kern\fontdimen2\font}%
        }%
        
        % Allow breaks at special characters using \PYG... macros.
        \Wrappedbreaksatspecials
        % Breaks at punctuation characters . , ; ? ! and / need catcode=\active 	
        \OriginalVerbatim[#1,codes*=\Wrappedbreaksatpunct]%
    }
    \makeatother

    % Exact colors from NB
    \definecolor{incolor}{HTML}{303F9F}
    \definecolor{outcolor}{HTML}{D84315}
    \definecolor{cellborder}{HTML}{CFCFCF}
    \definecolor{cellbackground}{HTML}{F7F7F7}
    
    % prompt
    \makeatletter
    \newcommand{\boxspacing}{\kern\kvtcb@left@rule\kern\kvtcb@boxsep}
    \makeatother
    \newcommand{\prompt}[4]{
        {\ttfamily\llap{{\color{#2}[#3]:\hspace{3pt}#4}}\vspace{-\baselineskip}}
    }
    

    
    % Prevent overflowing lines due to hard-to-break entities
    \sloppy 
    % Setup hyperref package
    \hypersetup{
      breaklinks=true,  % so long urls are correctly broken across lines
      colorlinks=true,
      urlcolor=urlcolor,
      linkcolor=linkcolor,
      citecolor=citecolor,
      }
    % Slightly bigger margins than the latex defaults
    
    \geometry{verbose,tmargin=1in,bmargin=1in,lmargin=1in,rmargin=1in}
    
    

\begin{document}
    
    \maketitle
    
    

    
    \hypertarget{introduction}{%
\section{0 - Introduction}\label{introduction}}

    The work in this notebook is inspired by: -
\href{https://scikit-learn.org/stable/modules/generated/sklearn.pipeline.Pipeline.html}{Scikit-Learn's
\texttt{Pipeline}} -
\href{https://www.amazon.ca/Hands-Machine-Learning-Scikit-Learn-TensorFlow/dp/1491962291}{Hands-On
Machine Learning with Scikit-Learn and TensorFlow} by \textbf{Aurélien
Géron} -
\href{https://www.kaggle.com/code/juliencs/a-study-on-regression-applied-to-the-ames-dataset/notebook}{A
study on regression applied to the Ames dataset}

    \begin{tcolorbox}[breakable, size=fbox, boxrule=1pt, pad at break*=1mm,colback=cellbackground, colframe=cellborder]
\prompt{In}{incolor}{1}{\boxspacing}
\begin{Verbatim}[commandchars=\\\{\}]
\PY{k+kn}{import} \PY{n+nn}{gc} 
\PY{k+kn}{import} \PY{n+nn}{numpy} \PY{k}{as} \PY{n+nn}{np} 
\PY{k+kn}{from} \PY{n+nn}{numpy} \PY{k+kn}{import} \PY{n}{hstack}
\PY{k+kn}{from} \PY{n+nn}{numpy} \PY{k+kn}{import} \PY{n}{array}
\PY{k+kn}{import} \PY{n+nn}{pandas} \PY{k}{as} \PY{n+nn}{pd} 
\PY{k+kn}{import} \PY{n+nn}{matplotlib}\PY{n+nn}{.}\PY{n+nn}{pyplot} \PY{k}{as} \PY{n+nn}{plt} 
\PY{k+kn}{import} \PY{n+nn}{seaborn} \PY{k}{as} \PY{n+nn}{sns}
\PY{n}{color} \PY{o}{=} \PY{n}{sns}\PY{o}{.}\PY{n}{color\PYZus{}palette}\PY{p}{(}\PY{p}{)}
\PY{n}{sns}\PY{o}{.}\PY{n}{set\PYZus{}style}\PY{p}{(}\PY{l+s+s1}{\PYZsq{}}\PY{l+s+s1}{darkgrid}\PY{l+s+s1}{\PYZsq{}}\PY{p}{)}
\PY{k+kn}{import} \PY{n+nn}{os}
\PY{k+kn}{import} \PY{n+nn}{sklearn}
\PY{k+kn}{from} \PY{n+nn}{scipy} \PY{k+kn}{import} \PY{n}{stats}
\PY{k+kn}{from} \PY{n+nn}{scipy}\PY{n+nn}{.}\PY{n+nn}{stats} \PY{k+kn}{import} \PY{n}{norm}\PY{p}{,} \PY{n}{skew}
\PY{k+kn}{import} \PY{n+nn}{pandas\PYZus{}profiling}
\PY{o}{\PYZpc{}}\PY{k}{matplotlib} inline 

\PY{c+c1}{\PYZsh{} Suppress warnings }
\PY{k+kn}{import} \PY{n+nn}{warnings}
\PY{n}{warnings}\PY{o}{.}\PY{n}{filterwarnings}\PY{p}{(}\PY{l+s+s1}{\PYZsq{}}\PY{l+s+s1}{ignore}\PY{l+s+s1}{\PYZsq{}}\PY{p}{)}   
\end{Verbatim}
\end{tcolorbox}

    \begin{tcolorbox}[breakable, size=fbox, boxrule=1pt, pad at break*=1mm,colback=cellbackground, colframe=cellborder]
\prompt{In}{incolor}{2}{\boxspacing}
\begin{Verbatim}[commandchars=\\\{\}]
\PY{k+kn}{import} \PY{n+nn}{utils}
\end{Verbatim}
\end{tcolorbox}

    Import a library with some useful function and classes in order to
prevent the notebook from being too long and boring. Another advantage
is reusability for other Data Science tasks.

Function: - check\_duplicates(dataframe,features): check for duplicates
looking at specified \texttt{features} -
drop\_duplicates(dataframe,features): drop duplicates looking at
specified \texttt{features} and return updated dataframe -
predict\_in\_chunks(model,preprocessor,df): simply predicts chunk by
chunk\\
- nan\_values(dataframe,percentage): drop rows in \texttt{dataframe}
containing more than a certain \texttt{percentage} of NaN Values -
drop\_outliers(dataframe,feature,std\_factor): drop rows in
\texttt{dataframe} with a value for specified \texttt{feature} that is
outside \texttt{std\_factor} multiply by standard deviation of
\texttt{feature}. Future work: add isolation forest and some other
methods for outliers detection - plot\_variable(feature): plot
distribution of \texttt{feature} - def reduce\_mem\_usage(dataframe):
reduce memory usage for dataframe but can be used only on not null
values. So this function before reducing memory usage substitute null
values with min values minus 1 for each feature. - def
get\_eval\_metrics(models, X, y\_true): Calculates MAE (Mean Absoulate
Error) and RMSE (Root Mean Squared Error) on the data set for input
models. \texttt{models}: list of fit models - def
get\_cross\_val\_scores(models, X, y, cv=10, fit\_params=None): Performs
k-fold cross validation and calculates MAE for each fold for all input
models. \texttt{models}: list of fit models

In this notebook I have implemented Scikit-Learn pipeline so each of
this classes inherits Scikit-Learn BaseEstimator and TransformerMixin
like Scikit-Learn reference explains. Classes: - class
ConvertToCategorical(BaseEstimator, TransformerMixin): pipeline to
convert categorical variables to Pandas Category type. This pipeline is
specific to LGBM which handles categorical vars differently. - class
FeatureDropper(BaseEstimator, TransformerMixin): drop a list of features
- class ColumnNamesAppender(BaseEstimator, TransformerMixin): output of
scikitlearn pipeline is numpy array instead of pandas dataframe. So,
this class does this transformation - class
ConvertFeatureType(BaseEstimator, TransformerMixin): convert features to
a specific type (int,float,string and boolean) - class
FeatureEncoderAndScaler(BaseEstimator, TransformerMixin): - class
CreateDerivedFeatures(BaseEstimator, TransformerMixin): creates new
features by combining existing variables - class
CreateDateFeatures(BaseEstimator, TransformerMixin): creates simple date
features by extracting the information from \texttt{transactiondate}\\
- class ConvertToType(BaseEstimator, TransformerMixin): convert ALL
columns to specific type - class CreateYearFeatures(BaseEstimator,
TransformerMixin): convert date to age by looking to current year -
class CreatePolynomialFeatures(BaseEstimator, TransformerMixin): create
3 new polinomial features: squared,cubed and sqrt. - class
BoxCoxSkewedFeatures(BaseEstimator, TransformerMixin): apply Box-Cox
transformation in order to remove asymmetry in features with skewness
above a certain threshold

    \hypertarget{import-zillow-datasets}{%
\section{1 - Import Zillow Datasets}\label{import-zillow-datasets}}

Goal is to predict the log-error between their Zestimate (value
predicted by Zillow asset evaluation) and the actual sale price, given
all the features of a home. The log error is defined as
\texttt{logerror\ =\ log(Zestimate)\ -\ log(SalePrice)}

    \begin{tcolorbox}[breakable, size=fbox, boxrule=1pt, pad at break*=1mm,colback=cellbackground, colframe=cellborder]
\prompt{In}{incolor}{3}{\boxspacing}
\begin{Verbatim}[commandchars=\\\{\}]
\PY{k}{def} \PY{n+nf}{load\PYZus{}data}\PY{p}{(}\PY{n}{path}\PY{p}{)}\PY{p}{:}
    \PY{n}{properties\PYZus{}2016} \PY{o}{=} \PY{n}{pd}\PY{o}{.}\PY{n}{read\PYZus{}csv}\PY{p}{(}\PY{n}{os}\PY{o}{.}\PY{n}{path}\PY{o}{.}\PY{n}{join}\PY{p}{(}\PY{n}{path}\PY{p}{,} \PY{l+s+s1}{\PYZsq{}}\PY{l+s+s1}{properties\PYZus{}2016.csv}\PY{l+s+s1}{\PYZsq{}}\PY{p}{)}\PY{p}{,}\PY{n}{low\PYZus{}memory}\PY{o}{=}\PY{k+kc}{False}\PY{p}{)}
    \PY{n}{properties\PYZus{}2017} \PY{o}{=} \PY{n}{pd}\PY{o}{.}\PY{n}{read\PYZus{}csv}\PY{p}{(}\PY{n}{os}\PY{o}{.}\PY{n}{path}\PY{o}{.}\PY{n}{join}\PY{p}{(}\PY{n}{path}\PY{p}{,} \PY{l+s+s1}{\PYZsq{}}\PY{l+s+s1}{properties\PYZus{}2017.csv}\PY{l+s+s1}{\PYZsq{}}\PY{p}{)}\PY{p}{,}\PY{n}{low\PYZus{}memory}\PY{o}{=}\PY{k+kc}{False}\PY{p}{)}
    \PY{n}{train\PYZus{}2016} \PY{o}{=} \PY{n}{pd}\PY{o}{.}\PY{n}{read\PYZus{}csv}\PY{p}{(}\PY{n}{os}\PY{o}{.}\PY{n}{path}\PY{o}{.}\PY{n}{join}\PY{p}{(}\PY{n}{path}\PY{p}{,} \PY{l+s+s1}{\PYZsq{}}\PY{l+s+s1}{train\PYZus{}2016.csv}\PY{l+s+s1}{\PYZsq{}}\PY{p}{)}\PY{p}{)}
    \PY{n}{train\PYZus{}2017} \PY{o}{=} \PY{n}{pd}\PY{o}{.}\PY{n}{read\PYZus{}csv}\PY{p}{(}\PY{n}{os}\PY{o}{.}\PY{n}{path}\PY{o}{.}\PY{n}{join}\PY{p}{(}\PY{n}{path}\PY{p}{,} \PY{l+s+s1}{\PYZsq{}}\PY{l+s+s1}{train\PYZus{}2017.csv}\PY{l+s+s1}{\PYZsq{}}\PY{p}{)}\PY{p}{)}
    \PY{n+nb}{print}\PY{p}{(}\PY{n}{properties\PYZus{}2016}\PY{o}{.}\PY{n}{shape}\PY{p}{)}
    \PY{n+nb}{print}\PY{p}{(}\PY{n}{properties\PYZus{}2017}\PY{o}{.}\PY{n}{shape}\PY{p}{)}
    \PY{n+nb}{print}\PY{p}{(}\PY{n}{train\PYZus{}2016}\PY{o}{.}\PY{n}{shape}\PY{p}{)}
    \PY{n+nb}{print}\PY{p}{(}\PY{n}{train\PYZus{}2017}\PY{o}{.}\PY{n}{shape}\PY{p}{)}
    
    \PY{c+c1}{\PYZsh{} Left join will ignore all properties that do not have a logerror (target variable) associated with them}
    \PY{n}{train\PYZus{}2016} \PY{o}{=} \PY{n}{pd}\PY{o}{.}\PY{n}{merge}\PY{p}{(}\PY{n}{train\PYZus{}2016}\PY{p}{,} \PY{n}{properties\PYZus{}2016}\PY{p}{,} \PY{n}{how} \PY{o}{=} \PY{l+s+s1}{\PYZsq{}}\PY{l+s+s1}{left}\PY{l+s+s1}{\PYZsq{}}\PY{p}{,} \PY{n}{on} \PY{o}{=} \PY{l+s+s1}{\PYZsq{}}\PY{l+s+s1}{parcelid}\PY{l+s+s1}{\PYZsq{}}\PY{p}{)}
    \PY{n}{train\PYZus{}2017} \PY{o}{=} \PY{n}{pd}\PY{o}{.}\PY{n}{merge}\PY{p}{(}\PY{n}{train\PYZus{}2017}\PY{p}{,} \PY{n}{properties\PYZus{}2017}\PY{p}{,} \PY{n}{how} \PY{o}{=} \PY{l+s+s1}{\PYZsq{}}\PY{l+s+s1}{left}\PY{l+s+s1}{\PYZsq{}}\PY{p}{,} \PY{n}{on} \PY{o}{=} \PY{l+s+s1}{\PYZsq{}}\PY{l+s+s1}{parcelid}\PY{l+s+s1}{\PYZsq{}}\PY{p}{)}
    
    \PY{n}{all\PYZus{}properties} \PY{o}{=} \PY{n}{pd}\PY{o}{.}\PY{n}{concat}\PY{p}{(}\PY{p}{[}\PY{n}{properties\PYZus{}2016}\PY{p}{,} \PY{n}{properties\PYZus{}2017}\PY{p}{]}\PY{p}{,} \PY{n}{ignore\PYZus{}index}\PY{o}{=}\PY{k+kc}{True}\PY{p}{)}
    \PY{n+nb}{print}\PY{p}{(}\PY{n}{all\PYZus{}properties}\PY{o}{.}\PY{n}{shape}\PY{p}{)}
    \PY{n}{all\PYZus{}training} \PY{o}{=} \PY{n}{pd}\PY{o}{.}\PY{n}{concat}\PY{p}{(}\PY{p}{[}\PY{n}{train\PYZus{}2016}\PY{p}{,} \PY{n}{train\PYZus{}2017}\PY{p}{]}\PY{p}{,} \PY{n}{ignore\PYZus{}index}\PY{o}{=}\PY{k+kc}{True}\PY{p}{)}
    \PY{k}{return} \PY{n}{all\PYZus{}properties}\PY{p}{,} \PY{n}{all\PYZus{}training}
\end{Verbatim}
\end{tcolorbox}

    \begin{tcolorbox}[breakable, size=fbox, boxrule=1pt, pad at break*=1mm,colback=cellbackground, colframe=cellborder]
\prompt{In}{incolor}{4}{\boxspacing}
\begin{Verbatim}[commandchars=\\\{\}]
\PY{n}{all\PYZus{}properties}\PY{p}{,} \PY{n}{df} \PY{o}{=} \PY{n}{load\PYZus{}data}\PY{p}{(}\PY{n}{os}\PY{o}{.}\PY{n}{path}\PY{o}{.}\PY{n}{join}\PY{p}{(}\PY{l+s+s2}{\PYZdq{}}\PY{l+s+s2}{..}\PY{l+s+s2}{\PYZdq{}}\PY{p}{,} \PY{l+s+s2}{\PYZdq{}}\PY{l+s+s2}{zillow competition}\PY{l+s+s2}{\PYZdq{}}\PY{p}{,} \PY{l+s+s2}{\PYZdq{}}\PY{l+s+s2}{zillow\PYZhy{}prize\PYZhy{}1}\PY{l+s+s2}{\PYZdq{}}\PY{p}{)}\PY{p}{)}
\PY{n}{df}\PY{o}{.}\PY{n}{head}\PY{p}{(}\PY{p}{)}
\end{Verbatim}
\end{tcolorbox}

    \begin{Verbatim}[commandchars=\\\{\}]
(2985217, 58)
(2985217, 58)
(90275, 3)
(77613, 3)
(5970434, 58)
    \end{Verbatim}

            \begin{tcolorbox}[breakable, size=fbox, boxrule=.5pt, pad at break*=1mm, opacityfill=0]
\prompt{Out}{outcolor}{4}{\boxspacing}
\begin{Verbatim}[commandchars=\\\{\}]
   parcelid  logerror transactiondate  airconditioningtypeid  \textbackslash{}
0  11016594    0.0276      2016-01-01                    1.0
1  14366692   -0.1684      2016-01-01                    NaN
2  12098116   -0.0040      2016-01-01                    1.0
3  12643413    0.0218      2016-01-02                    1.0
4  14432541   -0.0050      2016-01-02                    NaN

   architecturalstyletypeid  basementsqft  bathroomcnt  bedroomcnt  \textbackslash{}
0                       NaN           NaN          2.0         3.0
1                       NaN           NaN          3.5         4.0
2                       NaN           NaN          3.0         2.0
3                       NaN           NaN          2.0         2.0
4                       NaN           NaN          2.5         4.0

   buildingclasstypeid  buildingqualitytypeid  {\ldots}  numberofstories  \textbackslash{}
0                  NaN                    4.0  {\ldots}              NaN
1                  NaN                    NaN  {\ldots}              NaN
2                  NaN                    4.0  {\ldots}              NaN
3                  NaN                    4.0  {\ldots}              NaN
4                  NaN                    NaN  {\ldots}              2.0

   fireplaceflag  structuretaxvaluedollarcnt  taxvaluedollarcnt  \textbackslash{}
0            NaN                    122754.0           360170.0
1            NaN                    346458.0           585529.0
2            NaN                     61994.0           119906.0
3            NaN                    171518.0           244880.0
4            NaN                    169574.0           434551.0

   assessmentyear  landtaxvaluedollarcnt  taxamount  taxdelinquencyflag  \textbackslash{}
0          2015.0               237416.0    6735.88                 NaN
1          2015.0               239071.0   10153.02                 NaN
2          2015.0                57912.0   11484.48                 NaN
3          2015.0                73362.0    3048.74                 NaN
4          2015.0               264977.0    5488.96                 NaN

   taxdelinquencyyear  censustractandblock
0                 NaN         6.037107e+13
1                 NaN                  NaN
2                 NaN         6.037464e+13
3                 NaN         6.037296e+13
4                 NaN         6.059042e+13

[5 rows x 60 columns]
\end{Verbatim}
\end{tcolorbox}
        
    \begin{tcolorbox}[breakable, size=fbox, boxrule=1pt, pad at break*=1mm,colback=cellbackground, colframe=cellborder]
\prompt{In}{incolor}{5}{\boxspacing}
\begin{Verbatim}[commandchars=\\\{\}]
\PY{c+c1}{\PYZsh{}generate an explorative report}
\PY{c+c1}{\PYZsh{}pandas\PYZus{}profiling.ProfileReport(df).to\PYZus{}file(\PYZdq{}zillow\PYZus{}dataset\PYZdq{})}
\end{Verbatim}
\end{tcolorbox}

    \begin{tcolorbox}[breakable, size=fbox, boxrule=1pt, pad at break*=1mm,colback=cellbackground, colframe=cellborder]
\prompt{In}{incolor}{6}{\boxspacing}
\begin{Verbatim}[commandchars=\\\{\}]
\PY{n}{df}\PY{o}{.}\PY{n}{info}\PY{p}{(}\PY{p}{)}
\end{Verbatim}
\end{tcolorbox}

    \begin{Verbatim}[commandchars=\\\{\}]
<class 'pandas.core.frame.DataFrame'>
RangeIndex: 167888 entries, 0 to 167887
Data columns (total 60 columns):
 \#   Column                        Non-Null Count   Dtype
---  ------                        --------------   -----
 0   parcelid                      167888 non-null  int64
 1   logerror                      167888 non-null  float64
 2   transactiondate               167888 non-null  object
 3   airconditioningtypeid         53788 non-null   float64
 4   architecturalstyletypeid      468 non-null     float64
 5   basementsqft                  93 non-null      float64
 6   bathroomcnt                   167854 non-null  float64
 7   bedroomcnt                    167854 non-null  float64
 8   buildingclasstypeid           31 non-null      float64
 9   buildingqualitytypeid         107173 non-null  float64
 10  calculatedbathnbr             166056 non-null  float64
 11  decktypeid                    1272 non-null    float64
 12  finishedfloor1squarefeet      12893 non-null   float64
 13  calculatedfinishedsquarefeet  166992 non-null  float64
 14  finishedsquarefeet12          159519 non-null  float64
 15  finishedsquarefeet13          75 non-null      float64
 16  finishedsquarefeet15          6591 non-null    float64
 17  finishedsquarefeet50          12893 non-null   float64
 18  finishedsquarefeet6           807 non-null     float64
 19  fips                          167854 non-null  float64
 20  fireplacecnt                  17896 non-null   float64
 21  fullbathcnt                   166056 non-null  float64
 22  garagecarcnt                  55457 non-null   float64
 23  garagetotalsqft               55457 non-null   float64
 24  hashottuborspa                3904 non-null    object
 25  heatingorsystemtypeid         105651 non-null  float64
 26  latitude                      167854 non-null  float64
 27  longitude                     167854 non-null  float64
 28  lotsizesquarefeet             149446 non-null  float64
 29  poolcnt                       34075 non-null   float64
 30  poolsizesum                   1838 non-null    float64
 31  pooltypeid10                  1626 non-null    float64
 32  pooltypeid2                   2278 non-null    float64
 33  pooltypeid7                   31776 non-null   float64
 34  propertycountylandusecode     167853 non-null  object
 35  propertylandusetypeid         167854 non-null  float64
 36  propertyzoningdesc            108789 non-null  object
 37  rawcensustractandblock        167854 non-null  float64
 38  regionidcity                  164579 non-null  float64
 39  regionidcounty                167854 non-null  float64
 40  regionidneighborhood          66986 non-null   float64
 41  regionidzip                   167769 non-null  float64
 42  roomcnt                       167854 non-null  float64
 43  storytypeid                   93 non-null      float64
 44  threequarterbathnbr           22115 non-null   float64
 45  typeconstructiontypeid        522 non-null     float64
 46  unitcnt                       109056 non-null  float64
 47  yardbuildingsqft17            5039 non-null    float64
 48  yardbuildingsqft26            165 non-null     float64
 49  yearbuilt                     166828 non-null  float64
 50  numberofstories               38169 non-null   float64
 51  fireplaceflag                 394 non-null     object
 52  structuretaxvaluedollarcnt    167359 non-null  float64
 53  taxvaluedollarcnt             167852 non-null  float64
 54  assessmentyear                167854 non-null  float64
 55  landtaxvaluedollarcnt         167851 non-null  float64
 56  taxamount                     167843 non-null  float64
 57  taxdelinquencyflag            4683 non-null    object
 58  taxdelinquencyyear            4683 non-null    float64
 59  censustractandblock           167002 non-null  float64
dtypes: float64(53), int64(1), object(6)
memory usage: 76.9+ MB
    \end{Verbatim}

    \begin{tcolorbox}[breakable, size=fbox, boxrule=1pt, pad at break*=1mm,colback=cellbackground, colframe=cellborder]
\prompt{In}{incolor}{7}{\boxspacing}
\begin{Verbatim}[commandchars=\\\{\}]
\PY{n}{plt}\PY{o}{.}\PY{n}{figure}\PY{p}{(}\PY{n}{figsize}\PY{o}{=}\PY{p}{(}\PY{l+m+mi}{12}\PY{p}{,}\PY{l+m+mi}{12}\PY{p}{)}\PY{p}{)}
\PY{n}{sns}\PY{o}{.}\PY{n}{jointplot}\PY{p}{(}\PY{n}{x}\PY{o}{=}\PY{n}{all\PYZus{}properties}\PY{o}{.}\PY{n}{latitude}\PY{o}{.}\PY{n}{values}\PY{p}{,} \PY{n}{y}\PY{o}{=}\PY{n}{all\PYZus{}properties}\PY{o}{.}\PY{n}{longitude}\PY{o}{.}\PY{n}{values}\PY{p}{,} \PY{n}{height}\PY{o}{=}\PY{l+m+mi}{10}\PY{p}{)}
\PY{n}{plt}\PY{o}{.}\PY{n}{ylabel}\PY{p}{(}\PY{l+s+s1}{\PYZsq{}}\PY{l+s+s1}{Longitude}\PY{l+s+s1}{\PYZsq{}}\PY{p}{,} \PY{n}{fontsize}\PY{o}{=}\PY{l+m+mi}{12}\PY{p}{)}
\PY{n}{plt}\PY{o}{.}\PY{n}{xlabel}\PY{p}{(}\PY{l+s+s1}{\PYZsq{}}\PY{l+s+s1}{Latitude}\PY{l+s+s1}{\PYZsq{}}\PY{p}{,} \PY{n}{fontsize}\PY{o}{=}\PY{l+m+mi}{12}\PY{p}{)}

\PY{n}{plt}\PY{o}{.}\PY{n}{show}\PY{p}{(}\PY{p}{)}
\end{Verbatim}
\end{tcolorbox}

    
    \begin{Verbatim}[commandchars=\\\{\}]
<Figure size 864x864 with 0 Axes>
    \end{Verbatim}

    
    \begin{center}
    \adjustimage{max size={0.9\linewidth}{0.9\paperheight}}{output_10_1.png}
    \end{center}
    { \hspace*{\fill} \\}
    
    \begin{tcolorbox}[breakable, size=fbox, boxrule=1pt, pad at break*=1mm,colback=cellbackground, colframe=cellborder]
\prompt{In}{incolor}{8}{\boxspacing}
\begin{Verbatim}[commandchars=\\\{\}]
\PY{n}{utils}\PY{o}{.}\PY{n}{check\PYZus{}duplicates}\PY{p}{(}\PY{n}{df}\PY{p}{,}\PY{p}{[}\PY{l+s+s1}{\PYZsq{}}\PY{l+s+s1}{parcelid}\PY{l+s+s1}{\PYZsq{}}\PY{p}{,} \PY{l+s+s1}{\PYZsq{}}\PY{l+s+s1}{transactiondate}\PY{l+s+s1}{\PYZsq{}}\PY{p}{]}\PY{p}{)}
\PY{n}{df} \PY{o}{=} \PY{n}{utils}\PY{o}{.}\PY{n}{drop\PYZus{}duplicates}\PY{p}{(}\PY{n}{df}\PY{p}{,}\PY{p}{[}\PY{l+s+s1}{\PYZsq{}}\PY{l+s+s1}{parcelid}\PY{l+s+s1}{\PYZsq{}}\PY{p}{,} \PY{l+s+s1}{\PYZsq{}}\PY{l+s+s1}{transactiondate}\PY{l+s+s1}{\PYZsq{}}\PY{p}{]}\PY{p}{)}
\PY{n}{utils}\PY{o}{.}\PY{n}{check\PYZus{}duplicates}\PY{p}{(}\PY{n}{df}\PY{p}{,}\PY{p}{[}\PY{l+s+s1}{\PYZsq{}}\PY{l+s+s1}{parcelid}\PY{l+s+s1}{\PYZsq{}}\PY{p}{,} \PY{l+s+s1}{\PYZsq{}}\PY{l+s+s1}{transactiondate}\PY{l+s+s1}{\PYZsq{}}\PY{p}{]}\PY{p}{)}
\end{Verbatim}
\end{tcolorbox}

    \begin{Verbatim}[commandchars=\\\{\}]
There are 0 duplicate IDs for 167888 total entries
Dropping all duplicates based on: ['parcelid', 'transactiondate']
There are 0 duplicate IDs for 167888 total entries
    \end{Verbatim}

    \begin{tcolorbox}[breakable, size=fbox, boxrule=1pt, pad at break*=1mm,colback=cellbackground, colframe=cellborder]
\prompt{In}{incolor}{9}{\boxspacing}
\begin{Verbatim}[commandchars=\\\{\}]
\PY{c+c1}{\PYZsh{}df[[\PYZdq{}garagecarcnt\PYZdq{},\PYZdq{}garagetotalsqft\PYZdq{},\PYZdq{}fireplacecnt\PYZdq{},\PYZdq{}decktypeid\PYZdq{},\PYZdq{}hashottuborspa\PYZdq{},\PYZdq{}poolcnt\PYZdq{},\PYZdq{}pooltypeid10\PYZdq{},\PYZdq{}pooltypeid2\PYZdq{},\PYZdq{}pooltypeid7\PYZdq{},\PYZdq{}yardbuildingsqft17\PYZdq{},}
\PY{c+c1}{\PYZsh{}                 \PYZdq{}threequarterbathnbr\PYZdq{},\PYZdq{}taxdelinquencyflag\PYZdq{}]].fillna(0,inplace=True)}
\PY{n}{dropped} \PY{o}{=} \PY{p}{[}\PY{l+s+s2}{\PYZdq{}}\PY{l+s+s2}{finishedsquarefeet13}\PY{l+s+s2}{\PYZdq{}}\PY{p}{,} \PY{l+s+s2}{\PYZdq{}}\PY{l+s+s2}{finishedsquarefeet15}\PY{l+s+s2}{\PYZdq{}}\PY{p}{,} \PY{l+s+s2}{\PYZdq{}}\PY{l+s+s2}{finishedfloor1squarefeet}\PY{l+s+s2}{\PYZdq{}}\PY{p}{,} \PY{l+s+s2}{\PYZdq{}}\PY{l+s+s2}{finishedsquarefeet50}\PY{l+s+s2}{\PYZdq{}}\PY{p}{,}
             \PY{l+s+s2}{\PYZdq{}}\PY{l+s+s2}{storytypeid}\PY{l+s+s2}{\PYZdq{}}\PY{p}{,} \PY{l+s+s2}{\PYZdq{}}\PY{l+s+s2}{architecturalstyletypeid}\PY{l+s+s2}{\PYZdq{}}\PY{p}{,} \PY{l+s+s2}{\PYZdq{}}\PY{l+s+s2}{buildingclasstypeid}\PY{l+s+s2}{\PYZdq{}}\PY{p}{,} \PY{l+s+s2}{\PYZdq{}}\PY{l+s+s2}{typeconstructiontypeid}\PY{l+s+s2}{\PYZdq{}}\PY{p}{,} \PY{l+s+s2}{\PYZdq{}}\PY{l+s+s2}{finishedsquarefeet6}\PY{l+s+s2}{\PYZdq{}}\PY{p}{,}
             \PY{l+s+s2}{\PYZdq{}}\PY{l+s+s2}{pooltypeid10}\PY{l+s+s2}{\PYZdq{}}\PY{p}{,} \PY{l+s+s2}{\PYZdq{}}\PY{l+s+s2}{pooltypeid2}\PY{l+s+s2}{\PYZdq{}}\PY{p}{,} \PY{l+s+s2}{\PYZdq{}}\PY{l+s+s2}{fireplaceflag}\PY{l+s+s2}{\PYZdq{}}\PY{p}{,} \PY{l+s+s2}{\PYZdq{}}\PY{l+s+s2}{threequarterbathnbr}\PY{l+s+s2}{\PYZdq{}}\PY{p}{,} \PY{l+s+s2}{\PYZdq{}}\PY{l+s+s2}{calculatedbathnbr}\PY{l+s+s2}{\PYZdq{}}\PY{p}{,}
             \PY{l+s+s2}{\PYZdq{}}\PY{l+s+s2}{fullbathcnt}\PY{l+s+s2}{\PYZdq{}}\PY{p}{,} \PY{l+s+s2}{\PYZdq{}}\PY{l+s+s2}{numberofstories}\PY{l+s+s2}{\PYZdq{}}\PY{p}{,} \PY{l+s+s2}{\PYZdq{}}\PY{l+s+s2}{censustractandblock}\PY{l+s+s2}{\PYZdq{}}\PY{p}{,} \PY{l+s+s2}{\PYZdq{}}\PY{l+s+s2}{rawcensustractandblock}\PY{l+s+s2}{\PYZdq{}}\PY{p}{,}
             \PY{l+s+s2}{\PYZdq{}}\PY{l+s+s2}{finishedsquarefeet12}\PY{l+s+s2}{\PYZdq{}}\PY{p}{,} \PY{l+s+s2}{\PYZdq{}}\PY{l+s+s2}{taxvaluedollarcnt}\PY{l+s+s2}{\PYZdq{}}\PY{p}{,} \PY{l+s+s2}{\PYZdq{}}\PY{l+s+s2}{assessmentyear}\PY{l+s+s2}{\PYZdq{}}\PY{p}{,} \PY{l+s+s2}{\PYZdq{}}\PY{l+s+s2}{roomcnt}\PY{l+s+s2}{\PYZdq{}}\PY{p}{,}
             \PY{l+s+s2}{\PYZdq{}}\PY{l+s+s2}{regionidneighborhood}\PY{l+s+s2}{\PYZdq{}}\PY{p}{,} \PY{l+s+s2}{\PYZdq{}}\PY{l+s+s2}{taxdelinquencyyear}\PY{l+s+s2}{\PYZdq{}}\PY{p}{,} \PY{l+s+s2}{\PYZdq{}}\PY{l+s+s2}{basementsqft}\PY{l+s+s2}{\PYZdq{}}\PY{p}{,}
             \PY{l+s+s2}{\PYZdq{}}\PY{l+s+s2}{yardbuildingsqft26}\PY{l+s+s2}{\PYZdq{}}\PY{p}{,}
            \PY{p}{]}
\PY{c+c1}{\PYZsh{}df.drop(dropped,axis=1,inplace=True)}
\end{Verbatim}
\end{tcolorbox}

    \begin{tcolorbox}[breakable, size=fbox, boxrule=1pt, pad at break*=1mm,colback=cellbackground, colframe=cellborder]
\prompt{In}{incolor}{10}{\boxspacing}
\begin{Verbatim}[commandchars=\\\{\}]
\PY{c+c1}{\PYZsh{} Drop rows containing either 75\PYZpc{} or more NaN Values}
\PY{n}{percent} \PY{o}{=} \PY{l+m+mf}{50.0} 
\PY{n}{min\PYZus{}count} \PY{o}{=}  \PY{n+nb}{int}\PY{p}{(}\PY{p}{(}\PY{p}{(}\PY{l+m+mi}{100}\PY{o}{\PYZhy{}}\PY{n}{percent}\PY{p}{)}\PY{o}{/}\PY{l+m+mi}{100}\PY{p}{)}\PY{o}{*}\PY{n}{df}\PY{o}{.}\PY{n}{shape}\PY{p}{[}\PY{l+m+mi}{1}\PY{p}{]} \PY{o}{+} \PY{l+m+mi}{1}\PY{p}{)}
\PY{n}{housing} \PY{o}{=} \PY{n}{df}\PY{o}{.}\PY{n}{dropna}\PY{p}{(}\PY{n}{axis}\PY{o}{=}\PY{l+m+mi}{0}\PY{p}{,} \PY{n}{thresh}\PY{o}{=}\PY{n}{min\PYZus{}count}\PY{p}{)}
\PY{n}{housing}\PY{o}{.}\PY{n}{shape}
\end{Verbatim}
\end{tcolorbox}

            \begin{tcolorbox}[breakable, size=fbox, boxrule=.5pt, pad at break*=1mm, opacityfill=0]
\prompt{Out}{outcolor}{10}{\boxspacing}
\begin{Verbatim}[commandchars=\\\{\}]
(138617, 60)
\end{Verbatim}
\end{tcolorbox}
        
    \hypertarget{target-variable}{%
\subsection{Target Variable}\label{target-variable}}

\texttt{logerror} is the variable we need to predict.

    \begin{tcolorbox}[breakable, size=fbox, boxrule=1pt, pad at break*=1mm,colback=cellbackground, colframe=cellborder]
\prompt{In}{incolor}{11}{\boxspacing}
\begin{Verbatim}[commandchars=\\\{\}]
\PY{n}{utils}\PY{o}{.}\PY{n}{plot\PYZus{}variable}\PY{p}{(}\PY{n}{y}\PY{o}{=}\PY{n}{df}\PY{o}{.}\PY{n}{logerror}\PY{p}{)}
\end{Verbatim}
\end{tcolorbox}

    \begin{Verbatim}[commandchars=\\\{\}]

 mu = 0.01 and sigma = 0.17

    \end{Verbatim}

    \begin{center}
    \adjustimage{max size={0.9\linewidth}{0.9\paperheight}}{output_15_1.png}
    \end{center}
    { \hspace*{\fill} \\}
    
    \begin{center}
    \adjustimage{max size={0.9\linewidth}{0.9\paperheight}}{output_15_2.png}
    \end{center}
    { \hspace*{\fill} \\}
    
    \hypertarget{dropping-outliers}{%
\subsubsection{Dropping Outliers}\label{dropping-outliers}}

Since the data is mostly normally distributed outside of the outliers,
we will drop all values that are more than 2.5 standard deviations away
from the mean.

I (others might disagree) don't care about the error itself, but how
common (here the freq part) it is. I don't want my model to spend
resources trying to learn something that happens very rarely. I think
that Zillow Data Scientist are very good, so is useless try to
predicting high errors that probably occur for some external factor.

4800 values dropped: 2,85\% of original dataset

    \begin{tcolorbox}[breakable, size=fbox, boxrule=1pt, pad at break*=1mm,colback=cellbackground, colframe=cellborder]
\prompt{In}{incolor}{12}{\boxspacing}
\begin{Verbatim}[commandchars=\\\{\}]
\PY{n}{y}\PY{p}{,}\PY{n}{df} \PY{o}{=} \PY{n}{utils}\PY{o}{.}\PY{n}{drop\PYZus{}outliers}\PY{p}{(}\PY{n}{df}\PY{p}{,}\PY{l+s+s1}{\PYZsq{}}\PY{l+s+s1}{logerror}\PY{l+s+s1}{\PYZsq{}}\PY{p}{,}\PY{l+m+mi}{2}\PY{p}{)}
\PY{n}{utils}\PY{o}{.}\PY{n}{plot\PYZus{}variable}\PY{p}{(}\PY{n}{y}\PY{o}{=}\PY{n}{df}\PY{o}{.}\PY{n}{logerror}\PY{p}{)}
\PY{n}{df}\PY{o}{.}\PY{n}{logerror}\PY{o}{.}\PY{n}{count}
\end{Verbatim}
\end{tcolorbox}

    \begin{Verbatim}[commandchars=\\\{\}]
Highest allowed 0.34531818020294763
Lowest allowed -0.3175055678604645

 mu = 0.01 and sigma = 0.08

    \end{Verbatim}

    \begin{center}
    \adjustimage{max size={0.9\linewidth}{0.9\paperheight}}{output_17_1.png}
    \end{center}
    { \hspace*{\fill} \\}
    
    \begin{center}
    \adjustimage{max size={0.9\linewidth}{0.9\paperheight}}{output_17_2.png}
    \end{center}
    { \hspace*{\fill} \\}
    
            \begin{tcolorbox}[breakable, size=fbox, boxrule=.5pt, pad at break*=1mm, opacityfill=0]
\prompt{Out}{outcolor}{12}{\boxspacing}
\begin{Verbatim}[commandchars=\\\{\}]
<bound method Series.count of 0         0.027600
1        -0.168400
2        -0.004000
3         0.021800
4        -0.005000
            {\ldots}
167883   -0.002245
167884    0.020615
167885    0.013209
167886    0.037129
167887    0.007204
Name: logerror, Length: 163052, dtype: float64>
\end{Verbatim}
\end{tcolorbox}
        
    \hypertarget{splitting-dataset}{%
\section{2 - Splitting Dataset}\label{splitting-dataset}}

Strategy: we could compute a hash of each instance's identifier and put
that instance in the test set if the hash is lower than or equal to 20\%
of the maximum hash value. This ensures that the test set will remain
consistent across multiple runs, even if we refresh the dataset.

\textbf{Since \texttt{parcelid} is a unique identifier for each instance
in the housing dataset, we can use it to implement the hash strategy
outlined above.}

    \begin{tcolorbox}[breakable, size=fbox, boxrule=1pt, pad at break*=1mm,colback=cellbackground, colframe=cellborder]
\prompt{In}{incolor}{13}{\boxspacing}
\begin{Verbatim}[commandchars=\\\{\}]
\PY{k+kn}{from} \PY{n+nn}{zlib} \PY{k+kn}{import} \PY{n}{crc32}
\PY{k+kn}{from} \PY{n+nn}{sklearn}\PY{n+nn}{.}\PY{n+nn}{model\PYZus{}selection} \PY{k+kn}{import} \PY{n}{train\PYZus{}test\PYZus{}split} 

\PY{k}{def} \PY{n+nf}{test\PYZus{}set\PYZus{}check}\PY{p}{(}\PY{n}{identifier}\PY{p}{,} \PY{n}{test\PYZus{}ratio}\PY{p}{)}\PY{p}{:}
    \PY{c+c1}{\PYZsh{} hash function}
    \PY{k}{return} \PY{n}{crc32}\PY{p}{(}\PY{n}{np}\PY{o}{.}\PY{n}{int64}\PY{p}{(}\PY{n}{identifier}\PY{p}{)}\PY{p}{)} \PY{o}{\PYZam{}} \PY{l+m+mh}{0xffffffff} \PY{o}{\PYZlt{}} \PY{n}{test\PYZus{}ratio} \PY{o}{*} \PY{l+m+mi}{2}\PY{o}{*}\PY{o}{*}\PY{l+m+mi}{32}

\PY{k}{def} \PY{n+nf}{split\PYZus{}train\PYZus{}test\PYZus{}by\PYZus{}id}\PY{p}{(}\PY{n}{data}\PY{p}{,} \PY{n}{test\PYZus{}ratio}\PY{p}{,} \PY{n}{id\PYZus{}column}\PY{p}{)}\PY{p}{:}
    \PY{n}{ids} \PY{o}{=} \PY{n}{data}\PY{p}{[}\PY{n}{id\PYZus{}column}\PY{p}{]}
    \PY{n}{in\PYZus{}test\PYZus{}set} \PY{o}{=} \PY{n}{ids}\PY{o}{.}\PY{n}{apply}\PY{p}{(}\PY{k}{lambda} \PY{n}{id\PYZus{}}\PY{p}{:} \PY{n}{test\PYZus{}set\PYZus{}check}\PY{p}{(}\PY{n}{id\PYZus{}}\PY{p}{,} \PY{n}{test\PYZus{}ratio}\PY{p}{)}\PY{p}{)}
    
    \PY{n}{train\PYZus{}set} \PY{o}{=} \PY{n}{data}\PY{o}{.}\PY{n}{loc}\PY{p}{[}\PY{o}{\PYZti{}}\PY{n}{in\PYZus{}test\PYZus{}set}\PY{p}{]}
    \PY{n}{test\PYZus{}set} \PY{o}{=} \PY{n}{data}\PY{o}{.}\PY{n}{loc}\PY{p}{[}\PY{n}{in\PYZus{}test\PYZus{}set}\PY{p}{]}
    
    \PY{n}{X\PYZus{}train} \PY{o}{=} \PY{n}{train\PYZus{}set}\PY{o}{.}\PY{n}{drop}\PY{p}{(}\PY{l+s+s2}{\PYZdq{}}\PY{l+s+s2}{logerror}\PY{l+s+s2}{\PYZdq{}}\PY{p}{,} \PY{n}{axis}\PY{o}{=}\PY{l+m+mi}{1}\PY{p}{)}
    \PY{n}{y\PYZus{}train} \PY{o}{=} \PY{n}{train\PYZus{}set}\PY{p}{[}\PY{l+s+s2}{\PYZdq{}}\PY{l+s+s2}{logerror}\PY{l+s+s2}{\PYZdq{}}\PY{p}{]}\PY{o}{.}\PY{n}{copy}\PY{p}{(}\PY{p}{)}
    \PY{n}{X\PYZus{}test} \PY{o}{=} \PY{n}{test\PYZus{}set}\PY{o}{.}\PY{n}{drop}\PY{p}{(}\PY{l+s+s2}{\PYZdq{}}\PY{l+s+s2}{logerror}\PY{l+s+s2}{\PYZdq{}}\PY{p}{,} \PY{n}{axis}\PY{o}{=}\PY{l+m+mi}{1}\PY{p}{)}
    \PY{n}{y\PYZus{}test} \PY{o}{=} \PY{n}{test\PYZus{}set}\PY{p}{[}\PY{l+s+s2}{\PYZdq{}}\PY{l+s+s2}{logerror}\PY{l+s+s2}{\PYZdq{}}\PY{p}{]}\PY{o}{.}\PY{n}{copy}\PY{p}{(}\PY{p}{)}
    \PY{k}{return} \PY{n}{X\PYZus{}train}\PY{p}{,} \PY{n}{X\PYZus{}test}\PY{p}{,} \PY{n}{y\PYZus{}train}\PY{p}{,} \PY{n}{y\PYZus{}test}

\PY{n}{X\PYZus{}other}\PY{p}{,} \PY{n}{X\PYZus{}test}\PY{p}{,} \PY{n}{y\PYZus{}other}\PY{p}{,} \PY{n}{y\PYZus{}test} \PY{o}{=} \PY{n}{split\PYZus{}train\PYZus{}test\PYZus{}by\PYZus{}id}\PY{p}{(}\PY{n}{df}\PY{p}{,} \PY{l+m+mf}{0.1}\PY{p}{,} \PY{l+s+s2}{\PYZdq{}}\PY{l+s+s2}{parcelid}\PY{l+s+s2}{\PYZdq{}}\PY{p}{)}
\PY{n+nb}{print}\PY{p}{(}\PY{l+s+sa}{f}\PY{l+s+s2}{\PYZdq{}}\PY{l+s+s2}{Other Dataset Shape: }\PY{l+s+si}{\PYZob{}}\PY{n}{X\PYZus{}other}\PY{o}{.}\PY{n}{shape}\PY{l+s+si}{\PYZcb{}}\PY{l+s+s2}{; Test Dataset Shape: }\PY{l+s+si}{\PYZob{}}\PY{n}{X\PYZus{}test}\PY{o}{.}\PY{n}{shape}\PY{l+s+si}{\PYZcb{}}\PY{l+s+s2}{\PYZdq{}}\PY{p}{)}
\PY{n+nb}{print}\PY{p}{(}\PY{l+s+sa}{f}\PY{l+s+s2}{\PYZdq{}}\PY{l+s+s2}{Other Target Shape: }\PY{l+s+si}{\PYZob{}}\PY{n}{y\PYZus{}other}\PY{o}{.}\PY{n}{shape}\PY{l+s+si}{\PYZcb{}}\PY{l+s+s2}{; Test Target Shape: }\PY{l+s+si}{\PYZob{}}\PY{n}{y\PYZus{}test}\PY{o}{.}\PY{n}{shape}\PY{l+s+si}{\PYZcb{}}\PY{l+s+s2}{\PYZdq{}}\PY{p}{)}
\end{Verbatim}
\end{tcolorbox}

    \begin{Verbatim}[commandchars=\\\{\}]
Other Dataset Shape: (146781, 59); Test Dataset Shape: (16271, 59)
Other Target Shape: (146781,); Test Target Shape: (16271,)
    \end{Verbatim}

    Next step is to split \texttt{X\_train,\ y\_train} into Training and
Validation Datasets. This is because: - Test set is kept hidden until
the \textbf{final} step when the fully tuned machine learning algorithm
is ready for deployment.

    \begin{tcolorbox}[breakable, size=fbox, boxrule=1pt, pad at break*=1mm,colback=cellbackground, colframe=cellborder]
\prompt{In}{incolor}{14}{\boxspacing}
\begin{Verbatim}[commandchars=\\\{\}]
\PY{n}{X\PYZus{}train}\PY{p}{,} \PY{n}{X\PYZus{}val}\PY{p}{,} \PY{n}{y\PYZus{}train}\PY{p}{,} \PY{n}{y\PYZus{}val} \PY{o}{=} \PY{n}{train\PYZus{}test\PYZus{}split}\PY{p}{(}\PY{n}{X\PYZus{}other}\PY{p}{,} \PY{n}{y\PYZus{}other}\PY{p}{,} \PY{n}{train\PYZus{}size}\PY{o}{=}\PY{l+m+mf}{0.9}\PY{p}{,} \PY{n}{random\PYZus{}state}\PY{o}{=}\PY{l+m+mi}{42}\PY{p}{)}
\PY{n+nb}{print}\PY{p}{(}\PY{l+s+sa}{f}\PY{l+s+s2}{\PYZdq{}}\PY{l+s+s2}{Training Dataset Shape: }\PY{l+s+si}{\PYZob{}}\PY{n}{X\PYZus{}train}\PY{o}{.}\PY{n}{shape}\PY{l+s+si}{\PYZcb{}}\PY{l+s+s2}{\PYZdq{}}\PY{p}{)}    \PY{c+c1}{\PYZsh{} 81\PYZpc{} of instances are in training }
\PY{n+nb}{print}\PY{p}{(}\PY{l+s+sa}{f}\PY{l+s+s2}{\PYZdq{}}\PY{l+s+s2}{Test Dataset Shape: }\PY{l+s+si}{\PYZob{}}\PY{n}{X\PYZus{}test}\PY{o}{.}\PY{n}{shape}\PY{l+s+si}{\PYZcb{}}\PY{l+s+s2}{\PYZdq{}}\PY{p}{)}         \PY{c+c1}{\PYZsh{} 10\PYZpc{} of instances are in test }
\PY{n+nb}{print}\PY{p}{(}\PY{l+s+sa}{f}\PY{l+s+s2}{\PYZdq{}}\PY{l+s+s2}{Validation Dataset Shape: }\PY{l+s+si}{\PYZob{}}\PY{n}{X\PYZus{}val}\PY{o}{.}\PY{n}{shape}\PY{l+s+si}{\PYZcb{}}\PY{l+s+s2}{\PYZdq{}}\PY{p}{)}    \PY{c+c1}{\PYZsh{} 9\PYZpc{} of instances are in validation }
\end{Verbatim}
\end{tcolorbox}

    \begin{Verbatim}[commandchars=\\\{\}]
Training Dataset Shape: (132102, 59)
Test Dataset Shape: (16271, 59)
Validation Dataset Shape: (14679, 59)
    \end{Verbatim}

    \begin{tcolorbox}[breakable, size=fbox, boxrule=1pt, pad at break*=1mm,colback=cellbackground, colframe=cellborder]
\prompt{In}{incolor}{15}{\boxspacing}
\begin{Verbatim}[commandchars=\\\{\}]
\PY{k}{del} \PY{n}{all\PYZus{}properties}\PY{p}{,} \PY{n}{df}\PY{p}{;} \PY{n}{gc}\PY{o}{.}\PY{n}{collect}\PY{p}{(}\PY{p}{)}
\end{Verbatim}
\end{tcolorbox}

            \begin{tcolorbox}[breakable, size=fbox, boxrule=.5pt, pad at break*=1mm, opacityfill=0]
\prompt{Out}{outcolor}{15}{\boxspacing}
\begin{Verbatim}[commandchars=\\\{\}]
85834
\end{Verbatim}
\end{tcolorbox}
        
    \begin{tcolorbox}[breakable, size=fbox, boxrule=1pt, pad at break*=1mm,colback=cellbackground, colframe=cellborder]
\prompt{In}{incolor}{16}{\boxspacing}
\begin{Verbatim}[commandchars=\\\{\}]
\PY{n}{X\PYZus{}temp} \PY{o}{=} \PY{n}{X\PYZus{}train}\PY{o}{.}\PY{n}{copy}\PY{p}{(}\PY{p}{)}
\end{Verbatim}
\end{tcolorbox}

    \begin{tcolorbox}[breakable, size=fbox, boxrule=1pt, pad at break*=1mm,colback=cellbackground, colframe=cellborder]
\prompt{In}{incolor}{17}{\boxspacing}
\begin{Verbatim}[commandchars=\\\{\}]
\PY{n}{results} \PY{o}{=} \PY{p}{\PYZob{}}\PY{p}{\PYZcb{}}
\end{Verbatim}
\end{tcolorbox}

    \hypertarget{data-preprocessing-pipelines}{%
\section{3 - Data Preprocessing
Pipelines}\label{data-preprocessing-pipelines}}

    In particular these steps refers to Linear Regression pipeline

    \hypertarget{missing-data}{%
\subsubsection{Missing Data}\label{missing-data}}

    \begin{tcolorbox}[breakable, size=fbox, boxrule=1pt, pad at break*=1mm,colback=cellbackground, colframe=cellborder]
\prompt{In}{incolor}{18}{\boxspacing}
\begin{Verbatim}[commandchars=\\\{\}]
\PY{n}{all\PYZus{}data\PYZus{}na} \PY{o}{=} \PY{p}{(}\PY{n}{X\PYZus{}train}\PY{o}{.}\PY{n}{isnull}\PY{p}{(}\PY{p}{)}\PY{o}{.}\PY{n}{sum}\PY{p}{(}\PY{p}{)} \PY{o}{/} \PY{n+nb}{len}\PY{p}{(}\PY{n}{X\PYZus{}train}\PY{p}{)}\PY{p}{)} \PY{o}{*} \PY{l+m+mi}{100}
\PY{n}{all\PYZus{}data\PYZus{}na} \PY{o}{=} \PY{n}{all\PYZus{}data\PYZus{}na}\PY{o}{.}\PY{n}{drop}\PY{p}{(}\PY{n}{all\PYZus{}data\PYZus{}na}\PY{p}{[}\PY{n}{all\PYZus{}data\PYZus{}na} \PY{o}{==} \PY{l+m+mi}{0}\PY{p}{]}\PY{o}{.}\PY{n}{index}\PY{p}{)}\PY{o}{.}\PY{n}{sort\PYZus{}values}\PY{p}{(}\PY{n}{ascending}\PY{o}{=}\PY{k+kc}{False}\PY{p}{)}
\PY{n}{missing\PYZus{}data} \PY{o}{=} \PY{n}{pd}\PY{o}{.}\PY{n}{DataFrame}\PY{p}{(}\PY{p}{\PYZob{}}\PY{l+s+s1}{\PYZsq{}}\PY{l+s+s1}{Missing Ratio}\PY{l+s+s1}{\PYZsq{}} \PY{p}{:}\PY{n}{all\PYZus{}data\PYZus{}na}\PY{p}{\PYZcb{}}\PY{p}{)}
\PY{n}{missing\PYZus{}data}
\end{Verbatim}
\end{tcolorbox}

            \begin{tcolorbox}[breakable, size=fbox, boxrule=.5pt, pad at break*=1mm, opacityfill=0]
\prompt{Out}{outcolor}{18}{\boxspacing}
\begin{Verbatim}[commandchars=\\\{\}]
                              Missing Ratio
buildingclasstypeid               99.985617
finishedsquarefeet13              99.960636
basementsqft                      99.943983
storytypeid                       99.943983
yardbuildingsqft26                99.902348
fireplaceflag                     99.765333
architecturalstyletypeid          99.719913
typeconstructiontypeid            99.687363
finishedsquarefeet6               99.551104
decktypeid                        99.246794
pooltypeid10                      99.020454
poolsizesum                       98.884953
pooltypeid2                       98.641958
hashottuborspa                    97.662412
taxdelinquencyflag                97.316468
taxdelinquencyyear                97.316468
yardbuildingsqft17                96.944028
finishedsquarefeet15              96.239270
finishedsquarefeet50              92.234031
finishedfloor1squarefeet          92.234031
fireplacecnt                      89.268141
threequarterbathnbr               86.742820
pooltypeid7                       81.019212
poolcnt                           79.648302
numberofstories                   77.203979
airconditioningtypeid             67.753705
garagetotalsqft                   66.727226
garagecarcnt                      66.727226
regionidneighborhood              60.247385
heatingorsystemtypeid             37.007767
buildingqualitytypeid             36.309821
propertyzoningdesc                35.400675
unitcnt                           35.242464
lotsizesquarefeet                 11.087644
finishedsquarefeet12               4.747846
regionidcity                       1.982559
calculatedbathnbr                  1.009069
fullbathcnt                        1.009069
yearbuilt                          0.591967
censustractandblock                0.514754
calculatedfinishedsquarefeet       0.498857
structuretaxvaluedollarcnt         0.301282
regionidzip                        0.064344
taxamount                          0.025738
taxvaluedollarcnt                  0.020439
landtaxvaluedollarcnt              0.020439
propertycountylandusecode          0.019682
roomcnt                            0.018925
propertylandusetypeid              0.018925
fips                               0.018925
regionidcounty                     0.018925
latitude                           0.018925
longitude                          0.018925
rawcensustractandblock             0.018925
assessmentyear                     0.018925
bedroomcnt                         0.018925
bathroomcnt                        0.018925
\end{Verbatim}
\end{tcolorbox}
        
    \hypertarget{drop-candidates}{%
\subsubsection{Drop Candidates}\label{drop-candidates}}

The following variables are dropped.

Over 90\% missing values: - \textbf{finishedsquarefeet13}: Over 99\% of
the dataset is missing values. - \textbf{finishedsquarefeet15}: Over
96\% of the dataset is missing values. -
\textbf{finishedfloor1squarefeet}: Over 92\% of the dataset is missing
values. - \textbf{finishedsquarefeet50}: Over 92\% of the dataset is
missing values. - \textbf{storytypeid}: Over 99\% of the dataset is
missing values. - \textbf{buildingclasstypeid}: Over 99.8\% of the
dataset is missing values. - \textbf{architecturalstyletypeid}: Over
99\% of the dataset is missing values. -
\textbf{typeconstructiontypeid}: Over 99\% of the dataset is missing
values. - \textbf{finishedsquarefeet6}: Over 99\% of the dataset is
missing values. - \textbf{basementsqft, yardbuildingsqft26}: Over 96\%
of the dataset is missing values. - \textbf{taxdelinquencyyear}: Over
97\% of the dataset is missing values.

    \begin{itemize}
\tightlist
\item
  \textbf{numberofstories}: With over 77\% of the missing values and no
  one value dominating the variable distribution, it is impractical to
  impute.
\end{itemize}

    \begin{tcolorbox}[breakable, size=fbox, boxrule=1pt, pad at break*=1mm,colback=cellbackground, colframe=cellborder]
\prompt{In}{incolor}{19}{\boxspacing}
\begin{Verbatim}[commandchars=\\\{\}]
\PY{n}{utils}\PY{o}{.}\PY{n}{plot\PYZus{}variable}\PY{p}{(}\PY{n}{X\PYZus{}train}\PY{o}{.}\PY{n}{numberofstories}\PY{o}{.}\PY{n}{dropna}\PY{p}{(}\PY{p}{)}\PY{p}{)}
\end{Verbatim}
\end{tcolorbox}

    \begin{Verbatim}[commandchars=\\\{\}]

 mu = 1.44 and sigma = 0.54

    \end{Verbatim}

    \begin{center}
    \adjustimage{max size={0.9\linewidth}{0.9\paperheight}}{output_31_1.png}
    \end{center}
    { \hspace*{\fill} \\}
    
    \begin{center}
    \adjustimage{max size={0.9\linewidth}{0.9\paperheight}}{output_31_2.png}
    \end{center}
    { \hspace*{\fill} \\}
    
    \begin{itemize}
\item
  \textbf{assessmentyear}: 2015 for 2016's properties and 2016 for
  2017's properties. So, for now we drop it.
\item
  \textbf{parcelid, transactiondate}: These variables are not available
  when we trying to predict target variable \texttt{logerror}
\end{itemize}

    \begin{itemize}
\tightlist
\item
  \textbf{rawcensustractandblock}: A wikipedia search revealed: Census
  tracts represent the smallest territorial unit for which population
  data are available in many countries. In the United States, census
  tracts are subdivided into block groups and census blocks. In the
  U.S., census tracts are ``designed to be relatively homogeneous units
  with respect to population characteristics, economic status, and
  living conditions'' and ``average about 4,000 inhabitants''.
  Impractical to impute. Probably we want to do splitting like described
  above, but before doing this, it is better to do further research
\item
  \textbf{censustractandblock}: Same as above.
\end{itemize}

    \hypertarget{duplicate-features}{%
\paragraph{Duplicate Features}\label{duplicate-features}}

\begin{itemize}
\tightlist
\item
  \textbf{pooltypeid10, hashottuborspa}: Duplicate information is
  present in \texttt{pooltypeid2} feature.
\item
  \textbf{pooltypeid7}: Data description states `Pool without Hot Tub',
  duplicate information is present in \texttt{pooltypeid2} feature which
  is boolean for `Pool with Spa/Hot Tub'
\item
  \textbf{fireplaceflag}: Duplicate information is present in
  \texttt{fireplacecnt} feature with \texttt{fireplaceflag} having a
  higher missing ratio.
\item
  \textbf{calculatedbathnbr, threequarterbathnbr, fullbathcnt}:
  Duplicate information is present in \texttt{bathroomcnt} which has a
  lower missing ratio
\item
  \textbf{finishedsquarefeet12}: Duplicate information in
  \texttt{calculatedfinishedsquarefeet}.
\item
  \textbf{taxvaluedollarcnt}: Duplicate information from the sum of
  \texttt{structuretaxvaluedollarcnt} and \texttt{landtaxvaluedollarcnt}
\item
  \textbf{propertyzoningdesc, propertycountylandusecode}:
  \texttt{propertylandusetypeid} already provides similar information.
  In addition, this variable has over 2300 unique values - drastically
  increasing dataset cardinality.
\item
  \textbf{regionidneighborhood, regionidzip, regionidcity}: With over
  60\% of the dataset missing values and 500+ unique values, there are
  better region based features such as
  \texttt{regionidcounty,\ latitude,\ longitude} to obtain this
  information
\end{itemize}

    \begin{itemize}
\tightlist
\item
  \textbf{roomcnt}: Shows inconsistent data with majority of properties
  having 0 rooms in the principal residence. We will use bedroom and
  bathroom count.
\end{itemize}

    \begin{tcolorbox}[breakable, size=fbox, boxrule=1pt, pad at break*=1mm,colback=cellbackground, colframe=cellborder]
\prompt{In}{incolor}{20}{\boxspacing}
\begin{Verbatim}[commandchars=\\\{\}]
\PY{n}{X\PYZus{}train}\PY{o}{.}\PY{n}{roomcnt}\PY{o}{.}\PY{n}{hist}\PY{p}{(}\PY{n}{bins}\PY{o}{=}\PY{l+m+mi}{100}\PY{p}{,} \PY{n}{figsize}\PY{o}{=}\PY{p}{(}\PY{l+m+mi}{8}\PY{p}{,}\PY{l+m+mi}{5}\PY{p}{)}\PY{p}{)}
\end{Verbatim}
\end{tcolorbox}

            \begin{tcolorbox}[breakable, size=fbox, boxrule=.5pt, pad at break*=1mm, opacityfill=0]
\prompt{Out}{outcolor}{20}{\boxspacing}
\begin{Verbatim}[commandchars=\\\{\}]
<AxesSubplot:>
\end{Verbatim}
\end{tcolorbox}
        
    \begin{center}
    \adjustimage{max size={0.9\linewidth}{0.9\paperheight}}{output_36_1.png}
    \end{center}
    { \hspace*{\fill} \\}
    
    \hypertarget{dropping-features-pipeline}{%
\subsection{Dropping Features
Pipeline}\label{dropping-features-pipeline}}

    \begin{tcolorbox}[breakable, size=fbox, boxrule=1pt, pad at break*=1mm,colback=cellbackground, colframe=cellborder]
\prompt{In}{incolor}{21}{\boxspacing}
\begin{Verbatim}[commandchars=\\\{\}]
\PY{k+kn}{from} \PY{n+nn}{sklearn}\PY{n+nn}{.}\PY{n+nn}{base} \PY{k+kn}{import} \PY{n}{BaseEstimator}\PY{p}{,} \PY{n}{TransformerMixin}

\PY{n}{lin\PYZus{}reg\PYZus{}drop\PYZus{}vars} \PY{o}{=} \PY{p}{[}\PY{l+s+s2}{\PYZdq{}}\PY{l+s+s2}{finishedsquarefeet13}\PY{l+s+s2}{\PYZdq{}}\PY{p}{,} \PY{l+s+s2}{\PYZdq{}}\PY{l+s+s2}{finishedsquarefeet15}\PY{l+s+s2}{\PYZdq{}}\PY{p}{,} \PY{l+s+s2}{\PYZdq{}}\PY{l+s+s2}{finishedfloor1squarefeet}\PY{l+s+s2}{\PYZdq{}}\PY{p}{,} \PY{l+s+s2}{\PYZdq{}}\PY{l+s+s2}{finishedsquarefeet50}\PY{l+s+s2}{\PYZdq{}}\PY{p}{,}
             \PY{l+s+s2}{\PYZdq{}}\PY{l+s+s2}{storytypeid}\PY{l+s+s2}{\PYZdq{}}\PY{p}{,} \PY{l+s+s2}{\PYZdq{}}\PY{l+s+s2}{architecturalstyletypeid}\PY{l+s+s2}{\PYZdq{}}\PY{p}{,} \PY{l+s+s2}{\PYZdq{}}\PY{l+s+s2}{buildingclasstypeid}\PY{l+s+s2}{\PYZdq{}}\PY{p}{,} \PY{l+s+s2}{\PYZdq{}}\PY{l+s+s2}{typeconstructiontypeid}\PY{l+s+s2}{\PYZdq{}}\PY{p}{,} \PY{l+s+s2}{\PYZdq{}}\PY{l+s+s2}{finishedsquarefeet6}\PY{l+s+s2}{\PYZdq{}}\PY{p}{,}
             \PY{l+s+s2}{\PYZdq{}}\PY{l+s+s2}{pooltypeid10}\PY{l+s+s2}{\PYZdq{}}\PY{p}{,} \PY{l+s+s2}{\PYZdq{}}\PY{l+s+s2}{hashottuborspa}\PY{l+s+s2}{\PYZdq{}}\PY{p}{,} \PY{l+s+s2}{\PYZdq{}}\PY{l+s+s2}{fireplaceflag}\PY{l+s+s2}{\PYZdq{}}\PY{p}{,} \PY{l+s+s2}{\PYZdq{}}\PY{l+s+s2}{threequarterbathnbr}\PY{l+s+s2}{\PYZdq{}}\PY{p}{,} \PY{l+s+s2}{\PYZdq{}}\PY{l+s+s2}{calculatedbathnbr}\PY{l+s+s2}{\PYZdq{}}\PY{p}{,}
             \PY{l+s+s2}{\PYZdq{}}\PY{l+s+s2}{fullbathcnt}\PY{l+s+s2}{\PYZdq{}}\PY{p}{,} \PY{l+s+s2}{\PYZdq{}}\PY{l+s+s2}{numberofstories}\PY{l+s+s2}{\PYZdq{}}\PY{p}{,} \PY{l+s+s2}{\PYZdq{}}\PY{l+s+s2}{censustractandblock}\PY{l+s+s2}{\PYZdq{}}\PY{p}{,} \PY{l+s+s2}{\PYZdq{}}\PY{l+s+s2}{rawcensustractandblock}\PY{l+s+s2}{\PYZdq{}}\PY{p}{,}
             \PY{l+s+s2}{\PYZdq{}}\PY{l+s+s2}{finishedsquarefeet12}\PY{l+s+s2}{\PYZdq{}}\PY{p}{,} \PY{l+s+s2}{\PYZdq{}}\PY{l+s+s2}{taxvaluedollarcnt}\PY{l+s+s2}{\PYZdq{}}\PY{p}{,} \PY{l+s+s2}{\PYZdq{}}\PY{l+s+s2}{taxamount}\PY{l+s+s2}{\PYZdq{}}\PY{p}{,} \PY{l+s+s2}{\PYZdq{}}\PY{l+s+s2}{assessmentyear}\PY{l+s+s2}{\PYZdq{}}\PY{p}{,} \PY{l+s+s2}{\PYZdq{}}\PY{l+s+s2}{roomcnt}\PY{l+s+s2}{\PYZdq{}}\PY{p}{,}
             \PY{l+s+s2}{\PYZdq{}}\PY{l+s+s2}{propertyzoningdesc}\PY{l+s+s2}{\PYZdq{}}\PY{p}{,} \PY{l+s+s2}{\PYZdq{}}\PY{l+s+s2}{regionidneighborhood}\PY{l+s+s2}{\PYZdq{}}\PY{p}{,} \PY{l+s+s2}{\PYZdq{}}\PY{l+s+s2}{regionidzip}\PY{l+s+s2}{\PYZdq{}}\PY{p}{,} \PY{l+s+s2}{\PYZdq{}}\PY{l+s+s2}{taxdelinquencyyear}\PY{l+s+s2}{\PYZdq{}}\PY{p}{,}
             \PY{l+s+s2}{\PYZdq{}}\PY{l+s+s2}{propertycountylandusecode}\PY{l+s+s2}{\PYZdq{}}\PY{p}{,} \PY{l+s+s2}{\PYZdq{}}\PY{l+s+s2}{regionidcity}\PY{l+s+s2}{\PYZdq{}}\PY{p}{,} \PY{l+s+s2}{\PYZdq{}}\PY{l+s+s2}{parcelid}\PY{l+s+s2}{\PYZdq{}}\PY{p}{,} \PY{l+s+s2}{\PYZdq{}}\PY{l+s+s2}{basementsqft}\PY{l+s+s2}{\PYZdq{}}\PY{p}{,} \PY{l+s+s2}{\PYZdq{}}\PY{l+s+s2}{yardbuildingsqft26}\PY{l+s+s2}{\PYZdq{}}\PY{p}{,} \PY{l+s+s2}{\PYZdq{}}\PY{l+s+s2}{transactiondate}\PY{l+s+s2}{\PYZdq{}}
            \PY{p}{]}

\PY{n}{feat\PYZus{}dropper} \PY{o}{=} \PY{n}{utils}\PY{o}{.}\PY{n}{FeatureDropper}\PY{p}{(}\PY{n}{features\PYZus{}to\PYZus{}drop}\PY{o}{=}\PY{n}{lin\PYZus{}reg\PYZus{}drop\PYZus{}vars}\PY{p}{)}
\PY{n}{X\PYZus{}temp} \PY{o}{=} \PY{n}{feat\PYZus{}dropper}\PY{o}{.}\PY{n}{fit\PYZus{}transform}\PY{p}{(}\PY{n}{X\PYZus{}temp}\PY{p}{)}
\end{Verbatim}
\end{tcolorbox}

    \hypertarget{data-imputation-pipeline}{%
\subsection{Data Imputation Pipeline}\label{data-imputation-pipeline}}

There are two main types of data imputation: 1) \textbf{Univariate
Imputation}: Impute values in a feature using only non-missing values in
that feature only. Examples include calculating the mean/median/mode of
a specific variable such as \texttt{lot\_size} from all non-missing
values and imputing the calculated value for missing \texttt{lot\_size}
rows.

\begin{enumerate}
\def\labelenumi{\arabic{enumi})}
\setcounter{enumi}{1}
\tightlist
\item
  \textbf{Multivariate Imputation}: Multivariate imputation algorithms
  use the entire set of available feature dimensions to estimate the
  missing values (e.g.~impute.IterativeImputer). Basically, the purpose
  of multivariate imputation is to use other features (columns) in the
  dataset to predict the missing value(s) in the current feature.
\end{enumerate}

    \hypertarget{univariate-imputation}{%
\subsection{Univariate Imputation}\label{univariate-imputation}}

\hypertarget{none-imputation-features}{%
\subsubsection{0/None Imputation
Features}\label{none-imputation-features}}

Based on the data descriptions of the following features, missing values
most likely indicate the property missing the specific feature (eg: no
basement, no shed, no pool, etc.). Thus, the imputed values in either
\texttt{0}, \texttt{None}, etc. depending on the variable type.

\textbf{0 Imputation}

\begin{itemize}
\tightlist
\item
  \textbf{yardbuildingsqft17}: Data description says `Patio in yard'.
  Missing values are likely zero for having no patio in yard.
\item
  \textbf{fireplacecnt}: Missing values must indicate no fireplace
  present in the unit, thus imputing \texttt{0} for all missing values.
\item
  \textbf{poolcnt}: All values are \texttt{1} in data indicating one
  pool is present, missing values must be \texttt{0} indicating
  otherwise.
\item
  \textbf{poolsizesum}: All missing values indicate no pool on property,
  thus impute \texttt{0} for sqaure footage of all pools.
\item
  \textbf{pooltypeid2}: All values are \texttt{1} in data indicating a
  pool with spa/hot tub is present, missing values must be \texttt{0}
  indicating otherwise.
\item
  \textbf{pooltypeid7}: All values are \texttt{1} in data indicating a
  pool without hot tub is present, missing values must be \texttt{0}
  indicating otherwise.
\item
  \textbf{hashottuborspa}: All values are \texttt{1} in data indicating
  a spa/hot tub is present, missing values must be \texttt{0} indicating
  no hot tub/spa.
\item
  \textbf{decktypeid}: Same value in data indicating a deck is present,
  missing values must be \texttt{0} indicating no deck.
\item
  \textbf{taxdelinquencyflag}: All values are \texttt{Y} in data for
  properties that are tax delinquent implying all missing values must be
  \texttt{N} or \texttt{0} for easier handling.
\item
  \textbf{garagecarcnt}: No properties have \texttt{0} as the garage car
  count, indicating the missing values are all properties without a
  garage.
\item
  \textbf{garagetotalsqft}: All properties with missing
  \texttt{garagecarcnt} are also missing the square feet, indicating the
  properties do not have a garage.
\end{itemize}

\hypertarget{mode-imputation-features}{%
\subsubsection{Mode Imputation
Features}\label{mode-imputation-features}}

The following features are imputed with the most frequent value (mode)
due to the majority of the dataset having that specific value. -
\textbf{airconditioningtypeid}: Majority of the properties have a
Central air conditioning type. - \textbf{heatingorsystemtypeid}:
Majority of the properties have a Central heating system. -
\textbf{unitcnt}: Majority of the property are built into 1 unit. -
\textbf{fips, propertylandusetypeid, regionidcounty}: With only 0.4\% of
the dataset missing values, imputing the mode is acceptable. -
\textbf{yearbuilt}: Since missing rows is extremely low, mode suffices

\hypertarget{median-imputation-features}{%
\subsubsection{Median Imputation
Features}\label{median-imputation-features}}

The following features are imputing with the 50th percentile value
(median) to best represent the numerical distributions represented by
each features. - \textbf{buildingqualitytypeid}: Overall condition of
the condition from best (lowest) to worst (highest). Thus, imputing the
median for missing values. - \textbf{lotsizesquarefeet}: Continuous
numerical variable for area of the lot - \textbf{bathroomcnt,
bedroomcnt, calculatedfinishedsquarefeet} -
\textbf{structuretaxvaluedollarcnt, landtaxvaluedollarcnt, latitude,
longitude}

    \begin{tcolorbox}[breakable, size=fbox, boxrule=1pt, pad at break*=1mm,colback=cellbackground, colframe=cellborder]
\prompt{In}{incolor}{22}{\boxspacing}
\begin{Verbatim}[commandchars=\\\{\}]
\PY{k+kn}{from} \PY{n+nn}{sklearn}\PY{n+nn}{.}\PY{n+nn}{compose} \PY{k+kn}{import} \PY{n}{ColumnTransformer}
\PY{k+kn}{from} \PY{n+nn}{sklearn}\PY{n+nn}{.}\PY{n+nn}{pipeline} \PY{k+kn}{import} \PY{n}{Pipeline}
\PY{k+kn}{from} \PY{n+nn}{sklearn}\PY{n+nn}{.}\PY{n+nn}{impute} \PY{k+kn}{import} \PY{n}{SimpleImputer}
\PY{k+kn}{from} \PY{n+nn}{sklearn}\PY{n+nn}{.}\PY{n+nn}{preprocessing} \PY{k+kn}{import} \PY{n}{OneHotEncoder}
\PY{k+kn}{from} \PY{n+nn}{sklearn}\PY{n+nn}{.}\PY{n+nn}{preprocessing} \PY{k+kn}{import} \PY{n}{StandardScaler}
\PY{k+kn}{from} \PY{n+nn}{sklearn}\PY{n+nn}{.}\PY{n+nn}{preprocessing} \PY{k+kn}{import} \PY{n}{RobustScaler}
\end{Verbatim}
\end{tcolorbox}

    \begin{tcolorbox}[breakable, size=fbox, boxrule=1pt, pad at break*=1mm,colback=cellbackground, colframe=cellborder]
\prompt{In}{incolor}{23}{\boxspacing}
\begin{Verbatim}[commandchars=\\\{\}]
\PY{n}{impute\PYZus{}0\PYZus{}vars} \PY{o}{=} \PY{p}{[}\PY{l+s+s2}{\PYZdq{}}\PY{l+s+s2}{yardbuildingsqft17}\PY{l+s+s2}{\PYZdq{}}\PY{p}{,} \PY{l+s+s2}{\PYZdq{}}\PY{l+s+s2}{fireplacecnt}\PY{l+s+s2}{\PYZdq{}}\PY{p}{,} \PY{l+s+s2}{\PYZdq{}}\PY{l+s+s2}{poolcnt}\PY{l+s+s2}{\PYZdq{}}\PY{p}{,} \PY{l+s+s2}{\PYZdq{}}\PY{l+s+s2}{garagecarcnt}\PY{l+s+s2}{\PYZdq{}}\PY{p}{,} \PY{l+s+s2}{\PYZdq{}}\PY{l+s+s2}{garagetotalsqft}\PY{l+s+s2}{\PYZdq{}}\PY{p}{,}
                 \PY{l+s+s2}{\PYZdq{}}\PY{l+s+s2}{pooltypeid2}\PY{l+s+s2}{\PYZdq{}}\PY{p}{,} \PY{l+s+s2}{\PYZdq{}}\PY{l+s+s2}{poolsizesum}\PY{l+s+s2}{\PYZdq{}}\PY{p}{,} \PY{l+s+s2}{\PYZdq{}}\PY{l+s+s2}{decktypeid}\PY{l+s+s2}{\PYZdq{}}\PY{p}{,} \PY{l+s+s2}{\PYZdq{}}\PY{l+s+s2}{taxdelinquencyflag}\PY{l+s+s2}{\PYZdq{}}\PY{p}{,}\PY{l+s+s2}{\PYZdq{}}\PY{l+s+s2}{pooltypeid7}\PY{l+s+s2}{\PYZdq{}}\PY{p}{]}

\PY{n}{impute\PYZus{}mode\PYZus{}vars} \PY{o}{=} \PY{p}{[}\PY{l+s+s2}{\PYZdq{}}\PY{l+s+s2}{airconditioningtypeid}\PY{l+s+s2}{\PYZdq{}}\PY{p}{,} \PY{l+s+s2}{\PYZdq{}}\PY{l+s+s2}{heatingorsystemtypeid}\PY{l+s+s2}{\PYZdq{}}\PY{p}{,} \PY{l+s+s2}{\PYZdq{}}\PY{l+s+s2}{unitcnt}\PY{l+s+s2}{\PYZdq{}}\PY{p}{,} \PY{l+s+s2}{\PYZdq{}}\PY{l+s+s2}{fips}\PY{l+s+s2}{\PYZdq{}}\PY{p}{,}
                    \PY{l+s+s2}{\PYZdq{}}\PY{l+s+s2}{propertylandusetypeid}\PY{l+s+s2}{\PYZdq{}}\PY{p}{,} \PY{l+s+s2}{\PYZdq{}}\PY{l+s+s2}{regionidcounty}\PY{l+s+s2}{\PYZdq{}}\PY{p}{,} \PY{l+s+s2}{\PYZdq{}}\PY{l+s+s2}{yearbuilt}\PY{l+s+s2}{\PYZdq{}}\PY{p}{]} 

\PY{n}{impute\PYZus{}median\PYZus{}vars} \PY{o}{=} \PY{p}{[}\PY{l+s+s2}{\PYZdq{}}\PY{l+s+s2}{buildingqualitytypeid}\PY{l+s+s2}{\PYZdq{}}\PY{p}{,} \PY{l+s+s2}{\PYZdq{}}\PY{l+s+s2}{lotsizesquarefeet}\PY{l+s+s2}{\PYZdq{}}\PY{p}{,} \PY{l+s+s2}{\PYZdq{}}\PY{l+s+s2}{bathroomcnt}\PY{l+s+s2}{\PYZdq{}}\PY{p}{,} \PY{l+s+s2}{\PYZdq{}}\PY{l+s+s2}{bedroomcnt}\PY{l+s+s2}{\PYZdq{}}\PY{p}{,} \PY{l+s+s2}{\PYZdq{}}\PY{l+s+s2}{calculatedfinishedsquarefeet}\PY{l+s+s2}{\PYZdq{}}\PY{p}{,}
                      \PY{l+s+s2}{\PYZdq{}}\PY{l+s+s2}{structuretaxvaluedollarcnt}\PY{l+s+s2}{\PYZdq{}}\PY{p}{,} \PY{l+s+s2}{\PYZdq{}}\PY{l+s+s2}{landtaxvaluedollarcnt}\PY{l+s+s2}{\PYZdq{}}\PY{p}{,} \PY{l+s+s2}{\PYZdq{}}\PY{l+s+s2}{latitude}\PY{l+s+s2}{\PYZdq{}}\PY{p}{,} \PY{l+s+s2}{\PYZdq{}}\PY{l+s+s2}{longitude}\PY{l+s+s2}{\PYZdq{}}\PY{p}{]}

\PY{n}{univariate\PYZus{}impute\PYZus{}pipe} \PY{o}{=} \PY{n}{utils}\PY{o}{.}\PY{n}{ColumnTransformer}\PY{p}{(}\PY{p}{[}
        \PY{p}{(}\PY{l+s+s2}{\PYZdq{}}\PY{l+s+s2}{impute\PYZus{}0}\PY{l+s+s2}{\PYZdq{}}\PY{p}{,} \PY{n}{SimpleImputer}\PY{p}{(}\PY{n}{strategy}\PY{o}{=}\PY{l+s+s2}{\PYZdq{}}\PY{l+s+s2}{constant}\PY{l+s+s2}{\PYZdq{}}\PY{p}{,} \PY{n}{fill\PYZus{}value}\PY{o}{=}\PY{l+m+mi}{0}\PY{p}{)}\PY{p}{,} \PY{n}{impute\PYZus{}0\PYZus{}vars}\PY{p}{)}\PY{p}{,}
        \PY{p}{(}\PY{l+s+s2}{\PYZdq{}}\PY{l+s+s2}{impute\PYZus{}mode}\PY{l+s+s2}{\PYZdq{}}\PY{p}{,} \PY{n}{SimpleImputer}\PY{p}{(}\PY{n}{strategy}\PY{o}{=}\PY{l+s+s2}{\PYZdq{}}\PY{l+s+s2}{most\PYZus{}frequent}\PY{l+s+s2}{\PYZdq{}}\PY{p}{)}\PY{p}{,} \PY{n}{impute\PYZus{}mode\PYZus{}vars}\PY{p}{)}\PY{p}{,}
        \PY{p}{(}\PY{l+s+s2}{\PYZdq{}}\PY{l+s+s2}{impute\PYZus{}median}\PY{l+s+s2}{\PYZdq{}}\PY{p}{,} \PY{n}{SimpleImputer}\PY{p}{(}\PY{n}{strategy}\PY{o}{=}\PY{l+s+s2}{\PYZdq{}}\PY{l+s+s2}{median}\PY{l+s+s2}{\PYZdq{}}\PY{p}{)}\PY{p}{,} \PY{n}{impute\PYZus{}median\PYZus{}vars}\PY{p}{)}\PY{p}{,}
    \PY{p}{]}\PY{p}{,}
    \PY{n}{remainder}\PY{o}{=}\PY{l+s+s1}{\PYZsq{}}\PY{l+s+s1}{passthrough}\PY{l+s+s1}{\PYZsq{}}
\PY{p}{)}

\PY{n}{X\PYZus{}temp} \PY{o}{=} \PY{n}{univariate\PYZus{}impute\PYZus{}pipe}\PY{o}{.}\PY{n}{fit\PYZus{}transform}\PY{p}{(}\PY{n}{X\PYZus{}temp}\PY{p}{)}
\end{Verbatim}
\end{tcolorbox}

    \hypertarget{column-names-appender-pipeline}{%
\subsection{Column Names Appender
Pipeline}\label{column-names-appender-pipeline}}

The output of the imputation pipeline is not a Pandas DataFrame but a
NumPy Array. The following pipeline takes as an input the imputation
pipeline and creates a DataFrame from the Numpy Array input.

    \begin{tcolorbox}[breakable, size=fbox, boxrule=1pt, pad at break*=1mm,colback=cellbackground, colframe=cellborder]
\prompt{In}{incolor}{24}{\boxspacing}
\begin{Verbatim}[commandchars=\\\{\}]
\PY{n}{column\PYZus{}appender} \PY{o}{=} \PY{n}{utils}\PY{o}{.}\PY{n}{ColumnNamesAppender}\PY{p}{(}\PY{n}{univariate\PYZus{}impute\PYZus{}pipe}\PY{p}{,} \PY{n}{orig\PYZus{}columns}\PY{o}{=}\PY{n}{X\PYZus{}train}\PY{o}{.}\PY{n}{columns}\PY{p}{,} \PY{n}{num\PYZus{}transformers}\PY{o}{=}\PY{l+m+mi}{3}\PY{p}{)}
\PY{n}{X\PYZus{}temp} \PY{o}{=} \PY{n}{column\PYZus{}appender}\PY{o}{.}\PY{n}{fit\PYZus{}transform}\PY{p}{(}\PY{n}{X\PYZus{}temp}\PY{p}{)}
\end{Verbatim}
\end{tcolorbox}

    \hypertarget{convert-variables-types-pipeline}{%
\subsection{Convert Variables Types
Pipeline}\label{convert-variables-types-pipeline}}

Many categorical and boolean variables are currently encoded as floats,
so we convert them.

    \begin{tcolorbox}[breakable, size=fbox, boxrule=1pt, pad at break*=1mm,colback=cellbackground, colframe=cellborder]
\prompt{In}{incolor}{25}{\boxspacing}
\begin{Verbatim}[commandchars=\\\{\}]
\PY{n}{convert\PYZus{}to\PYZus{}int} \PY{o}{=} \PY{p}{[}\PY{l+s+s2}{\PYZdq{}}\PY{l+s+s2}{yearbuilt}\PY{l+s+s2}{\PYZdq{}}\PY{p}{]} 
\PY{n}{convert\PYZus{}to\PYZus{}string}\PY{o}{=} \PY{p}{[}\PY{l+s+s2}{\PYZdq{}}\PY{l+s+s2}{airconditioningtypeid}\PY{l+s+s2}{\PYZdq{}}\PY{p}{,} \PY{l+s+s2}{\PYZdq{}}\PY{l+s+s2}{heatingorsystemtypeid}\PY{l+s+s2}{\PYZdq{}}\PY{p}{,} \PY{l+s+s2}{\PYZdq{}}\PY{l+s+s2}{fips}\PY{l+s+s2}{\PYZdq{}}\PY{p}{,} \PY{l+s+s2}{\PYZdq{}}\PY{l+s+s2}{propertylandusetypeid}\PY{l+s+s2}{\PYZdq{}}\PY{p}{,} \PY{l+s+s2}{\PYZdq{}}\PY{l+s+s2}{regionidcounty}\PY{l+s+s2}{\PYZdq{}}\PY{p}{,} \PY{l+s+s2}{\PYZdq{}}\PY{l+s+s2}{pooltypeid2}\PY{l+s+s2}{\PYZdq{}}\PY{p}{,} \PY{l+s+s2}{\PYZdq{}}\PY{l+s+s2}{decktypeid}\PY{l+s+s2}{\PYZdq{}}\PY{p}{,} \PY{l+s+s2}{\PYZdq{}}\PY{l+s+s2}{taxdelinquencyflag}\PY{l+s+s2}{\PYZdq{}}\PY{p}{,}\PY{p}{]} 
\PY{n}{convert\PYZus{}to\PYZus{}float}\PY{o}{=} \PY{p}{[}\PY{l+s+s2}{\PYZdq{}}\PY{l+s+s2}{bathroomcnt}\PY{l+s+s2}{\PYZdq{}}\PY{p}{,} \PY{l+s+s2}{\PYZdq{}}\PY{l+s+s2}{bedroomcnt}\PY{l+s+s2}{\PYZdq{}}\PY{p}{,} \PY{l+s+s2}{\PYZdq{}}\PY{l+s+s2}{buildingqualitytypeid}\PY{l+s+s2}{\PYZdq{}}\PY{p}{,} \PY{l+s+s2}{\PYZdq{}}\PY{l+s+s2}{calculatedfinishedsquarefeet}\PY{l+s+s2}{\PYZdq{}}\PY{p}{,}
                  \PY{l+s+s2}{\PYZdq{}}\PY{l+s+s2}{fireplacecnt}\PY{l+s+s2}{\PYZdq{}}\PY{p}{,} \PY{l+s+s2}{\PYZdq{}}\PY{l+s+s2}{garagecarcnt}\PY{l+s+s2}{\PYZdq{}}\PY{p}{,} \PY{l+s+s2}{\PYZdq{}}\PY{l+s+s2}{garagetotalsqft}\PY{l+s+s2}{\PYZdq{}}\PY{p}{,} \PY{l+s+s2}{\PYZdq{}}\PY{l+s+s2}{latitude}\PY{l+s+s2}{\PYZdq{}}\PY{p}{,} \PY{l+s+s2}{\PYZdq{}}\PY{l+s+s2}{longitude}\PY{l+s+s2}{\PYZdq{}}\PY{p}{,} \PY{l+s+s2}{\PYZdq{}}\PY{l+s+s2}{lotsizesquarefeet}\PY{l+s+s2}{\PYZdq{}}\PY{p}{,} \PY{l+s+s2}{\PYZdq{}}\PY{l+s+s2}{poolcnt}\PY{l+s+s2}{\PYZdq{}}\PY{p}{,}
                  \PY{l+s+s2}{\PYZdq{}}\PY{l+s+s2}{poolsizesum}\PY{l+s+s2}{\PYZdq{}}\PY{p}{,} \PY{l+s+s2}{\PYZdq{}}\PY{l+s+s2}{unitcnt}\PY{l+s+s2}{\PYZdq{}}\PY{p}{,} \PY{l+s+s2}{\PYZdq{}}\PY{l+s+s2}{yardbuildingsqft17}\PY{l+s+s2}{\PYZdq{}}\PY{p}{,} \PY{l+s+s2}{\PYZdq{}}\PY{l+s+s2}{structuretaxvaluedollarcnt}\PY{l+s+s2}{\PYZdq{}}\PY{p}{,} \PY{l+s+s2}{\PYZdq{}}\PY{l+s+s2}{landtaxvaluedollarcnt}\PY{l+s+s2}{\PYZdq{}}\PY{p}{]}
    
\PY{c+c1}{\PYZsh{} \PYZsh{} Code to test pipeline}
\PY{n}{feature\PYZus{}type\PYZus{}changer} \PY{o}{=} \PY{n}{utils}\PY{o}{.}\PY{n}{ConvertFeatureType}\PY{p}{(}\PY{n}{convert\PYZus{}to\PYZus{}int}\PY{o}{=}\PY{n}{convert\PYZus{}to\PYZus{}int}\PY{p}{,} \PY{n}{convert\PYZus{}to\PYZus{}string}\PY{o}{=}\PY{n}{convert\PYZus{}to\PYZus{}string}\PY{p}{,} \PY{n}{convert\PYZus{}to\PYZus{}float}\PY{o}{=}\PY{n}{convert\PYZus{}to\PYZus{}float}\PY{p}{)}
\PY{n}{X\PYZus{}temp} \PY{o}{=} \PY{n}{feature\PYZus{}type\PYZus{}changer}\PY{o}{.}\PY{n}{fit\PYZus{}transform}\PY{p}{(}\PY{n}{X\PYZus{}temp}\PY{p}{)}
\end{Verbatim}
\end{tcolorbox}

    \hypertarget{year-feature-creation-pipeline}{%
\subsection{Year Feature Creation
Pipeline}\label{year-feature-creation-pipeline}}

\texttt{1989} is converted into
\texttt{present\_year(2021)\ -\ 1989\ =\ 32}

    \begin{tcolorbox}[breakable, size=fbox, boxrule=1pt, pad at break*=1mm,colback=cellbackground, colframe=cellborder]
\prompt{In}{incolor}{26}{\boxspacing}
\begin{Verbatim}[commandchars=\\\{\}]
\PY{k+kn}{from} \PY{n+nn}{datetime} \PY{k+kn}{import} \PY{n}{date}
\PY{n}{date\PYZus{}features} \PY{o}{=} \PY{p}{\PYZob{}}\PY{l+s+s2}{\PYZdq{}}\PY{l+s+s2}{yearbuilt}\PY{l+s+s2}{\PYZdq{}}\PY{p}{:} \PY{l+s+s2}{\PYZdq{}}\PY{l+s+s2}{house\PYZus{}age}\PY{l+s+s2}{\PYZdq{}}\PY{p}{\PYZcb{}}

\PY{n}{year\PYZus{}feat\PYZus{}creator} \PY{o}{=} \PY{n}{utils}\PY{o}{.}\PY{n}{CreateYearFeatures}\PY{p}{(}\PY{n}{date\PYZus{}features}\PY{o}{=}\PY{n}{date\PYZus{}features}\PY{p}{)}
\PY{n}{X\PYZus{}temp} \PY{o}{=} \PY{n}{year\PYZus{}feat\PYZus{}creator}\PY{o}{.}\PY{n}{fit\PYZus{}transform}\PY{p}{(}\PY{n}{X\PYZus{}temp}\PY{p}{)}
\end{Verbatim}
\end{tcolorbox}

    \hypertarget{one-hot-encoding-categorical-variables-standardizing-numerical-variables}{%
\subsection{One-Hot Encoding Categorical Variables + Standardizing
Numerical
Variables}\label{one-hot-encoding-categorical-variables-standardizing-numerical-variables}}

The following custom transformer uses \texttt{ColumnTransformer} to
perform One-Hot Encoding on Categorical Features and Robust Scaler on
Numerical Features.

    \begin{tcolorbox}[breakable, size=fbox, boxrule=1pt, pad at break*=1mm,colback=cellbackground, colframe=cellborder]
\prompt{In}{incolor}{27}{\boxspacing}
\begin{Verbatim}[commandchars=\\\{\}]
\PY{n}{feature\PYZus{}encoder\PYZus{}scaler} \PY{o}{=} \PY{n}{utils}\PY{o}{.}\PY{n}{FeatureEncoderAndScaler}\PY{p}{(}\PY{p}{)}
\PY{n}{X\PYZus{}temp} \PY{o}{=} \PY{n}{feature\PYZus{}encoder\PYZus{}scaler}\PY{o}{.}\PY{n}{fit\PYZus{}transform}\PY{p}{(}\PY{n}{X\PYZus{}temp}\PY{p}{)}
\end{Verbatim}
\end{tcolorbox}

    \hypertarget{create-polynomial-features-pipeline}{%
\subsection{Create Polynomial Features
Pipeline}\label{create-polynomial-features-pipeline}}

The three new polynomial features are: - \texttt{feature\^{}2} -
\texttt{feature\^{}3} - \texttt{sqrt(feature)}

This transformation is useful for models such as linear regression
compared to more complex models such as Random Forest, GBMs that can
detect non-linear patters within the data without such feature
engineering.

    \begin{tcolorbox}[breakable, size=fbox, boxrule=1pt, pad at break*=1mm,colback=cellbackground, colframe=cellborder]
\prompt{In}{incolor}{28}{\boxspacing}
\begin{Verbatim}[commandchars=\\\{\}]
\PY{n}{corr\PYZus{}df} \PY{o}{=} \PY{n}{X\PYZus{}temp}\PY{o}{.}\PY{n}{copy}\PY{p}{(}\PY{p}{)}
\PY{n}{corr\PYZus{}df}\PY{p}{[}\PY{l+s+s2}{\PYZdq{}}\PY{l+s+s2}{logerror}\PY{l+s+s2}{\PYZdq{}}\PY{p}{]} \PY{o}{=} \PY{n}{y\PYZus{}train}\PY{o}{.}\PY{n}{values}
\PY{n}{corr} \PY{o}{=} \PY{n}{corr\PYZus{}df}\PY{o}{.}\PY{n}{corr}\PY{p}{(}\PY{p}{)}
\PY{n}{most\PYZus{}corr\PYZus{}feat} \PY{o}{=} \PY{n}{corr}\PY{o}{.}\PY{n}{logerror}\PY{o}{.}\PY{n}{abs}\PY{p}{(}\PY{p}{)}\PY{o}{.}\PY{n}{sort\PYZus{}values}\PY{p}{(}\PY{n}{ascending}\PY{o}{=}\PY{k+kc}{False}\PY{p}{)}\PY{p}{[}\PY{l+m+mi}{1}\PY{p}{:}\PY{l+m+mi}{9}\PY{p}{]}\PY{o}{.}\PY{n}{index}
\PY{n}{most\PYZus{}corr\PYZus{}feat}
\end{Verbatim}
\end{tcolorbox}

            \begin{tcolorbox}[breakable, size=fbox, boxrule=.5pt, pad at break*=1mm, opacityfill=0]
\prompt{Out}{outcolor}{28}{\boxspacing}
\begin{Verbatim}[commandchars=\\\{\}]
Index(['num\_scaler\_\_calculatedfinishedsquarefeet', 'num\_scaler\_\_bathroomcnt',
       'num\_scaler\_\_bedroomcnt', 'num\_scaler\_\_structuretaxvaluedollarcnt',
       'num\_scaler\_\_house\_age', 'num\_scaler\_\_garagetotalsqft',
       'num\_scaler\_\_landtaxvaluedollarcnt', 'num\_scaler\_\_garagecarcnt'],
      dtype='object')
\end{Verbatim}
\end{tcolorbox}
        
    \begin{tcolorbox}[breakable, size=fbox, boxrule=1pt, pad at break*=1mm,colback=cellbackground, colframe=cellborder]
\prompt{In}{incolor}{29}{\boxspacing}
\begin{Verbatim}[commandchars=\\\{\}]
\PY{n}{poly\PYZus{}feat\PYZus{}creator} \PY{o}{=} \PY{n}{utils}\PY{o}{.}\PY{n}{CreatePolynomialFeatures}\PY{p}{(}\PY{n}{most\PYZus{}corr\PYZus{}feat}\PY{p}{)}
\PY{n}{X\PYZus{}temp} \PY{o}{=} \PY{n}{poly\PYZus{}feat\PYZus{}creator}\PY{o}{.}\PY{n}{fit\PYZus{}transform}\PY{p}{(}\PY{n}{X\PYZus{}temp}\PY{p}{)}
\end{Verbatim}
\end{tcolorbox}

    \hypertarget{skewed-features-pipeline}{%
\subsection{Skewed Features Pipeline}\label{skewed-features-pipeline}}

Next transformation is applied to numerical features that are highly
skewed (all variables with skewness above the threshold value of 0.75).
We will be performing the \textbf{Box Cox Transformation} using scipy
function \texttt{boxcox1p}.

    \begin{tcolorbox}[breakable, size=fbox, boxrule=1pt, pad at break*=1mm,colback=cellbackground, colframe=cellborder]
\prompt{In}{incolor}{30}{\boxspacing}
\begin{Verbatim}[commandchars=\\\{\}]
\PY{n}{numeric\PYZus{}feats} \PY{o}{=} \PY{n}{X\PYZus{}temp}\PY{o}{.}\PY{n}{dtypes}\PY{p}{[}\PY{n}{X\PYZus{}temp}\PY{o}{.}\PY{n}{dtypes} \PY{o}{==} \PY{l+s+s1}{\PYZsq{}}\PY{l+s+s1}{float}\PY{l+s+s1}{\PYZsq{}}\PY{p}{]}\PY{o}{.}\PY{n}{index}
\PY{n}{skewed\PYZus{}feats} \PY{o}{=} \PY{n}{X\PYZus{}temp}\PY{p}{[}\PY{n}{numeric\PYZus{}feats}\PY{p}{]}\PY{o}{.}\PY{n}{apply}\PY{p}{(}\PY{k}{lambda} \PY{n}{x}\PY{p}{:} \PY{n}{skew}\PY{p}{(}\PY{n}{x}\PY{o}{.}\PY{n}{dropna}\PY{p}{(}\PY{p}{)}\PY{p}{)}\PY{p}{)}\PY{o}{.}\PY{n}{sort\PYZus{}values}\PY{p}{(}\PY{n}{ascending}\PY{o}{=}\PY{k+kc}{False}\PY{p}{)}
\PY{n+nb}{print}\PY{p}{(}\PY{n}{skewed\PYZus{}feats}\PY{p}{[}\PY{p}{:}\PY{l+m+mi}{20}\PY{p}{]}\PY{p}{)}

\PY{n}{skew\PYZus{}transformer} \PY{o}{=} \PY{n}{utils}\PY{o}{.}\PY{n}{BoxCoxSkewedFeatures}\PY{p}{(}\PY{p}{)}
\PY{n}{X\PYZus{}temp} \PY{o}{=} \PY{n}{skew\PYZus{}transformer}\PY{o}{.}\PY{n}{transform}\PY{p}{(}\PY{n}{X\PYZus{}temp}\PY{p}{)}
\end{Verbatim}
\end{tcolorbox}

    \begin{Verbatim}[commandchars=\\\{\}]
num\_scaler\_\_structuretaxvaluedollarcnt-s3      188.246998
num\_scaler\_\_unitcnt                            186.776719
num\_scaler\_\_landtaxvaluedollarcnt-s3           181.553795
num\_scaler\_\_bathroomcnt-s3                     151.889413
num\_scaler\_\_calculatedfinishedsquarefeet-s3    116.428447
num\_scaler\_\_garagetotalsqft-s3                 106.881884
num\_scaler\_\_landtaxvaluedollarcnt-s2           103.260718
num\_scaler\_\_structuretaxvaluedollarcnt-s2       93.976187
num\_scaler\_\_garagecarcnt-s3                     89.126351
num\_scaler\_\_calculatedfinishedsquarefeet-s2     38.796511
num\_scaler\_\_bedroomcnt-s3                       36.400945
num\_scaler\_\_garagetotalsqft-s2                  28.797628
num\_scaler\_\_lotsizesquarefeet                   26.200211
num\_scaler\_\_bathroomcnt-s2                      18.750082
num\_scaler\_\_garagecarcnt-s2                     16.122097
num\_scaler\_\_yardbuildingsqft17                  12.331821
num\_scaler\_\_bedroomcnt-s2                       12.258034
num\_scaler\_\_landtaxvaluedollarcnt               11.760451
num\_scaler\_\_poolsizesum                         10.811301
num\_scaler\_\_structuretaxvaluedollarcnt           9.344524
dtype: float64
    \end{Verbatim}

    \hypertarget{linear-regression-models}{%
\section{4 - Linear Regression Models}\label{linear-regression-models}}

Both plain Linear Regression and Regularized Linear Regression
algorithms will be tested.

    \begin{tcolorbox}[breakable, size=fbox, boxrule=1pt, pad at break*=1mm,colback=cellbackground, colframe=cellborder]
\prompt{In}{incolor}{31}{\boxspacing}
\begin{Verbatim}[commandchars=\\\{\}]
\PY{k+kn}{from} \PY{n+nn}{sklearn}\PY{n+nn}{.}\PY{n+nn}{compose} \PY{k+kn}{import} \PY{n}{ColumnTransformer}
\PY{k+kn}{from} \PY{n+nn}{sklearn}\PY{n+nn}{.}\PY{n+nn}{pipeline} \PY{k+kn}{import} \PY{n}{Pipeline}
\PY{k+kn}{from} \PY{n+nn}{sklearn}\PY{n+nn}{.}\PY{n+nn}{experimental} \PY{k+kn}{import} \PY{n}{enable\PYZus{}iterative\PYZus{}imputer}
\PY{k+kn}{from} \PY{n+nn}{sklearn}\PY{n+nn}{.}\PY{n+nn}{impute} \PY{k+kn}{import} \PY{n}{IterativeImputer}
\PY{k+kn}{from} \PY{n+nn}{sklearn}\PY{n+nn}{.}\PY{n+nn}{impute} \PY{k+kn}{import} \PY{n}{SimpleImputer}
\PY{k+kn}{from} \PY{n+nn}{sklearn}\PY{n+nn}{.}\PY{n+nn}{preprocessing} \PY{k+kn}{import} \PY{n}{OneHotEncoder}
\PY{k+kn}{from} \PY{n+nn}{sklearn}\PY{n+nn}{.}\PY{n+nn}{preprocessing} \PY{k+kn}{import} \PY{n}{StandardScaler}
\PY{k+kn}{from} \PY{n+nn}{sklearn}\PY{n+nn}{.}\PY{n+nn}{preprocessing} \PY{k+kn}{import} \PY{n}{RobustScaler}
\PY{k+kn}{from} \PY{n+nn}{sklearn}\PY{n+nn}{.}\PY{n+nn}{ensemble} \PY{k+kn}{import} \PY{n}{RandomForestRegressor}
\end{Verbatim}
\end{tcolorbox}

    \begin{tcolorbox}[breakable, size=fbox, boxrule=1pt, pad at break*=1mm,colback=cellbackground, colframe=cellborder]
\prompt{In}{incolor}{32}{\boxspacing}
\begin{Verbatim}[commandchars=\\\{\}]
\PY{n}{X\PYZus{}prepared} \PY{o}{=} \PY{n}{X\PYZus{}train}\PY{o}{.}\PY{n}{copy}\PY{p}{(}\PY{p}{)}
\PY{n}{X\PYZus{}prepared\PYZus{}val} \PY{o}{=} \PY{n}{X\PYZus{}val}\PY{o}{.}\PY{n}{copy}\PY{p}{(}\PY{p}{)}
\end{Verbatim}
\end{tcolorbox}

    \begin{tcolorbox}[breakable, size=fbox, boxrule=1pt, pad at break*=1mm,colback=cellbackground, colframe=cellborder]
\prompt{In}{incolor}{33}{\boxspacing}
\begin{Verbatim}[commandchars=\\\{\}]
\PY{c+c1}{\PYZsh{} Feature Dropper Pipeline}
\PY{n}{lin\PYZus{}reg\PYZus{}drop\PYZus{}vars} \PY{o}{=} \PY{p}{[}\PY{l+s+s2}{\PYZdq{}}\PY{l+s+s2}{finishedsquarefeet13}\PY{l+s+s2}{\PYZdq{}}\PY{p}{,} \PY{l+s+s2}{\PYZdq{}}\PY{l+s+s2}{finishedsquarefeet15}\PY{l+s+s2}{\PYZdq{}}\PY{p}{,} \PY{l+s+s2}{\PYZdq{}}\PY{l+s+s2}{finishedfloor1squarefeet}\PY{l+s+s2}{\PYZdq{}}\PY{p}{,} \PY{l+s+s2}{\PYZdq{}}\PY{l+s+s2}{finishedsquarefeet50}\PY{l+s+s2}{\PYZdq{}}\PY{p}{,}
             \PY{l+s+s2}{\PYZdq{}}\PY{l+s+s2}{storytypeid}\PY{l+s+s2}{\PYZdq{}}\PY{p}{,} \PY{l+s+s2}{\PYZdq{}}\PY{l+s+s2}{architecturalstyletypeid}\PY{l+s+s2}{\PYZdq{}}\PY{p}{,} \PY{l+s+s2}{\PYZdq{}}\PY{l+s+s2}{buildingclasstypeid}\PY{l+s+s2}{\PYZdq{}}\PY{p}{,} \PY{l+s+s2}{\PYZdq{}}\PY{l+s+s2}{typeconstructiontypeid}\PY{l+s+s2}{\PYZdq{}}\PY{p}{,} \PY{l+s+s2}{\PYZdq{}}\PY{l+s+s2}{finishedsquarefeet6}\PY{l+s+s2}{\PYZdq{}}\PY{p}{,}
             \PY{l+s+s2}{\PYZdq{}}\PY{l+s+s2}{pooltypeid10}\PY{l+s+s2}{\PYZdq{}}\PY{p}{,} \PY{l+s+s2}{\PYZdq{}}\PY{l+s+s2}{hashottuborspa}\PY{l+s+s2}{\PYZdq{}}\PY{p}{,} \PY{l+s+s2}{\PYZdq{}}\PY{l+s+s2}{fireplaceflag}\PY{l+s+s2}{\PYZdq{}}\PY{p}{,} \PY{l+s+s2}{\PYZdq{}}\PY{l+s+s2}{threequarterbathnbr}\PY{l+s+s2}{\PYZdq{}}\PY{p}{,} \PY{l+s+s2}{\PYZdq{}}\PY{l+s+s2}{calculatedbathnbr}\PY{l+s+s2}{\PYZdq{}}\PY{p}{,}
             \PY{l+s+s2}{\PYZdq{}}\PY{l+s+s2}{fullbathcnt}\PY{l+s+s2}{\PYZdq{}}\PY{p}{,} \PY{l+s+s2}{\PYZdq{}}\PY{l+s+s2}{numberofstories}\PY{l+s+s2}{\PYZdq{}}\PY{p}{,} \PY{l+s+s2}{\PYZdq{}}\PY{l+s+s2}{censustractandblock}\PY{l+s+s2}{\PYZdq{}}\PY{p}{,} \PY{l+s+s2}{\PYZdq{}}\PY{l+s+s2}{rawcensustractandblock}\PY{l+s+s2}{\PYZdq{}}\PY{p}{,}
             \PY{l+s+s2}{\PYZdq{}}\PY{l+s+s2}{finishedsquarefeet12}\PY{l+s+s2}{\PYZdq{}}\PY{p}{,} \PY{l+s+s2}{\PYZdq{}}\PY{l+s+s2}{taxvaluedollarcnt}\PY{l+s+s2}{\PYZdq{}}\PY{p}{,} \PY{l+s+s2}{\PYZdq{}}\PY{l+s+s2}{taxamount}\PY{l+s+s2}{\PYZdq{}}\PY{p}{,} \PY{l+s+s2}{\PYZdq{}}\PY{l+s+s2}{assessmentyear}\PY{l+s+s2}{\PYZdq{}}\PY{p}{,} \PY{l+s+s2}{\PYZdq{}}\PY{l+s+s2}{roomcnt}\PY{l+s+s2}{\PYZdq{}}\PY{p}{,}
             \PY{l+s+s2}{\PYZdq{}}\PY{l+s+s2}{propertyzoningdesc}\PY{l+s+s2}{\PYZdq{}}\PY{p}{,} \PY{l+s+s2}{\PYZdq{}}\PY{l+s+s2}{regionidneighborhood}\PY{l+s+s2}{\PYZdq{}}\PY{p}{,} \PY{l+s+s2}{\PYZdq{}}\PY{l+s+s2}{regionidzip}\PY{l+s+s2}{\PYZdq{}}\PY{p}{,} \PY{l+s+s2}{\PYZdq{}}\PY{l+s+s2}{taxdelinquencyyear}\PY{l+s+s2}{\PYZdq{}}\PY{p}{,}
             \PY{l+s+s2}{\PYZdq{}}\PY{l+s+s2}{propertycountylandusecode}\PY{l+s+s2}{\PYZdq{}}\PY{p}{,} \PY{l+s+s2}{\PYZdq{}}\PY{l+s+s2}{regionidcity}\PY{l+s+s2}{\PYZdq{}}\PY{p}{,} \PY{l+s+s2}{\PYZdq{}}\PY{l+s+s2}{parcelid}\PY{l+s+s2}{\PYZdq{}}\PY{p}{,} \PY{l+s+s2}{\PYZdq{}}\PY{l+s+s2}{basementsqft}\PY{l+s+s2}{\PYZdq{}}\PY{p}{,} \PY{l+s+s2}{\PYZdq{}}\PY{l+s+s2}{yardbuildingsqft26}\PY{l+s+s2}{\PYZdq{}}\PY{p}{,} \PY{l+s+s2}{\PYZdq{}}\PY{l+s+s2}{transactiondate}\PY{l+s+s2}{\PYZdq{}}
            \PY{p}{]}
\PY{n}{feature\PYZus{}dropper} \PY{o}{=} \PY{n}{utils}\PY{o}{.}\PY{n}{FeatureDropper}\PY{p}{(}\PY{n}{features\PYZus{}to\PYZus{}drop}\PY{o}{=}\PY{n}{lin\PYZus{}reg\PYZus{}drop\PYZus{}vars}\PY{p}{)}

\PY{n}{date\PYZus{}features} \PY{o}{=} \PY{p}{\PYZob{}}\PY{l+s+s2}{\PYZdq{}}\PY{l+s+s2}{yearbuilt}\PY{l+s+s2}{\PYZdq{}}\PY{p}{:} \PY{l+s+s2}{\PYZdq{}}\PY{l+s+s2}{house\PYZus{}age}\PY{l+s+s2}{\PYZdq{}}\PY{p}{\PYZcb{}}
\PY{c+c1}{\PYZsh{} Convert Date Features Pipeline}
\PY{n}{year\PYZus{}feat\PYZus{}creator} \PY{o}{=} \PY{n}{utils}\PY{o}{.}\PY{n}{CreateYearFeatures}\PY{p}{(}\PY{n}{date\PYZus{}features}\PY{o}{=}\PY{n}{date\PYZus{}features}\PY{p}{)}

\PY{c+c1}{\PYZsh{} Feature Encoding and Scaling Pipeline}
\PY{n}{feature\PYZus{}encoder\PYZus{}scaler} \PY{o}{=} \PY{n}{utils}\PY{o}{.}\PY{n}{FeatureEncoderAndScaler}\PY{p}{(}\PY{p}{)}

\PY{c+c1}{\PYZsh{} Transform Skewed Numerical Features Pipeline}
\PY{n}{skew\PYZus{}transformer} \PY{o}{=} \PY{n}{utils}\PY{o}{.}\PY{n}{BoxCoxSkewedFeatures}\PY{p}{(}\PY{p}{)}

\PY{c+c1}{\PYZsh{} Two versions below: Univariate Imputation and Multivariate Imputation:}
\PY{c+c1}{\PYZsh{} True for univariate imputation, false for multivariate imputation}
\PY{c+c1}{\PYZsh{}\PYZsh{}\PYZsh{}\PYZsh{}\PYZsh{}\PYZsh{}\PYZsh{}\PYZsh{}\PYZsh{}\PYZsh{}\PYZsh{}\PYZsh{}\PYZsh{}\PYZsh{}\PYZsh{}\PYZsh{}\PYZsh{}\PYZsh{}\PYZsh{}\PYZsh{}\PYZsh{}\PYZsh{}\PYZsh{}\PYZsh{}\PYZsh{}\PYZsh{}\PYZsh{}\PYZsh{}\PYZsh{}\PYZsh{}\PYZsh{}\PYZsh{}\PYZsh{}\PYZsh{}\PYZsh{}\PYZsh{}\PYZsh{}\PYZsh{}\PYZsh{}\PYZsh{}\PYZsh{}\PYZsh{}\PYZsh{} }
\PY{n}{univariate} \PY{o}{=} \PY{k+kc}{True} 
\PY{k}{if} \PY{n}{univariate}\PY{p}{:}
    \PY{c+c1}{\PYZsh{} 1) Univariate Imputation Pipeline}
    
    \PY{n}{impute\PYZus{}0\PYZus{}vars} \PY{o}{=} \PY{p}{[}\PY{l+s+s2}{\PYZdq{}}\PY{l+s+s2}{yardbuildingsqft17}\PY{l+s+s2}{\PYZdq{}}\PY{p}{,} \PY{l+s+s2}{\PYZdq{}}\PY{l+s+s2}{fireplacecnt}\PY{l+s+s2}{\PYZdq{}}\PY{p}{,} \PY{l+s+s2}{\PYZdq{}}\PY{l+s+s2}{poolcnt}\PY{l+s+s2}{\PYZdq{}}\PY{p}{,} \PY{l+s+s2}{\PYZdq{}}\PY{l+s+s2}{garagecarcnt}\PY{l+s+s2}{\PYZdq{}}\PY{p}{,} \PY{l+s+s2}{\PYZdq{}}\PY{l+s+s2}{garagetotalsqft}\PY{l+s+s2}{\PYZdq{}}\PY{p}{,}
                 \PY{l+s+s2}{\PYZdq{}}\PY{l+s+s2}{pooltypeid2}\PY{l+s+s2}{\PYZdq{}}\PY{p}{,} \PY{l+s+s2}{\PYZdq{}}\PY{l+s+s2}{poolsizesum}\PY{l+s+s2}{\PYZdq{}}\PY{p}{,} \PY{l+s+s2}{\PYZdq{}}\PY{l+s+s2}{decktypeid}\PY{l+s+s2}{\PYZdq{}}\PY{p}{,} \PY{l+s+s2}{\PYZdq{}}\PY{l+s+s2}{taxdelinquencyflag}\PY{l+s+s2}{\PYZdq{}}\PY{p}{,}\PY{l+s+s2}{\PYZdq{}}\PY{l+s+s2}{pooltypeid7}\PY{l+s+s2}{\PYZdq{}}\PY{p}{]}

    \PY{n}{impute\PYZus{}mode\PYZus{}vars} \PY{o}{=} \PY{p}{[}\PY{l+s+s2}{\PYZdq{}}\PY{l+s+s2}{airconditioningtypeid}\PY{l+s+s2}{\PYZdq{}}\PY{p}{,} \PY{l+s+s2}{\PYZdq{}}\PY{l+s+s2}{heatingorsystemtypeid}\PY{l+s+s2}{\PYZdq{}}\PY{p}{,} \PY{l+s+s2}{\PYZdq{}}\PY{l+s+s2}{unitcnt}\PY{l+s+s2}{\PYZdq{}}\PY{p}{,} \PY{l+s+s2}{\PYZdq{}}\PY{l+s+s2}{fips}\PY{l+s+s2}{\PYZdq{}}\PY{p}{,}
                        \PY{l+s+s2}{\PYZdq{}}\PY{l+s+s2}{propertylandusetypeid}\PY{l+s+s2}{\PYZdq{}}\PY{p}{,} \PY{l+s+s2}{\PYZdq{}}\PY{l+s+s2}{regionidcounty}\PY{l+s+s2}{\PYZdq{}}\PY{p}{,} \PY{l+s+s2}{\PYZdq{}}\PY{l+s+s2}{yearbuilt}\PY{l+s+s2}{\PYZdq{}}\PY{p}{]} 

    \PY{n}{impute\PYZus{}median\PYZus{}vars} \PY{o}{=} \PY{p}{[}\PY{l+s+s2}{\PYZdq{}}\PY{l+s+s2}{buildingqualitytypeid}\PY{l+s+s2}{\PYZdq{}}\PY{p}{,} \PY{l+s+s2}{\PYZdq{}}\PY{l+s+s2}{lotsizesquarefeet}\PY{l+s+s2}{\PYZdq{}}\PY{p}{,} \PY{l+s+s2}{\PYZdq{}}\PY{l+s+s2}{bathroomcnt}\PY{l+s+s2}{\PYZdq{}}\PY{p}{,} \PY{l+s+s2}{\PYZdq{}}\PY{l+s+s2}{bedroomcnt}\PY{l+s+s2}{\PYZdq{}}\PY{p}{,} \PY{l+s+s2}{\PYZdq{}}\PY{l+s+s2}{calculatedfinishedsquarefeet}\PY{l+s+s2}{\PYZdq{}}\PY{p}{,}
                          \PY{l+s+s2}{\PYZdq{}}\PY{l+s+s2}{structuretaxvaluedollarcnt}\PY{l+s+s2}{\PYZdq{}}\PY{p}{,} \PY{l+s+s2}{\PYZdq{}}\PY{l+s+s2}{landtaxvaluedollarcnt}\PY{l+s+s2}{\PYZdq{}}\PY{p}{,} \PY{l+s+s2}{\PYZdq{}}\PY{l+s+s2}{latitude}\PY{l+s+s2}{\PYZdq{}}\PY{p}{,} \PY{l+s+s2}{\PYZdq{}}\PY{l+s+s2}{longitude}\PY{l+s+s2}{\PYZdq{}}\PY{p}{]}

    \PY{n}{convert\PYZus{}to\PYZus{}int} \PY{o}{=} \PY{p}{[}\PY{l+s+s2}{\PYZdq{}}\PY{l+s+s2}{yearbuilt}\PY{l+s+s2}{\PYZdq{}}\PY{p}{]} 
    \PY{n}{convert\PYZus{}to\PYZus{}float}\PY{o}{=} \PY{p}{[}\PY{l+s+s2}{\PYZdq{}}\PY{l+s+s2}{bathroomcnt}\PY{l+s+s2}{\PYZdq{}}\PY{p}{,} \PY{l+s+s2}{\PYZdq{}}\PY{l+s+s2}{bedroomcnt}\PY{l+s+s2}{\PYZdq{}}\PY{p}{,} \PY{l+s+s2}{\PYZdq{}}\PY{l+s+s2}{buildingqualitytypeid}\PY{l+s+s2}{\PYZdq{}}\PY{p}{,} \PY{l+s+s2}{\PYZdq{}}\PY{l+s+s2}{calculatedfinishedsquarefeet}\PY{l+s+s2}{\PYZdq{}}\PY{p}{,}
                      \PY{l+s+s2}{\PYZdq{}}\PY{l+s+s2}{fireplacecnt}\PY{l+s+s2}{\PYZdq{}}\PY{p}{,} \PY{l+s+s2}{\PYZdq{}}\PY{l+s+s2}{garagecarcnt}\PY{l+s+s2}{\PYZdq{}}\PY{p}{,} \PY{l+s+s2}{\PYZdq{}}\PY{l+s+s2}{garagetotalsqft}\PY{l+s+s2}{\PYZdq{}}\PY{p}{,} \PY{l+s+s2}{\PYZdq{}}\PY{l+s+s2}{latitude}\PY{l+s+s2}{\PYZdq{}}\PY{p}{,} \PY{l+s+s2}{\PYZdq{}}\PY{l+s+s2}{longitude}\PY{l+s+s2}{\PYZdq{}}\PY{p}{,} \PY{l+s+s2}{\PYZdq{}}\PY{l+s+s2}{lotsizesquarefeet}\PY{l+s+s2}{\PYZdq{}}\PY{p}{,} \PY{l+s+s2}{\PYZdq{}}\PY{l+s+s2}{poolcnt}\PY{l+s+s2}{\PYZdq{}}\PY{p}{,}
                      \PY{l+s+s2}{\PYZdq{}}\PY{l+s+s2}{poolsizesum}\PY{l+s+s2}{\PYZdq{}}\PY{p}{,} \PY{l+s+s2}{\PYZdq{}}\PY{l+s+s2}{unitcnt}\PY{l+s+s2}{\PYZdq{}}\PY{p}{,} \PY{l+s+s2}{\PYZdq{}}\PY{l+s+s2}{yardbuildingsqft17}\PY{l+s+s2}{\PYZdq{}}\PY{p}{,} \PY{l+s+s2}{\PYZdq{}}\PY{l+s+s2}{structuretaxvaluedollarcnt}\PY{l+s+s2}{\PYZdq{}}\PY{p}{,} \PY{l+s+s2}{\PYZdq{}}\PY{l+s+s2}{landtaxvaluedollarcnt}\PY{l+s+s2}{\PYZdq{}}\PY{p}{]}

    \PY{n}{convert\PYZus{}to\PYZus{}bool} \PY{o}{=} \PY{p}{[}\PY{l+s+s2}{\PYZdq{}}\PY{l+s+s2}{pooltypeid2}\PY{l+s+s2}{\PYZdq{}}\PY{p}{,} \PY{l+s+s2}{\PYZdq{}}\PY{l+s+s2}{decktypeid}\PY{l+s+s2}{\PYZdq{}}\PY{p}{,} \PY{l+s+s2}{\PYZdq{}}\PY{l+s+s2}{taxdelinquencyflag}\PY{l+s+s2}{\PYZdq{}}\PY{p}{]} 
    \PY{n}{convert\PYZus{}to\PYZus{}string}\PY{o}{=} \PY{p}{[}\PY{l+s+s2}{\PYZdq{}}\PY{l+s+s2}{airconditioningtypeid}\PY{l+s+s2}{\PYZdq{}}\PY{p}{,} \PY{l+s+s2}{\PYZdq{}}\PY{l+s+s2}{heatingorsystemtypeid}\PY{l+s+s2}{\PYZdq{}}\PY{p}{,} \PY{l+s+s2}{\PYZdq{}}\PY{l+s+s2}{fips}\PY{l+s+s2}{\PYZdq{}}\PY{p}{,} \PY{l+s+s2}{\PYZdq{}}\PY{l+s+s2}{propertylandusetypeid}\PY{l+s+s2}{\PYZdq{}}\PY{p}{,} \PY{l+s+s2}{\PYZdq{}}\PY{l+s+s2}{regionidcounty}\PY{l+s+s2}{\PYZdq{}}\PY{p}{]}
    \PY{n}{univariate\PYZus{}impute\PYZus{}pipe} \PY{o}{=} \PY{n}{utils}\PY{o}{.}\PY{n}{ColumnTransformer}\PY{p}{(}\PY{p}{[}
            \PY{p}{(}\PY{l+s+s2}{\PYZdq{}}\PY{l+s+s2}{impute\PYZus{}0}\PY{l+s+s2}{\PYZdq{}}\PY{p}{,} \PY{n}{SimpleImputer}\PY{p}{(}\PY{n}{strategy}\PY{o}{=}\PY{l+s+s2}{\PYZdq{}}\PY{l+s+s2}{constant}\PY{l+s+s2}{\PYZdq{}}\PY{p}{,} \PY{n}{fill\PYZus{}value}\PY{o}{=}\PY{l+m+mi}{0}\PY{p}{)}\PY{p}{,} \PY{n}{impute\PYZus{}0\PYZus{}vars}\PY{p}{)}\PY{p}{,}
            \PY{p}{(}\PY{l+s+s2}{\PYZdq{}}\PY{l+s+s2}{impute\PYZus{}mode}\PY{l+s+s2}{\PYZdq{}}\PY{p}{,} \PY{n}{SimpleImputer}\PY{p}{(}\PY{n}{strategy}\PY{o}{=}\PY{l+s+s2}{\PYZdq{}}\PY{l+s+s2}{most\PYZus{}frequent}\PY{l+s+s2}{\PYZdq{}}\PY{p}{)}\PY{p}{,} \PY{n}{impute\PYZus{}mode\PYZus{}vars}\PY{p}{)}\PY{p}{,}
            \PY{p}{(}\PY{l+s+s2}{\PYZdq{}}\PY{l+s+s2}{impute\PYZus{}median}\PY{l+s+s2}{\PYZdq{}}\PY{p}{,} \PY{n}{SimpleImputer}\PY{p}{(}\PY{n}{strategy}\PY{o}{=}\PY{l+s+s2}{\PYZdq{}}\PY{l+s+s2}{median}\PY{l+s+s2}{\PYZdq{}}\PY{p}{)}\PY{p}{,} \PY{n}{impute\PYZus{}median\PYZus{}vars}\PY{p}{)}\PY{p}{,}
        \PY{p}{]}\PY{p}{,}
        \PY{n}{remainder}\PY{o}{=}\PY{l+s+s1}{\PYZsq{}}\PY{l+s+s1}{passthrough}\PY{l+s+s1}{\PYZsq{}}
    \PY{p}{)}
    \PY{n}{col\PYZus{}name\PYZus{}appender} \PY{o}{=} \PY{n}{utils}\PY{o}{.}\PY{n}{ColumnNamesAppender}\PY{p}{(}\PY{n}{univariate\PYZus{}impute\PYZus{}pipe}\PY{p}{,} \PY{n}{X\PYZus{}train}\PY{o}{.}\PY{n}{columns}\PY{p}{,} \PY{n}{num\PYZus{}transformers}\PY{o}{=}\PY{l+m+mi}{3}\PY{p}{)}
    \PY{n}{feature\PYZus{}type\PYZus{}changer} \PY{o}{=} \PY{n}{utils}\PY{o}{.}\PY{n}{ConvertFeatureType}\PY{p}{(}\PY{n}{convert\PYZus{}to\PYZus{}int}\PY{o}{=}\PY{n}{convert\PYZus{}to\PYZus{}int}\PY{p}{,} \PY{n}{convert\PYZus{}to\PYZus{}string}\PY{o}{=}\PY{n}{convert\PYZus{}to\PYZus{}string}\PY{p}{,} 
                                              \PY{n}{convert\PYZus{}to\PYZus{}float}\PY{o}{=}\PY{n}{convert\PYZus{}to\PYZus{}float}\PY{p}{,} \PY{n}{convert\PYZus{}to\PYZus{}bool}\PY{o}{=}\PY{n}{convert\PYZus{}to\PYZus{}bool}\PY{p}{)}
    
    \PY{n}{poly\PYZus{}feat\PYZus{}creator} \PY{o}{=} \PY{n}{utils}\PY{o}{.}\PY{n}{CreatePolynomialFeatures}\PY{p}{(}\PY{n}{most\PYZus{}corr\PYZus{}feat}\PY{p}{)}

\PY{k}{else}\PY{p}{:}
    \PY{c+c1}{\PYZsh{}2) Multivariate Version}
    \PY{n}{cat\PYZus{}impute\PYZus{}vars} \PY{o}{=} \PY{p}{[}\PY{l+s+s2}{\PYZdq{}}\PY{l+s+s2}{airconditioningtypeid}\PY{l+s+s2}{\PYZdq{}}\PY{p}{,} \PY{l+s+s2}{\PYZdq{}}\PY{l+s+s2}{heatingorsystemtypeid}\PY{l+s+s2}{\PYZdq{}}\PY{p}{,} \PY{l+s+s2}{\PYZdq{}}\PY{l+s+s2}{fips}\PY{l+s+s2}{\PYZdq{}}\PY{p}{,} \PY{l+s+s2}{\PYZdq{}}\PY{l+s+s2}{propertylandusetypeid}\PY{l+s+s2}{\PYZdq{}}\PY{p}{,} \PY{l+s+s2}{\PYZdq{}}\PY{l+s+s2}{regionidcounty}\PY{l+s+s2}{\PYZdq{}}\PY{p}{,} \PY{l+s+s2}{\PYZdq{}}\PY{l+s+s2}{pooltypeid2}\PY{l+s+s2}{\PYZdq{}}\PY{p}{,} \PY{l+s+s2}{\PYZdq{}}\PY{l+s+s2}{decktypeid}\PY{l+s+s2}{\PYZdq{}}\PY{p}{,} \PY{l+s+s2}{\PYZdq{}}\PY{l+s+s2}{taxdelinquencyflag}\PY{l+s+s2}{\PYZdq{}}\PY{p}{]} 
    \PY{n}{numeric\PYZus{}impute\PYZus{}vars} \PY{o}{=} \PY{p}{[}\PY{l+s+s2}{\PYZdq{}}\PY{l+s+s2}{bathroomcnt}\PY{l+s+s2}{\PYZdq{}}\PY{p}{,} \PY{l+s+s2}{\PYZdq{}}\PY{l+s+s2}{bedroomcnt}\PY{l+s+s2}{\PYZdq{}}\PY{p}{,} \PY{l+s+s2}{\PYZdq{}}\PY{l+s+s2}{buildingqualitytypeid}\PY{l+s+s2}{\PYZdq{}}\PY{p}{,} \PY{l+s+s2}{\PYZdq{}}\PY{l+s+s2}{calculatedfinishedsquarefeet}\PY{l+s+s2}{\PYZdq{}}\PY{p}{,}
                      \PY{l+s+s2}{\PYZdq{}}\PY{l+s+s2}{fireplacecnt}\PY{l+s+s2}{\PYZdq{}}\PY{p}{,} \PY{l+s+s2}{\PYZdq{}}\PY{l+s+s2}{garagecarcnt}\PY{l+s+s2}{\PYZdq{}}\PY{p}{,} \PY{l+s+s2}{\PYZdq{}}\PY{l+s+s2}{garagetotalsqft}\PY{l+s+s2}{\PYZdq{}}\PY{p}{,} \PY{l+s+s2}{\PYZdq{}}\PY{l+s+s2}{latitude}\PY{l+s+s2}{\PYZdq{}}\PY{p}{,} \PY{l+s+s2}{\PYZdq{}}\PY{l+s+s2}{longitude}\PY{l+s+s2}{\PYZdq{}}\PY{p}{,} \PY{l+s+s2}{\PYZdq{}}\PY{l+s+s2}{lotsizesquarefeet}\PY{l+s+s2}{\PYZdq{}}\PY{p}{,} \PY{l+s+s2}{\PYZdq{}}\PY{l+s+s2}{poolcnt}\PY{l+s+s2}{\PYZdq{}}\PY{p}{,}
                      \PY{l+s+s2}{\PYZdq{}}\PY{l+s+s2}{poolsizesum}\PY{l+s+s2}{\PYZdq{}}\PY{p}{,} \PY{l+s+s2}{\PYZdq{}}\PY{l+s+s2}{unitcnt}\PY{l+s+s2}{\PYZdq{}}\PY{p}{,} \PY{l+s+s2}{\PYZdq{}}\PY{l+s+s2}{yardbuildingsqft17}\PY{l+s+s2}{\PYZdq{}}\PY{p}{,} \PY{l+s+s2}{\PYZdq{}}\PY{l+s+s2}{yearbuilt}\PY{l+s+s2}{\PYZdq{}}\PY{p}{,} \PY{l+s+s2}{\PYZdq{}}\PY{l+s+s2}{structuretaxvaluedollarcnt}\PY{l+s+s2}{\PYZdq{}}\PY{p}{,} \PY{l+s+s2}{\PYZdq{}}\PY{l+s+s2}{landtaxvaluedollarcnt}\PY{l+s+s2}{\PYZdq{}}\PY{p}{]}

    \PY{n}{convert\PYZus{}to\PYZus{}string}\PY{o}{=} \PY{p}{[}\PY{l+s+s2}{\PYZdq{}}\PY{l+s+s2}{airconditioningtypeid}\PY{l+s+s2}{\PYZdq{}}\PY{p}{,} \PY{l+s+s2}{\PYZdq{}}\PY{l+s+s2}{heatingorsystemtypeid}\PY{l+s+s2}{\PYZdq{}}\PY{p}{,} \PY{l+s+s2}{\PYZdq{}}\PY{l+s+s2}{fips}\PY{l+s+s2}{\PYZdq{}}\PY{p}{,} \PY{l+s+s2}{\PYZdq{}}\PY{l+s+s2}{propertylandusetypeid}\PY{l+s+s2}{\PYZdq{}}\PY{p}{,} \PY{l+s+s2}{\PYZdq{}}\PY{l+s+s2}{regionidcounty}\PY{l+s+s2}{\PYZdq{}}\PY{p}{,} \PY{l+s+s2}{\PYZdq{}}\PY{l+s+s2}{pooltypeid2}\PY{l+s+s2}{\PYZdq{}}\PY{p}{,} \PY{l+s+s2}{\PYZdq{}}\PY{l+s+s2}{decktypeid}\PY{l+s+s2}{\PYZdq{}}\PY{p}{,} \PY{l+s+s2}{\PYZdq{}}\PY{l+s+s2}{taxdelinquencyflag}\PY{l+s+s2}{\PYZdq{}}\PY{p}{]}
    \PY{n}{multivariate\PYZus{}impute\PYZus{}pipe} \PY{o}{=} \PY{n}{utils}\PY{o}{.}\PY{n}{ColumnTransformer}\PY{p}{(}\PY{p}{[}
            \PY{p}{(}\PY{l+s+s2}{\PYZdq{}}\PY{l+s+s2}{impute\PYZus{}cats}\PY{l+s+s2}{\PYZdq{}}\PY{p}{,} \PY{n}{SimpleImputer}\PY{p}{(}\PY{n}{strategy}\PY{o}{=}\PY{l+s+s2}{\PYZdq{}}\PY{l+s+s2}{constant}\PY{l+s+s2}{\PYZdq{}}\PY{p}{,} \PY{n}{fill\PYZus{}value}\PY{o}{=}\PY{l+s+s1}{\PYZsq{}}\PY{l+s+s1}{missing}\PY{l+s+s1}{\PYZsq{}}\PY{p}{)}\PY{p}{,} \PY{n}{cat\PYZus{}impute\PYZus{}vars}\PY{p}{)}\PY{p}{,}
            \PY{p}{(}\PY{l+s+s2}{\PYZdq{}}\PY{l+s+s2}{impute\PYZus{}num}\PY{l+s+s2}{\PYZdq{}}\PY{p}{,} \PY{n}{IterativeImputer}\PY{p}{(}\PY{n}{estimator}\PY{o}{=}\PY{n}{RandomForestRegressor}\PY{p}{(}\PY{n}{n\PYZus{}estimators}\PY{o}{=}\PY{l+m+mi}{10}\PY{p}{,} \PY{n}{max\PYZus{}depth}\PY{o}{=}\PY{l+m+mi}{30}\PY{p}{,} \PY{n}{min\PYZus{}samples\PYZus{}leaf}\PY{o}{=}\PY{l+m+mi}{32}\PY{p}{)}\PY{p}{,} \PY{n}{random\PYZus{}state}\PY{o}{=}\PY{l+m+mi}{0}\PY{p}{,} \PY{n}{max\PYZus{}iter}\PY{o}{=}\PY{l+m+mi}{1}\PY{p}{)}\PY{p}{,} \PY{n}{numeric\PYZus{}impute\PYZus{}vars}\PY{p}{)}\PY{p}{,}
        \PY{p}{]}\PY{p}{,}
        \PY{n}{remainder}\PY{o}{=}\PY{l+s+s1}{\PYZsq{}}\PY{l+s+s1}{passthrough}\PY{l+s+s1}{\PYZsq{}}
    \PY{p}{)}
    \PY{n}{col\PYZus{}name\PYZus{}appender} \PY{o}{=} \PY{n}{utils}\PY{o}{.}\PY{n}{ColumnNamesAppender}\PY{p}{(}\PY{n}{multivariate\PYZus{}impute\PYZus{}pipe}\PY{p}{,} \PY{n}{X\PYZus{}train}\PY{o}{.}\PY{n}{columns}\PY{p}{,} \PY{n}{num\PYZus{}transformers}\PY{o}{=}\PY{l+m+mi}{3}\PY{p}{)}
    \PY{n}{feature\PYZus{}type\PYZus{}changer} \PY{o}{=} \PY{n}{utils}\PY{o}{.}\PY{n}{ConvertFeatureType}\PY{p}{(}\PY{n}{convert\PYZus{}to\PYZus{}int}\PY{o}{=}\PY{n}{convert\PYZus{}to\PYZus{}int}\PY{p}{,} \PY{n}{convert\PYZus{}to\PYZus{}string}\PY{o}{=}\PY{n}{convert\PYZus{}to\PYZus{}string}\PY{p}{,} \PY{n}{convert\PYZus{}to\PYZus{}float}\PY{o}{=}\PY{n}{convert\PYZus{}to\PYZus{}float}\PY{p}{)}
    \PY{n}{most\PYZus{}corr\PYZus{}feat} \PY{o}{=} \PY{n+nb}{list}\PY{p}{(}\PY{n+nb}{map}\PY{p}{(}\PY{k}{lambda} \PY{n}{x}\PY{p}{:} \PY{n}{x}\PY{o}{.}\PY{n}{replace}\PY{p}{(}\PY{l+s+s1}{\PYZsq{}}\PY{l+s+s1}{num\PYZus{}scaler\PYZus{}\PYZus{}}\PY{l+s+s1}{\PYZsq{}}\PY{p}{,}\PY{l+s+s1}{\PYZsq{}}\PY{l+s+s1}{\PYZsq{}}\PY{p}{)}\PY{p}{,} \PY{n}{most\PYZus{}corr\PYZus{}feat}\PY{p}{)}\PY{p}{)}     \PY{c+c1}{\PYZsh{} Clean up feature names by removing `num\PYZus{}scaler\PYZus{}\PYZus{}`}
    \PY{n}{poly\PYZus{}feat\PYZus{}creator} \PY{o}{=} \PY{n}{utils}\PY{o}{.}\PY{n}{CreatePolynomialFeatures}\PY{p}{(}\PY{n}{most\PYZus{}corr\PYZus{}feat}\PY{p}{)}
\end{Verbatim}
\end{tcolorbox}

    \begin{tcolorbox}[breakable, size=fbox, boxrule=1pt, pad at break*=1mm,colback=cellbackground, colframe=cellborder]
\prompt{In}{incolor}{34}{\boxspacing}
\begin{Verbatim}[commandchars=\\\{\}]
\PY{k}{if} \PY{n}{univariate}\PY{p}{:}
    \PY{n}{imputation} \PY{o}{=} \PY{n}{univariate\PYZus{}impute\PYZus{}pipe}
\PY{k}{else}\PY{p}{:}
    \PY{n}{imputation} \PY{o}{=} \PY{n}{multivariate\PYZus{}impute\PYZus{}pipe}
\PY{n}{lin\PYZus{}reg\PYZus{}preprocessor} \PY{o}{=} \PY{n}{Pipeline}\PY{p}{(}\PY{p}{[}
        \PY{p}{(}\PY{l+s+s1}{\PYZsq{}}\PY{l+s+s1}{feature\PYZus{}dropper}\PY{l+s+s1}{\PYZsq{}}\PY{p}{,} \PY{n}{feature\PYZus{}dropper}\PY{p}{)}\PY{p}{,}
        \PY{p}{(}\PY{l+s+s1}{\PYZsq{}}\PY{l+s+s1}{imputation}\PY{l+s+s1}{\PYZsq{}}\PY{p}{,} \PY{n}{imputation}\PY{p}{)}\PY{p}{,}
        \PY{p}{(}\PY{l+s+s1}{\PYZsq{}}\PY{l+s+s1}{col\PYZus{}name\PYZus{}appender}\PY{l+s+s1}{\PYZsq{}}\PY{p}{,} \PY{n}{col\PYZus{}name\PYZus{}appender}\PY{p}{)}\PY{p}{,}
        \PY{p}{(}\PY{l+s+s1}{\PYZsq{}}\PY{l+s+s1}{feature\PYZus{}type\PYZus{}changer}\PY{l+s+s1}{\PYZsq{}}\PY{p}{,} \PY{n}{feature\PYZus{}type\PYZus{}changer}\PY{p}{)}\PY{p}{,}
        \PY{p}{(}\PY{l+s+s1}{\PYZsq{}}\PY{l+s+s1}{year\PYZus{}feat\PYZus{}creator}\PY{l+s+s1}{\PYZsq{}}\PY{p}{,} \PY{n}{year\PYZus{}feat\PYZus{}creator}\PY{p}{)}\PY{p}{,}
        \PY{p}{(}\PY{l+s+s1}{\PYZsq{}}\PY{l+s+s1}{feature\PYZus{}encoder\PYZus{}scaler}\PY{l+s+s1}{\PYZsq{}}\PY{p}{,} \PY{n}{feature\PYZus{}encoder\PYZus{}scaler}\PY{p}{)}\PY{p}{,}
        \PY{p}{(}\PY{l+s+s1}{\PYZsq{}}\PY{l+s+s1}{skew\PYZus{}transformer}\PY{l+s+s1}{\PYZsq{}}\PY{p}{,} \PY{n}{skew\PYZus{}transformer}\PY{p}{)}\PY{p}{,}
    \PY{p}{]}\PY{p}{,}\PY{n}{verbose}\PY{o}{=}\PY{k+kc}{True}\PY{p}{)}

\PY{n}{data\PYZus{}prep\PYZus{}pipe} \PY{o}{=} \PY{n}{lin\PYZus{}reg\PYZus{}preprocessor}\PY{o}{.}\PY{n}{fit}\PY{p}{(}\PY{n}{X\PYZus{}prepared}\PY{p}{)}
\PY{n}{X\PYZus{}prepared} \PY{o}{=} \PY{n}{lin\PYZus{}reg\PYZus{}preprocessor}\PY{o}{.}\PY{n}{transform}\PY{p}{(}\PY{n}{X\PYZus{}prepared}\PY{p}{)}
\PY{n}{X\PYZus{}prepared\PYZus{}val} \PY{o}{=} \PY{n}{lin\PYZus{}reg\PYZus{}preprocessor}\PY{o}{.}\PY{n}{transform}\PY{p}{(}\PY{n}{X\PYZus{}prepared\PYZus{}val}\PY{p}{)}
\end{Verbatim}
\end{tcolorbox}

    \begin{Verbatim}[commandchars=\\\{\}]
[Pipeline] {\ldots} (step 1 of 7) Processing feature\_dropper, total=   0.0s
[Pipeline] {\ldots} (step 2 of 7) Processing imputation, total=   0.4s
[Pipeline] . (step 3 of 7) Processing col\_name\_appender, total=   0.0s
[Pipeline]  (step 4 of 7) Processing feature\_type\_changer, total=   0.6s
[Pipeline] . (step 5 of 7) Processing year\_feat\_creator, total=   0.0s
[Pipeline]  (step 6 of 7) Processing feature\_encoder\_scaler, total=   4.8s
[Pipeline] .. (step 7 of 7) Processing skew\_transformer, total=   0.0s
    \end{Verbatim}

    \begin{tcolorbox}[breakable, size=fbox, boxrule=1pt, pad at break*=1mm,colback=cellbackground, colframe=cellborder]
\prompt{In}{incolor}{35}{\boxspacing}
\begin{Verbatim}[commandchars=\\\{\}]
\PY{k+kn}{from} \PY{n+nn}{sklearn} \PY{k+kn}{import} \PY{n}{set\PYZus{}config}
\PY{n}{set\PYZus{}config}\PY{p}{(}\PY{n}{display}\PY{o}{=}\PY{l+s+s1}{\PYZsq{}}\PY{l+s+s1}{diagram}\PY{l+s+s1}{\PYZsq{}}\PY{p}{)}
\PY{n}{lin\PYZus{}reg\PYZus{}preprocessor}
\end{Verbatim}
\end{tcolorbox}

            \begin{tcolorbox}[breakable, size=fbox, boxrule=.5pt, pad at break*=1mm, opacityfill=0]
\prompt{Out}{outcolor}{35}{\boxspacing}
\begin{Verbatim}[commandchars=\\\{\}]
Pipeline(steps=[('feature\_dropper',
                 FeatureDropper(features\_to\_drop=['finishedsquarefeet13',
                                                  'finishedsquarefeet15',
                                                  'finishedfloor1squarefeet',
                                                  'finishedsquarefeet50',
                                                  'storytypeid',
                                                  'architecturalstyletypeid',
                                                  'buildingclasstypeid',
                                                  'typeconstructiontypeid',
                                                  'finishedsquarefeet6',
                                                  'pooltypeid10',
                                                  'hashottuborspa',
                                                  'fireplaceflag',
                                                  'threequarterbathnbr',
                                                  'calcu{\ldots}
features\_to\_scale=Index(['yardbuildingsqft17', 'fireplacecnt', 'poolcnt',
'garagecarcnt',
       'garagetotalsqft', 'poolsizesum', 'unitcnt', 'buildingqualitytypeid',
       'lotsizesquarefeet', 'bathroomcnt', 'bedroomcnt',
       'calculatedfinishedsquarefeet', 'structuretaxvaluedollarcnt',
       'landtaxvaluedollarcnt', 'latitude', 'longitude', 'house\_age'],
      dtype='object'))),
                ('skew\_transformer', BoxCoxSkewedFeatures())],
         verbose=True)
\end{Verbatim}
\end{tcolorbox}
        
    \begin{tcolorbox}[breakable, size=fbox, boxrule=1pt, pad at break*=1mm,colback=cellbackground, colframe=cellborder]
\prompt{In}{incolor}{36}{\boxspacing}
\begin{Verbatim}[commandchars=\\\{\}]
\PY{n}{X\PYZus{}lin} \PY{o}{=} \PY{n}{X\PYZus{}prepared}\PY{o}{.}\PY{n}{copy}\PY{p}{(}\PY{p}{)}
\PY{n}{X\PYZus{}lin\PYZus{}val} \PY{o}{=} \PY{n}{X\PYZus{}prepared\PYZus{}val}\PY{o}{.}\PY{n}{copy}\PY{p}{(}\PY{p}{)}
\end{Verbatim}
\end{tcolorbox}

    \hypertarget{model-evaluation}{%
\subsection{Model Evaluation}\label{model-evaluation}}

\hypertarget{baseline-metrics}{%
\subsubsection{Baseline Metrics}\label{baseline-metrics}}

It is important to set a baseline for the model's performance to compare
different algorithms.

For this regression problem, we will use the models' \textbf{MAE (Mean
Absolute Error)} and \textbf{RMSE (Root Mean Squared Error)}.

We will observe the RMSE as another evaluation metric which punishes
more for outliers than MAE.

    \begin{tcolorbox}[breakable, size=fbox, boxrule=1pt, pad at break*=1mm,colback=cellbackground, colframe=cellborder]
\prompt{In}{incolor}{37}{\boxspacing}
\begin{Verbatim}[commandchars=\\\{\}]
\PY{k+kn}{from} \PY{n+nn}{sklearn}\PY{n+nn}{.}\PY{n+nn}{linear\PYZus{}model} \PY{k+kn}{import} \PY{n}{LinearRegression}\PY{p}{,} \PY{n}{Ridge}\PY{p}{,} \PY{n}{Lasso}\PY{p}{,} \PY{n}{ElasticNet}
\PY{k+kn}{from} \PY{n+nn}{sklearn}\PY{n+nn}{.}\PY{n+nn}{linear\PYZus{}model} \PY{k+kn}{import} \PY{n}{RidgeCV}\PY{p}{,} \PY{n}{LassoCV}\PY{p}{,} \PY{n}{ElasticNetCV}
\PY{k+kn}{from} \PY{n+nn}{sklearn}\PY{n+nn}{.}\PY{n+nn}{model\PYZus{}selection} \PY{k+kn}{import} \PY{n}{cross\PYZus{}val\PYZus{}score}
\PY{k+kn}{from} \PY{n+nn}{sklearn}\PY{n+nn}{.}\PY{n+nn}{metrics} \PY{k+kn}{import} \PY{n}{mean\PYZus{}squared\PYZus{}error}\PY{p}{,} \PY{n}{mean\PYZus{}absolute\PYZus{}error}\PY{p}{,} \PY{n}{make\PYZus{}scorer}
\end{Verbatim}
\end{tcolorbox}

    \begin{tcolorbox}[breakable, size=fbox, boxrule=1pt, pad at break*=1mm,colback=cellbackground, colframe=cellborder]
\prompt{In}{incolor}{38}{\boxspacing}
\begin{Verbatim}[commandchars=\\\{\}]
\PY{n+nb}{print}\PY{p}{(}\PY{l+s+sa}{f}\PY{l+s+s2}{\PYZdq{}}\PY{l+s+s2}{MAE Baseline: }\PY{l+s+si}{\PYZob{}}\PY{n}{y\PYZus{}train}\PY{o}{.}\PY{n}{mad}\PY{p}{(}\PY{p}{)}\PY{l+s+si}{\PYZcb{}}\PY{l+s+s2}{\PYZdq{}}\PY{p}{)}
\PY{n+nb}{print}\PY{p}{(}\PY{l+s+sa}{f}\PY{l+s+s2}{\PYZdq{}}\PY{l+s+s2}{RMSE Baseline: }\PY{l+s+si}{\PYZob{}}\PY{n}{y\PYZus{}train}\PY{o}{.}\PY{n}{std}\PY{p}{(}\PY{p}{)}\PY{l+s+si}{\PYZcb{}}\PY{l+s+s2}{\PYZdq{}}\PY{p}{)}
\end{Verbatim}
\end{tcolorbox}

    \begin{Verbatim}[commandchars=\\\{\}]
MAE Baseline: 0.050452884735592965
RMSE Baseline: 0.07624165410510253
    \end{Verbatim}

    \hypertarget{mae-evaluation}{%
\subsubsection{MAE Evaluation}\label{mae-evaluation}}

To evaluate and short list the most promising models, we will use the
models' \textbf{MAE} in two different ways:

\begin{enumerate}
\def\labelenumi{\arabic{enumi})}
\tightlist
\item
  \textbf{MAE on Validation Set}
\item
  \textbf{K-Fold Cross-Validation}
\end{enumerate}

    \begin{tcolorbox}[breakable, size=fbox, boxrule=1pt, pad at break*=1mm,colback=cellbackground, colframe=cellborder]
\prompt{In}{incolor}{39}{\boxspacing}
\begin{Verbatim}[commandchars=\\\{\}]
\PY{k}{def} \PY{n+nf}{get\PYZus{}eval\PYZus{}metrics}\PY{p}{(}\PY{n}{models}\PY{p}{,} \PY{n}{X}\PY{p}{,} \PY{n}{y\PYZus{}true}\PY{p}{)}\PY{p}{:} 
    \PY{l+s+sd}{\PYZdq{}\PYZdq{}\PYZdq{}}
\PY{l+s+sd}{    Calculates MAE (Mean Absoulate Error) and RMSE (Root Mean Squared Error) on the data set for input models. }
\PY{l+s+sd}{    `models`: list of fit models }
\PY{l+s+sd}{    \PYZdq{}\PYZdq{}\PYZdq{}}
    \PY{k}{for} \PY{n}{model} \PY{o+ow}{in} \PY{n}{models}\PY{p}{:} 
        \PY{n}{y\PYZus{}pred}\PY{o}{=} \PY{n}{model}\PY{o}{.}\PY{n}{predict}\PY{p}{(}\PY{n}{X}\PY{p}{)}
        \PY{n}{rmse} \PY{o}{=} \PY{n}{mean\PYZus{}squared\PYZus{}error}\PY{p}{(}\PY{n}{y\PYZus{}true}\PY{p}{,} \PY{n}{y\PYZus{}pred}\PY{p}{,} \PY{n}{squared}\PY{o}{=}\PY{k+kc}{False}\PY{p}{)}
        \PY{n}{mae} \PY{o}{=} \PY{n}{mean\PYZus{}absolute\PYZus{}error}\PY{p}{(}\PY{n}{y\PYZus{}true}\PY{p}{,} \PY{n}{y\PYZus{}pred}\PY{p}{)}
        \PY{n+nb}{print}\PY{p}{(}\PY{l+s+sa}{f}\PY{l+s+s2}{\PYZdq{}}\PY{l+s+s2}{Model: }\PY{l+s+si}{\PYZob{}}\PY{n}{model}\PY{l+s+si}{\PYZcb{}}\PY{l+s+s2}{\PYZdq{}}\PY{p}{)}
        \PY{n+nb}{print}\PY{p}{(}\PY{l+s+sa}{f}\PY{l+s+s2}{\PYZdq{}}\PY{l+s+s2}{MAE: }\PY{l+s+si}{\PYZob{}}\PY{n}{mae}\PY{l+s+si}{\PYZcb{}}\PY{l+s+s2}{, RMSE: }\PY{l+s+si}{\PYZob{}}\PY{n}{rmse}\PY{l+s+si}{\PYZcb{}}\PY{l+s+s2}{\PYZdq{}}\PY{p}{)}
        \PY{k}{return} \PY{n}{mae}

\PY{k}{def} \PY{n+nf}{display\PYZus{}scores}\PY{p}{(}\PY{n}{model}\PY{p}{,} \PY{n}{scores}\PY{p}{)}\PY{p}{:}
    \PY{n+nb}{print}\PY{p}{(}\PY{l+s+s2}{\PYZdq{}}\PY{l+s+s2}{\PYZhy{}}\PY{l+s+s2}{\PYZdq{}}\PY{o}{*}\PY{l+m+mi}{50}\PY{p}{)}
    \PY{n+nb}{print}\PY{p}{(}\PY{l+s+s2}{\PYZdq{}}\PY{l+s+s2}{Model:}\PY{l+s+s2}{\PYZdq{}}\PY{p}{,} \PY{n}{model}\PY{p}{)}
    \PY{n+nb}{print}\PY{p}{(}\PY{l+s+s2}{\PYZdq{}}\PY{l+s+se}{\PYZbs{}n}\PY{l+s+s2}{Scores:}\PY{l+s+s2}{\PYZdq{}}\PY{p}{,} \PY{n}{scores}\PY{p}{)}
    \PY{n+nb}{print}\PY{p}{(}\PY{l+s+s2}{\PYZdq{}}\PY{l+s+se}{\PYZbs{}n}\PY{l+s+s2}{Mean:}\PY{l+s+s2}{\PYZdq{}}\PY{p}{,} \PY{n}{scores}\PY{o}{.}\PY{n}{mean}\PY{p}{(}\PY{p}{)}\PY{p}{)}
    \PY{n+nb}{print}\PY{p}{(}\PY{l+s+s2}{\PYZdq{}}\PY{l+s+se}{\PYZbs{}n}\PY{l+s+s2}{Standard deviation:}\PY{l+s+s2}{\PYZdq{}}\PY{p}{,} \PY{n}{scores}\PY{o}{.}\PY{n}{std}\PY{p}{(}\PY{p}{)}\PY{p}{)}
    
\PY{k}{def} \PY{n+nf}{get\PYZus{}cross\PYZus{}val\PYZus{}scores}\PY{p}{(}\PY{n}{models}\PY{p}{,} \PY{n}{X}\PY{p}{,} \PY{n}{y}\PY{p}{,} \PY{n}{cv}\PY{o}{=}\PY{l+m+mi}{10}\PY{p}{,} \PY{n}{fit\PYZus{}params}\PY{o}{=}\PY{k+kc}{None}\PY{p}{)}\PY{p}{:}
    \PY{l+s+sd}{\PYZdq{}\PYZdq{}\PYZdq{}}
\PY{l+s+sd}{    Performs k\PYZhy{}fold cross validation and calculates MAE for each fold for all input models. }
\PY{l+s+sd}{    `models`: list of fit models }
\PY{l+s+sd}{    \PYZdq{}\PYZdq{}\PYZdq{}}    
    \PY{n}{maes} \PY{o}{=} \PY{p}{[}\PY{p}{]}
    \PY{k}{for} \PY{n}{model} \PY{o+ow}{in} \PY{n}{models}\PY{p}{:} 
        \PY{n}{mae} \PY{o}{=} \PY{o}{\PYZhy{}}\PY{n}{cross\PYZus{}val\PYZus{}score}\PY{p}{(}\PY{n}{model}\PY{p}{,} \PY{n}{X}\PY{p}{,} \PY{n}{y}\PY{p}{,} \PY{n}{scoring}\PY{o}{=}\PY{l+s+s2}{\PYZdq{}}\PY{l+s+s2}{neg\PYZus{}mean\PYZus{}absolute\PYZus{}error}\PY{l+s+s2}{\PYZdq{}}\PY{p}{,} \PY{n}{cv}\PY{o}{=}\PY{n}{cv}\PY{p}{,} \PY{n}{fit\PYZus{}params}\PY{o}{=}\PY{n}{fit\PYZus{}params}\PY{p}{)}
        \PY{n}{display\PYZus{}scores}\PY{p}{(}\PY{n}{model}\PY{p}{,} \PY{n}{mae}\PY{p}{)} 
        \PY{n}{maes}\PY{o}{.}\PY{n}{append}\PY{p}{(}\PY{n}{mae}\PY{p}{)}
    \PY{k}{return} \PY{n}{maes}
\end{Verbatim}
\end{tcolorbox}

    \begin{tcolorbox}[breakable, size=fbox, boxrule=1pt, pad at break*=1mm,colback=cellbackground, colframe=cellborder]
\prompt{In}{incolor}{40}{\boxspacing}
\begin{Verbatim}[commandchars=\\\{\}]
\PY{o}{\PYZpc{}\PYZpc{}time}
\PY{n}{lin\PYZus{}reg} \PY{o}{=} \PY{n}{LinearRegression}\PY{p}{(}\PY{p}{)}
\PY{n}{lin\PYZus{}reg}\PY{o}{.}\PY{n}{fit}\PY{p}{(}\PY{n}{X\PYZus{}lin}\PY{p}{[}\PY{p}{:}\PY{l+m+mi}{100}\PY{p}{]}\PY{p}{,} \PY{n}{y\PYZus{}train}\PY{p}{[}\PY{p}{:}\PY{l+m+mi}{100}\PY{p}{]}\PY{p}{)}

\PY{n}{utils}\PY{o}{.}\PY{n}{get\PYZus{}eval\PYZus{}metrics}\PY{p}{(}\PY{p}{[}\PY{n}{lin\PYZus{}reg}\PY{p}{]}\PY{p}{,} \PY{n}{X\PYZus{}lin\PYZus{}val}\PY{p}{,} \PY{n}{y\PYZus{}val}\PY{p}{)}
\PY{n}{utils}\PY{o}{.}\PY{n}{get\PYZus{}cross\PYZus{}val\PYZus{}scores}\PY{p}{(}\PY{p}{[}\PY{n}{lin\PYZus{}reg}\PY{p}{]}\PY{p}{,} \PY{n}{X\PYZus{}lin}\PY{p}{,} \PY{n}{y\PYZus{}train}\PY{p}{,} \PY{n}{cv}\PY{o}{=}\PY{l+m+mi}{5}\PY{p}{)}
\end{Verbatim}
\end{tcolorbox}

    \begin{Verbatim}[commandchars=\\\{\}]
Model: LinearRegression()
MAE: 0.0638285210465309, RMSE: 0.08914220933427251
--------------------------------------------------
Model: LinearRegression()

Scores: [5.02252518e-02 4.11147584e+05 2.29951996e+04 4.99420498e-02
 5.00395918e-02]

Mean: 86828.58684028231

Standard deviation: 162403.87797419113
CPU times: total: 13.6 s
Wall time: 6.15 s
    \end{Verbatim}

            \begin{tcolorbox}[breakable, size=fbox, boxrule=.5pt, pad at break*=1mm, opacityfill=0]
\prompt{Out}{outcolor}{40}{\boxspacing}
\begin{Verbatim}[commandchars=\\\{\}]
[array([5.02252518e-02, 4.11147584e+05, 2.29951996e+04, 4.99420498e-02,
        5.00395918e-02])]
\end{Verbatim}
\end{tcolorbox}
        
    \begin{tcolorbox}[breakable, size=fbox, boxrule=1pt, pad at break*=1mm,colback=cellbackground, colframe=cellborder]
\prompt{In}{incolor}{41}{\boxspacing}
\begin{Verbatim}[commandchars=\\\{\}]
\PY{n}{result} \PY{o}{=} \PY{n}{utils}\PY{o}{.}\PY{n}{get\PYZus{}eval\PYZus{}metrics}\PY{p}{(}\PY{p}{[}\PY{n}{lin\PYZus{}reg}\PY{p}{]}\PY{p}{,} \PY{n}{X\PYZus{}lin\PYZus{}val}\PY{p}{,} \PY{n}{y\PYZus{}val}\PY{p}{)}
\PY{n}{results}\PY{p}{[}\PY{l+s+s1}{\PYZsq{}}\PY{l+s+s1}{lin\PYZus{}reg}\PY{l+s+s1}{\PYZsq{}}\PY{p}{]} \PY{o}{=} \PY{n}{result}
\end{Verbatim}
\end{tcolorbox}

    \begin{Verbatim}[commandchars=\\\{\}]
Model: LinearRegression()
MAE: 0.0638285210465309, RMSE: 0.08914220933427251
    \end{Verbatim}

    \begin{tcolorbox}[breakable, size=fbox, boxrule=1pt, pad at break*=1mm,colback=cellbackground, colframe=cellborder]
\prompt{In}{incolor}{42}{\boxspacing}
\begin{Verbatim}[commandchars=\\\{\}]
\PY{n}{y\PYZus{}train\PYZus{}prediction} \PY{o}{=} \PY{n}{lin\PYZus{}reg}\PY{o}{.}\PY{n}{predict}\PY{p}{(}\PY{n}{X\PYZus{}lin}\PY{p}{)}
\PY{n}{y\PYZus{}val\PYZus{}prediction} \PY{o}{=} \PY{n}{lin\PYZus{}reg}\PY{o}{.}\PY{n}{predict}\PY{p}{(}\PY{n}{X\PYZus{}lin\PYZus{}val}\PY{p}{)}

\PY{c+c1}{\PYZsh{} Plot residuals}
\PY{n}{plt}\PY{o}{.}\PY{n}{scatter}\PY{p}{(}\PY{n}{y\PYZus{}train\PYZus{}prediction}\PY{p}{,} \PY{n}{y\PYZus{}train\PYZus{}prediction} \PY{o}{\PYZhy{}} \PY{n}{y\PYZus{}train}\PY{p}{,} \PY{n}{c} \PY{o}{=} \PY{l+s+s2}{\PYZdq{}}\PY{l+s+s2}{blue}\PY{l+s+s2}{\PYZdq{}}\PY{p}{,} \PY{n}{marker} \PY{o}{=} \PY{l+s+s2}{\PYZdq{}}\PY{l+s+s2}{s}\PY{l+s+s2}{\PYZdq{}}\PY{p}{,} \PY{n}{label} \PY{o}{=} \PY{l+s+s2}{\PYZdq{}}\PY{l+s+s2}{Training data}\PY{l+s+s2}{\PYZdq{}}\PY{p}{)}
\PY{n}{plt}\PY{o}{.}\PY{n}{scatter}\PY{p}{(}\PY{n}{y\PYZus{}val\PYZus{}prediction}\PY{p}{,} \PY{n}{y\PYZus{}val\PYZus{}prediction} \PY{o}{\PYZhy{}} \PY{n}{y\PYZus{}val}\PY{p}{,} \PY{n}{c} \PY{o}{=} \PY{l+s+s2}{\PYZdq{}}\PY{l+s+s2}{lightgreen}\PY{l+s+s2}{\PYZdq{}}\PY{p}{,} \PY{n}{marker} \PY{o}{=} \PY{l+s+s2}{\PYZdq{}}\PY{l+s+s2}{s}\PY{l+s+s2}{\PYZdq{}}\PY{p}{,} \PY{n}{label} \PY{o}{=} \PY{l+s+s2}{\PYZdq{}}\PY{l+s+s2}{Validation data}\PY{l+s+s2}{\PYZdq{}}\PY{p}{)}
\PY{n}{plt}\PY{o}{.}\PY{n}{title}\PY{p}{(}\PY{l+s+s2}{\PYZdq{}}\PY{l+s+s2}{Linear regression without regularization}\PY{l+s+s2}{\PYZdq{}}\PY{p}{)}
\PY{n}{plt}\PY{o}{.}\PY{n}{xlabel}\PY{p}{(}\PY{l+s+s2}{\PYZdq{}}\PY{l+s+s2}{Predicted values}\PY{l+s+s2}{\PYZdq{}}\PY{p}{)}
\PY{n}{plt}\PY{o}{.}\PY{n}{ylabel}\PY{p}{(}\PY{l+s+s2}{\PYZdq{}}\PY{l+s+s2}{Residuals}\PY{l+s+s2}{\PYZdq{}}\PY{p}{)}
\PY{n}{plt}\PY{o}{.}\PY{n}{legend}\PY{p}{(}\PY{n}{loc} \PY{o}{=} \PY{l+s+s2}{\PYZdq{}}\PY{l+s+s2}{upper left}\PY{l+s+s2}{\PYZdq{}}\PY{p}{)}
\PY{n}{plt}\PY{o}{.}\PY{n}{show}\PY{p}{(}\PY{p}{)}

\PY{c+c1}{\PYZsh{} Plot predictions}
\PY{n}{plt}\PY{o}{.}\PY{n}{scatter}\PY{p}{(}\PY{n}{y\PYZus{}train\PYZus{}prediction}\PY{p}{,} \PY{n}{y\PYZus{}train}\PY{p}{,} \PY{n}{c} \PY{o}{=} \PY{l+s+s2}{\PYZdq{}}\PY{l+s+s2}{blue}\PY{l+s+s2}{\PYZdq{}}\PY{p}{,} \PY{n}{marker} \PY{o}{=} \PY{l+s+s2}{\PYZdq{}}\PY{l+s+s2}{s}\PY{l+s+s2}{\PYZdq{}}\PY{p}{,} \PY{n}{label} \PY{o}{=} \PY{l+s+s2}{\PYZdq{}}\PY{l+s+s2}{Training data}\PY{l+s+s2}{\PYZdq{}}\PY{p}{)}
\PY{n}{plt}\PY{o}{.}\PY{n}{scatter}\PY{p}{(}\PY{n}{y\PYZus{}val\PYZus{}prediction}\PY{p}{,} \PY{n}{y\PYZus{}val}\PY{p}{,} \PY{n}{c} \PY{o}{=} \PY{l+s+s2}{\PYZdq{}}\PY{l+s+s2}{lightgreen}\PY{l+s+s2}{\PYZdq{}}\PY{p}{,} \PY{n}{marker} \PY{o}{=} \PY{l+s+s2}{\PYZdq{}}\PY{l+s+s2}{s}\PY{l+s+s2}{\PYZdq{}}\PY{p}{,} \PY{n}{label} \PY{o}{=} \PY{l+s+s2}{\PYZdq{}}\PY{l+s+s2}{Validation data}\PY{l+s+s2}{\PYZdq{}}\PY{p}{)}
\PY{n}{plt}\PY{o}{.}\PY{n}{title}\PY{p}{(}\PY{l+s+s2}{\PYZdq{}}\PY{l+s+s2}{Linear regression without regularization}\PY{l+s+s2}{\PYZdq{}}\PY{p}{)}
\PY{n}{plt}\PY{o}{.}\PY{n}{xlabel}\PY{p}{(}\PY{l+s+s2}{\PYZdq{}}\PY{l+s+s2}{Predicted values}\PY{l+s+s2}{\PYZdq{}}\PY{p}{)}
\PY{n}{plt}\PY{o}{.}\PY{n}{ylabel}\PY{p}{(}\PY{l+s+s2}{\PYZdq{}}\PY{l+s+s2}{Real values}\PY{l+s+s2}{\PYZdq{}}\PY{p}{)}
\PY{n}{plt}\PY{o}{.}\PY{n}{legend}\PY{p}{(}\PY{n}{loc} \PY{o}{=} \PY{l+s+s2}{\PYZdq{}}\PY{l+s+s2}{upper left}\PY{l+s+s2}{\PYZdq{}}\PY{p}{)}
\PY{n}{plt}\PY{o}{.}\PY{n}{show}\PY{p}{(}\PY{p}{)}

\PY{c+c1}{\PYZsh{} Plot important coefficients}
\PY{n}{coefs} \PY{o}{=} \PY{n}{pd}\PY{o}{.}\PY{n}{Series}\PY{p}{(}\PY{n}{lin\PYZus{}reg}\PY{o}{.}\PY{n}{coef\PYZus{}}\PY{p}{,} \PY{n}{index} \PY{o}{=} \PY{n}{X\PYZus{}lin}\PY{o}{.}\PY{n}{columns}\PY{p}{)}
\PY{n+nb}{print}\PY{p}{(}\PY{l+s+s2}{\PYZdq{}}\PY{l+s+s2}{Linear Regression picked }\PY{l+s+s2}{\PYZdq{}} \PY{o}{+} \PY{n+nb}{str}\PY{p}{(}\PY{n+nb}{sum}\PY{p}{(}\PY{n}{coefs} \PY{o}{!=} \PY{l+m+mi}{0}\PY{p}{)}\PY{p}{)} \PY{o}{+} \PY{l+s+s2}{\PYZdq{}}\PY{l+s+s2}{ features and eliminated the other }\PY{l+s+s2}{\PYZdq{}} \PY{o}{+}  \PYZbs{}
      \PY{n+nb}{str}\PY{p}{(}\PY{n+nb}{sum}\PY{p}{(}\PY{n}{coefs} \PY{o}{==} \PY{l+m+mi}{0}\PY{p}{)}\PY{p}{)} \PY{o}{+} \PY{l+s+s2}{\PYZdq{}}\PY{l+s+s2}{ features}\PY{l+s+s2}{\PYZdq{}}\PY{p}{)}
\PY{n}{imp\PYZus{}coefs} \PY{o}{=} \PY{n}{pd}\PY{o}{.}\PY{n}{concat}\PY{p}{(}\PY{p}{[}\PY{n}{coefs}\PY{o}{.}\PY{n}{sort\PYZus{}values}\PY{p}{(}\PY{p}{)}\PY{o}{.}\PY{n}{head}\PY{p}{(}\PY{l+m+mi}{10}\PY{p}{)}\PY{p}{,}
                     \PY{n}{coefs}\PY{o}{.}\PY{n}{sort\PYZus{}values}\PY{p}{(}\PY{p}{)}\PY{o}{.}\PY{n}{tail}\PY{p}{(}\PY{l+m+mi}{10}\PY{p}{)}\PY{p}{]}\PY{p}{)}
\PY{n}{imp\PYZus{}coefs}\PY{o}{.}\PY{n}{plot}\PY{p}{(}\PY{n}{kind} \PY{o}{=} \PY{l+s+s2}{\PYZdq{}}\PY{l+s+s2}{barh}\PY{l+s+s2}{\PYZdq{}}\PY{p}{)}
\PY{n}{plt}\PY{o}{.}\PY{n}{title}\PY{p}{(}\PY{l+s+s2}{\PYZdq{}}\PY{l+s+s2}{Coefficients in the Linear Regression Model}\PY{l+s+s2}{\PYZdq{}}\PY{p}{)}
\PY{n}{plt}\PY{o}{.}\PY{n}{show}\PY{p}{(}\PY{p}{)}
\end{Verbatim}
\end{tcolorbox}

    \begin{center}
    \adjustimage{max size={0.9\linewidth}{0.9\paperheight}}{output_70_0.png}
    \end{center}
    { \hspace*{\fill} \\}
    
    \begin{center}
    \adjustimage{max size={0.9\linewidth}{0.9\paperheight}}{output_70_1.png}
    \end{center}
    { \hspace*{\fill} \\}
    
    \begin{Verbatim}[commandchars=\\\{\}]
Linear Regression picked 49 features and eliminated the other 10 features
    \end{Verbatim}

    \begin{center}
    \adjustimage{max size={0.9\linewidth}{0.9\paperheight}}{output_70_3.png}
    \end{center}
    { \hspace*{\fill} \\}
    
    \hypertarget{learning-curves}{%
\subsubsection{Learning Curves}\label{learning-curves}}

To detect where the model is under or overfitting, we can look at the
\emph{learning curves}.

    \begin{tcolorbox}[breakable, size=fbox, boxrule=1pt, pad at break*=1mm,colback=cellbackground, colframe=cellborder]
\prompt{In}{incolor}{43}{\boxspacing}
\begin{Verbatim}[commandchars=\\\{\}]
\PY{k+kn}{from} \PY{n+nn}{sklearn}\PY{n+nn}{.}\PY{n+nn}{metrics} \PY{k+kn}{import} \PY{n}{mean\PYZus{}squared\PYZus{}error}
\PY{k+kn}{from} \PY{n+nn}{sklearn}\PY{n+nn}{.}\PY{n+nn}{model\PYZus{}selection} \PY{k+kn}{import} \PY{n}{train\PYZus{}test\PYZus{}split}

\PY{k}{def} \PY{n+nf}{plot\PYZus{}learning\PYZus{}curves}\PY{p}{(}\PY{n}{model}\PY{p}{,} \PY{n}{X\PYZus{}train}\PY{p}{,} \PY{n}{y\PYZus{}train}\PY{p}{,} \PY{n}{X\PYZus{}val}\PY{p}{,} \PY{n}{y\PYZus{}val}\PY{p}{)}\PY{p}{:}
    \PY{l+s+sd}{\PYZdq{}\PYZdq{}\PYZdq{}}
\PY{l+s+sd}{    Train the input model on different sized subsets and test on validation set. }
\PY{l+s+sd}{    Output a plot of training and validation error for the different sized subsets. }
\PY{l+s+sd}{    \PYZdq{}\PYZdq{}\PYZdq{}}
    \PY{n}{train\PYZus{}errors}\PY{p}{,} \PY{n}{val\PYZus{}errors} \PY{o}{=} \PY{p}{[}\PY{p}{]}\PY{p}{,} \PY{p}{[}\PY{p}{]}
    \PY{n}{num\PYZus{}instances} \PY{o}{=} \PY{n}{np}\PY{o}{.}\PY{n}{linspace}\PY{p}{(}\PY{l+m+mi}{1}\PY{p}{,} \PY{n+nb}{len}\PY{p}{(}\PY{n}{X\PYZus{}train}\PY{p}{)}\PY{p}{,} \PY{n}{num}\PY{o}{=}\PY{l+m+mi}{15}\PY{p}{)}\PY{o}{.}\PY{n}{astype}\PY{p}{(}\PY{n+nb}{int}\PY{p}{)}
    
    \PY{k}{for} \PY{n}{m} \PY{o+ow}{in} \PY{n}{num\PYZus{}instances}\PY{p}{:}
        \PY{n}{model}\PY{o}{.}\PY{n}{fit}\PY{p}{(}\PY{n}{X\PYZus{}train}\PY{p}{[}\PY{p}{:}\PY{n}{m}\PY{p}{]}\PY{p}{,} \PY{n}{y\PYZus{}train}\PY{p}{[}\PY{p}{:}\PY{n}{m}\PY{p}{]}\PY{p}{)}
        \PY{n}{y\PYZus{}train\PYZus{}predict} \PY{o}{=} \PY{n}{model}\PY{o}{.}\PY{n}{predict}\PY{p}{(}\PY{n}{X\PYZus{}train}\PY{p}{[}\PY{p}{:}\PY{n}{m}\PY{p}{]}\PY{p}{)}
        \PY{n}{y\PYZus{}val\PYZus{}predict} \PY{o}{=} \PY{n}{model}\PY{o}{.}\PY{n}{predict}\PY{p}{(}\PY{n}{X\PYZus{}val}\PY{p}{)}
        \PY{n}{train\PYZus{}errors}\PY{o}{.}\PY{n}{append}\PY{p}{(}\PY{n}{mean\PYZus{}absolute\PYZus{}error}\PY{p}{(}\PY{n}{y\PYZus{}train}\PY{p}{[}\PY{p}{:}\PY{n}{m}\PY{p}{]}\PY{p}{,} \PY{n}{y\PYZus{}train\PYZus{}predict}\PY{p}{)}\PY{p}{)}
        \PY{n}{val\PYZus{}errors}\PY{o}{.}\PY{n}{append}\PY{p}{(}\PY{n}{mean\PYZus{}absolute\PYZus{}error}\PY{p}{(}\PY{n}{y\PYZus{}val}\PY{p}{,} \PY{n}{y\PYZus{}val\PYZus{}predict}\PY{p}{)}\PY{p}{)}
    \PY{n}{plt}\PY{o}{.}\PY{n}{plot}\PY{p}{(}\PY{n}{num\PYZus{}instances}\PY{p}{,} \PY{n}{train\PYZus{}errors}\PY{p}{,} \PY{l+s+s2}{\PYZdq{}}\PY{l+s+s2}{r\PYZhy{}+}\PY{l+s+s2}{\PYZdq{}}\PY{p}{,} \PY{n}{linewidth}\PY{o}{=}\PY{l+m+mi}{2}\PY{p}{,} \PY{n}{label}\PY{o}{=}\PY{l+s+s2}{\PYZdq{}}\PY{l+s+s2}{train}\PY{l+s+s2}{\PYZdq{}}\PY{p}{)}
    \PY{n}{plt}\PY{o}{.}\PY{n}{plot}\PY{p}{(}\PY{n}{num\PYZus{}instances}\PY{p}{,} \PY{n}{val\PYZus{}errors}\PY{p}{,} \PY{l+s+s2}{\PYZdq{}}\PY{l+s+s2}{b\PYZhy{}}\PY{l+s+s2}{\PYZdq{}}\PY{p}{,} \PY{n}{linewidth}\PY{o}{=}\PY{l+m+mi}{3}\PY{p}{,} \PY{n}{label}\PY{o}{=}\PY{l+s+s2}{\PYZdq{}}\PY{l+s+s2}{val}\PY{l+s+s2}{\PYZdq{}}\PY{p}{)}
    \PY{n}{plt}\PY{o}{.}\PY{n}{legend}\PY{p}{(}\PY{n}{loc}\PY{o}{=}\PY{l+s+s1}{\PYZsq{}}\PY{l+s+s1}{best}\PY{l+s+s1}{\PYZsq{}}\PY{p}{)}
    \PY{n}{plt}\PY{o}{.}\PY{n}{title}\PY{p}{(}\PY{n}{model}\PY{p}{)}
    \PY{k}{return} \PY{n}{plt}
\end{Verbatim}
\end{tcolorbox}

    \begin{tcolorbox}[breakable, size=fbox, boxrule=1pt, pad at break*=1mm,colback=cellbackground, colframe=cellborder]
\prompt{In}{incolor}{44}{\boxspacing}
\begin{Verbatim}[commandchars=\\\{\}]
\PY{n}{lin\PYZus{}reg} \PY{o}{=} \PY{n}{LinearRegression}\PY{p}{(}\PY{p}{)}
\PY{n}{plt} \PY{o}{=} \PY{n}{plot\PYZus{}learning\PYZus{}curves}\PY{p}{(}\PY{n}{lin\PYZus{}reg}\PY{p}{,} \PY{n}{X\PYZus{}prepared}\PY{p}{,} \PY{n}{y\PYZus{}train}\PY{p}{,} \PY{n}{X\PYZus{}prepared\PYZus{}val}\PY{p}{,} \PY{n}{y\PYZus{}val}\PY{p}{)}
\PY{n}{plt}\PY{o}{.}\PY{n}{ylim}\PY{p}{(}\PY{l+m+mi}{0}\PY{p}{,} \PY{l+m+mf}{0.25}\PY{p}{)} 
\PY{n}{plt}\PY{o}{.}\PY{n}{show}\PY{p}{(}\PY{p}{)}
\end{Verbatim}
\end{tcolorbox}

    \begin{center}
    \adjustimage{max size={0.9\linewidth}{0.9\paperheight}}{output_73_0.png}
    \end{center}
    { \hspace*{\fill} \\}
    
    \hypertarget{learning-curve-conclusion-for-linear-regression}{%
\subsubsection{Learning Curve Conclusion for Linear
Regression}\label{learning-curve-conclusion-for-linear-regression}}

\begin{itemize}
\tightlist
\item
  The model is not overfitting as the MAE error observed for both the
  validation and training sets is extremely close (errors would be
  different between \texttt{train} and \texttt{val} datasets if the
  model were overfitting with the \texttt{train} dataset, thus showing
  lower MAE values.
\end{itemize}

    \hypertarget{b-ridge-and-lasso-regression}{%
\subsection{1b) Ridge and Lasso
Regression}\label{b-ridge-and-lasso-regression}}

Since the Ridge and Lasso models' performance is highly affected by the
chosen \texttt{alpha} value, we need to tune its value to find the
optimal \texttt{alpha} for the given problem.

\textbf{NOTE}: \textbf{In this case, any of the Regularized Linear
Models will NOT perform any better than the Simple Linear Regression.
Regularized models help reduce overfitting and we have already
established that our current Linear Model is underfitting.}

    \begin{tcolorbox}[breakable, size=fbox, boxrule=1pt, pad at break*=1mm,colback=cellbackground, colframe=cellborder]
\prompt{In}{incolor}{45}{\boxspacing}
\begin{Verbatim}[commandchars=\\\{\}]
\PY{o}{\PYZpc{}\PYZpc{}time}

\PY{c+c1}{\PYZsh{} Set of alpha values to test}
\PY{n}{alphas} \PY{o}{=} \PY{n}{np}\PY{o}{.}\PY{n}{logspace}\PY{p}{(}\PY{l+m+mi}{0}\PY{p}{,}\PY{l+m+mi}{2}\PY{p}{,}\PY{l+m+mi}{20}\PY{p}{)}
\PY{n+nb}{print}\PY{p}{(}\PY{l+s+sa}{f}\PY{l+s+s2}{\PYZdq{}}\PY{l+s+s2}{Testing with alphas=}\PY{l+s+si}{\PYZob{}}\PY{n}{alphas}\PY{l+s+si}{\PYZcb{}}\PY{l+s+s2}{\PYZdq{}}\PY{p}{)}


\PY{c+c1}{\PYZsh{} Tune Ridge Regression}
\PY{n}{ridgecv} \PY{o}{=} \PY{n}{RidgeCV}\PY{p}{(}\PY{n}{alphas}\PY{o}{=}\PY{n}{alphas}\PY{p}{)}
\PY{n}{ridgecv}\PY{o}{.}\PY{n}{fit}\PY{p}{(}\PY{n}{X\PYZus{}prepared}\PY{p}{,} \PY{n}{y\PYZus{}train}\PY{p}{)}
\PY{n+nb}{print}\PY{p}{(}\PY{l+s+sa}{f}\PY{l+s+s2}{\PYZdq{}}\PY{l+s+s2}{Best Ridge Alpha: }\PY{l+s+si}{\PYZob{}}\PY{n}{ridgecv}\PY{o}{.}\PY{n}{alpha\PYZus{}}\PY{l+s+si}{\PYZcb{}}\PY{l+s+s2}{\PYZdq{}}\PY{p}{)}
\end{Verbatim}
\end{tcolorbox}

    \begin{Verbatim}[commandchars=\\\{\}]
Testing with alphas=[  1.           1.27427499   1.62377674   2.06913808
2.6366509
   3.35981829   4.2813324    5.45559478   6.95192796   8.8586679
  11.28837892  14.38449888  18.32980711  23.35721469  29.76351442
  37.92690191  48.32930239  61.58482111  78.47599704 100.        ]
Best Ridge Alpha: 37.926901907322495
CPU times: total: 8.2 s
Wall time: 2.7 s
    \end{Verbatim}

    \begin{tcolorbox}[breakable, size=fbox, boxrule=1pt, pad at break*=1mm,colback=cellbackground, colframe=cellborder]
\prompt{In}{incolor}{46}{\boxspacing}
\begin{Verbatim}[commandchars=\\\{\}]
\PY{o}{\PYZpc{}\PYZpc{}time}

\PY{c+c1}{\PYZsh{} Set of alpha values to test}
\PY{n}{alphas} \PY{o}{=} \PY{n}{np}\PY{o}{.}\PY{n}{logspace}\PY{p}{(}\PY{l+m+mi}{1}\PY{p}{,}\PY{l+m+mi}{5}\PY{p}{,}\PY{l+m+mi}{20}\PY{p}{)}
\PY{n+nb}{print}\PY{p}{(}\PY{l+s+sa}{f}\PY{l+s+s2}{\PYZdq{}}\PY{l+s+s2}{Testing with alphas=}\PY{l+s+si}{\PYZob{}}\PY{n}{alphas}\PY{l+s+si}{\PYZcb{}}\PY{l+s+s2}{\PYZdq{}}\PY{p}{)}


\PY{c+c1}{\PYZsh{} Tune Lasso Regression}
\PY{n}{lassocv} \PY{o}{=} \PY{n}{LassoCV}\PY{p}{(}\PY{n}{alphas}\PY{o}{=}\PY{n}{alphas}\PY{p}{)}
\PY{n}{lassocv}\PY{o}{.}\PY{n}{fit}\PY{p}{(}\PY{n}{X\PYZus{}prepared}\PY{p}{,} \PY{n}{y\PYZus{}train}\PY{p}{)}
\PY{n+nb}{print}\PY{p}{(}\PY{l+s+sa}{f}\PY{l+s+s2}{\PYZdq{}}\PY{l+s+s2}{Best Lasso Alpha: }\PY{l+s+si}{\PYZob{}}\PY{n}{lassocv}\PY{o}{.}\PY{n}{alpha\PYZus{}}\PY{l+s+si}{\PYZcb{}}\PY{l+s+s2}{\PYZdq{}}\PY{p}{)}
\end{Verbatim}
\end{tcolorbox}

    \begin{Verbatim}[commandchars=\\\{\}]
Testing with alphas=[1.00000000e+01 1.62377674e+01 2.63665090e+01 4.28133240e+01
 6.95192796e+01 1.12883789e+02 1.83298071e+02 2.97635144e+02
 4.83293024e+02 7.84759970e+02 1.27427499e+03 2.06913808e+03
 3.35981829e+03 5.45559478e+03 8.85866790e+03 1.43844989e+04
 2.33572147e+04 3.79269019e+04 6.15848211e+04 1.00000000e+05]
Best Lasso Alpha: 100000.0
CPU times: total: 5.31 s
Wall time: 2.1 s
    \end{Verbatim}

    \begin{tcolorbox}[breakable, size=fbox, boxrule=1pt, pad at break*=1mm,colback=cellbackground, colframe=cellborder]
\prompt{In}{incolor}{47}{\boxspacing}
\begin{Verbatim}[commandchars=\\\{\}]
\PY{o}{\PYZpc{}\PYZpc{}time} 
\PY{c+c1}{\PYZsh{} Fit using optimal alpha}
\PY{n}{ridge} \PY{o}{=} \PY{n}{Ridge}\PY{p}{(}\PY{n}{alpha}\PY{o}{=}\PY{n}{ridgecv}\PY{o}{.}\PY{n}{alpha\PYZus{}}\PY{p}{)}
\PY{n}{ridge}\PY{o}{.}\PY{n}{fit}\PY{p}{(}\PY{n}{X\PYZus{}lin}\PY{p}{,} \PY{n}{y\PYZus{}train}\PY{p}{)}

\PY{n}{lasso} \PY{o}{=} \PY{n}{Lasso}\PY{p}{(}\PY{n}{alpha}\PY{o}{=}\PY{n}{lassocv}\PY{o}{.}\PY{n}{alpha\PYZus{}}\PY{p}{)}
\PY{n}{lasso}\PY{o}{.}\PY{n}{fit}\PY{p}{(}\PY{n}{X\PYZus{}lin}\PY{p}{,} \PY{n}{y\PYZus{}train}\PY{p}{)}

\PY{c+c1}{\PYZsh{} utils.get\PYZus{}eval\PYZus{}metrics([ridge, lasso], X\PYZus{}lin\PYZus{}val, y\PYZus{}val)}
\PY{n}{utils}\PY{o}{.}\PY{n}{get\PYZus{}cross\PYZus{}val\PYZus{}scores}\PY{p}{(}\PY{p}{[}\PY{n}{ridge}\PY{p}{,} \PY{n}{lasso}\PY{p}{]}\PY{p}{,} \PY{n}{X\PYZus{}lin}\PY{p}{,} \PY{n}{y\PYZus{}train}\PY{p}{,} \PY{n}{cv}\PY{o}{=}\PY{l+m+mi}{5}\PY{p}{)}
\end{Verbatim}
\end{tcolorbox}

    \begin{Verbatim}[commandchars=\\\{\}]
--------------------------------------------------
Model: Ridge(alpha=37.926901907322495)

Scores: [0.05022134 0.0502121  0.05069803 0.0499109  0.05002422]

Mean: 0.050213316520987816

Standard deviation: 0.00026915765734012863
--------------------------------------------------
Model: Lasso(alpha=100000.0)

Scores: [0.05050908 0.05032806 0.05089881 0.05022955 0.05029943]

Mean: 0.05045298759670745

Standard deviation: 0.00024125080636937485
CPU times: total: 21.1 s
Wall time: 13.2 s
    \end{Verbatim}

            \begin{tcolorbox}[breakable, size=fbox, boxrule=.5pt, pad at break*=1mm, opacityfill=0]
\prompt{Out}{outcolor}{47}{\boxspacing}
\begin{Verbatim}[commandchars=\\\{\}]
[array([0.05022134, 0.0502121 , 0.05069803, 0.0499109 , 0.05002422]),
 array([0.05050908, 0.05032806, 0.05089881, 0.05022955, 0.05029943])]
\end{Verbatim}
\end{tcolorbox}
        
    \begin{tcolorbox}[breakable, size=fbox, boxrule=1pt, pad at break*=1mm,colback=cellbackground, colframe=cellborder]
\prompt{In}{incolor}{48}{\boxspacing}
\begin{Verbatim}[commandchars=\\\{\}]
\PY{c+c1}{\PYZsh{} Learning Curves for Ridge and Lasso}
\PY{n}{ridge} \PY{o}{=} \PY{n}{Ridge}\PY{p}{(}\PY{n}{alpha}\PY{o}{=}\PY{n}{ridgecv}\PY{o}{.}\PY{n}{alpha\PYZus{}}\PY{p}{)}
\PY{n}{plt} \PY{o}{=} \PY{n}{plot\PYZus{}learning\PYZus{}curves}\PY{p}{(}\PY{n}{ridge}\PY{p}{,} \PY{n}{X\PYZus{}lin}\PY{p}{,} \PY{n}{y\PYZus{}train}\PY{p}{,} \PY{n}{X\PYZus{}lin\PYZus{}val}\PY{p}{,} \PY{n}{y\PYZus{}val}\PY{p}{)}
\PY{n}{plt}\PY{o}{.}\PY{n}{show}\PY{p}{(}\PY{p}{)}

\PY{n}{lasso} \PY{o}{=} \PY{n}{Lasso}\PY{p}{(}\PY{n}{alpha}\PY{o}{=}\PY{n}{lassocv}\PY{o}{.}\PY{n}{alpha\PYZus{}}\PY{p}{)}
\PY{n}{plt} \PY{o}{=} \PY{n}{plot\PYZus{}learning\PYZus{}curves}\PY{p}{(}\PY{n}{lasso}\PY{p}{,} \PY{n}{X\PYZus{}lin}\PY{p}{,} \PY{n}{y\PYZus{}train}\PY{p}{,} \PY{n}{X\PYZus{}lin\PYZus{}val}\PY{p}{,} \PY{n}{y\PYZus{}val}\PY{p}{)}
\PY{n}{plt}\PY{o}{.}\PY{n}{show}\PY{p}{(}\PY{p}{)}
\end{Verbatim}
\end{tcolorbox}

    \begin{center}
    \adjustimage{max size={0.9\linewidth}{0.9\paperheight}}{output_79_0.png}
    \end{center}
    { \hspace*{\fill} \\}
    
    \begin{center}
    \adjustimage{max size={0.9\linewidth}{0.9\paperheight}}{output_79_1.png}
    \end{center}
    { \hspace*{\fill} \\}
    
    \textbf{As expected, even the regularized Linear Models do not perform
any better. Thus, we need to consider more complex algorithms which make
fewer assumptions to try and understand the relationship between the
features and target variable.}

    \begin{tcolorbox}[breakable, size=fbox, boxrule=1pt, pad at break*=1mm,colback=cellbackground, colframe=cellborder]
\prompt{In}{incolor}{49}{\boxspacing}
\begin{Verbatim}[commandchars=\\\{\}]
\PY{n}{result} \PY{o}{=} \PY{n}{utils}\PY{o}{.}\PY{n}{get\PYZus{}eval\PYZus{}metrics}\PY{p}{(}\PY{p}{[}\PY{n}{ridge}\PY{p}{]}\PY{p}{,} \PY{n}{X\PYZus{}lin\PYZus{}val}\PY{p}{,} \PY{n}{y\PYZus{}val}\PY{p}{)}
\PY{n}{results}\PY{p}{[}\PY{l+s+s1}{\PYZsq{}}\PY{l+s+s1}{ridge}\PY{l+s+s1}{\PYZsq{}}\PY{p}{]} \PY{o}{=} \PY{n}{result}
\PY{n}{result} \PY{o}{=} \PY{n}{utils}\PY{o}{.}\PY{n}{get\PYZus{}eval\PYZus{}metrics}\PY{p}{(}\PY{p}{[}\PY{n}{lasso}\PY{p}{]}\PY{p}{,} \PY{n}{X\PYZus{}lin\PYZus{}val}\PY{p}{,} \PY{n}{y\PYZus{}val}\PY{p}{)}
\PY{n}{results}\PY{p}{[}\PY{l+s+s1}{\PYZsq{}}\PY{l+s+s1}{lasso}\PY{l+s+s1}{\PYZsq{}}\PY{p}{]} \PY{o}{=} \PY{n}{result}
\end{Verbatim}
\end{tcolorbox}

    \begin{Verbatim}[commandchars=\\\{\}]
Model: Ridge(alpha=37.926901907322495)
MAE: 0.04998213389383104, RMSE: 0.07598996170631349
Model: Lasso(alpha=100000.0)
MAE: 0.050153838000011726, RMSE: 0.0762536269593192
    \end{Verbatim}

    \hypertarget{boosting-algorithm}{%
\section{Boosting Algorithm}\label{boosting-algorithm}}

    \hypertarget{missing-data}{%
\subsubsection{Missing Data}\label{missing-data}}

One of most powerful capabilities of Gradient Boosting machines is their
ability to handle missing data. They do not require data imputation and
are designed to extract as much information as possible from the rows
with missing data.

    \hypertarget{xgboost}{%
\section{6 - XGBoost}\label{xgboost}}

    \begin{tcolorbox}[breakable, size=fbox, boxrule=1pt, pad at break*=1mm,colback=cellbackground, colframe=cellborder]
\prompt{In}{incolor}{72}{\boxspacing}
\begin{Verbatim}[commandchars=\\\{\}]
\PY{k+kn}{import} \PY{n+nn}{xgboost} \PY{k}{as} \PY{n+nn}{xgb}
\PY{k+kn}{from} \PY{n+nn}{sklearn}\PY{n+nn}{.}\PY{n+nn}{model\PYZus{}selection} \PY{k+kn}{import} \PY{n}{cross\PYZus{}val\PYZus{}score}
\PY{k+kn}{from} \PY{n+nn}{sklearn}\PY{n+nn}{.}\PY{n+nn}{metrics} \PY{k+kn}{import} \PY{n}{mean\PYZus{}squared\PYZus{}error}\PY{p}{,} \PY{n}{mean\PYZus{}absolute\PYZus{}error}\PY{p}{,} \PY{n}{make\PYZus{}scorer}
\end{Verbatim}
\end{tcolorbox}

    \begin{tcolorbox}[breakable, size=fbox, boxrule=1pt, pad at break*=1mm,colback=cellbackground, colframe=cellborder]
\prompt{In}{incolor}{73}{\boxspacing}
\begin{Verbatim}[commandchars=\\\{\}]
\PY{n}{X\PYZus{}prepared} \PY{o}{=} \PY{n}{X\PYZus{}train}\PY{o}{.}\PY{n}{copy}\PY{p}{(}\PY{p}{)}
\PY{n}{X\PYZus{}prepared\PYZus{}val} \PY{o}{=} \PY{n}{X\PYZus{}val}\PY{o}{.}\PY{n}{copy}\PY{p}{(}\PY{p}{)}
\end{Verbatim}
\end{tcolorbox}

    \begin{tcolorbox}[breakable, size=fbox, boxrule=1pt, pad at break*=1mm,colback=cellbackground, colframe=cellborder]
\prompt{In}{incolor}{74}{\boxspacing}
\begin{Verbatim}[commandchars=\\\{\}]
\PY{c+c1}{\PYZsh{} Feature Dropper Pipeline}
\PY{n}{xgb\PYZus{}drop} \PY{o}{=} \PY{p}{[}\PY{l+s+s1}{\PYZsq{}}\PY{l+s+s1}{parcelid}\PY{l+s+s1}{\PYZsq{}}\PY{p}{]}
\PY{n}{feature\PYZus{}dropper} \PY{o}{=} \PY{n}{utils}\PY{o}{.}\PY{n}{FeatureDropper}\PY{p}{(}\PY{n}{features\PYZus{}to\PYZus{}drop}\PY{o}{=}\PY{n}{xgb\PYZus{}drop}\PY{p}{)}

\PY{c+c1}{\PYZsh{} Convert Year Features Pipeline}
\PY{n}{year\PYZus{}feat\PYZus{}creator} \PY{o}{=} \PY{n}{utils}\PY{o}{.}\PY{n}{CreateYearFeatures}\PY{p}{(}\PY{n}{date\PYZus{}features}\PY{o}{=}\PY{n}{date\PYZus{}features}\PY{p}{)}

\PY{c+c1}{\PYZsh{} Derived Features Creator}
\PY{n}{derived\PYZus{}feat\PYZus{}creator} \PY{o}{=} \PY{n}{utils}\PY{o}{.}\PY{n}{CreateDerivedFeatures}\PY{p}{(}\PY{p}{)}

\PY{c+c1}{\PYZsh{} Date Feature Creator}
\PY{n}{date\PYZus{}feat\PYZus{}creator} \PY{o}{=} \PY{n}{utils}\PY{o}{.}\PY{n}{CreateDateFeatures}\PY{p}{(}\PY{p}{)}

\PY{c+c1}{\PYZsh{} Feature Encoding Pipeline}
\PY{n}{cat\PYZus{}vars} \PY{o}{=} \PY{p}{[}\PY{l+s+s1}{\PYZsq{}}\PY{l+s+s1}{transaction\PYZus{}year}\PY{l+s+s1}{\PYZsq{}}\PY{p}{,} \PY{l+s+s1}{\PYZsq{}}\PY{l+s+s1}{transaction\PYZus{}month}\PY{l+s+s1}{\PYZsq{}}\PY{p}{,} \PY{l+s+s1}{\PYZsq{}}\PY{l+s+s1}{transaction\PYZus{}day}\PY{l+s+s1}{\PYZsq{}}\PY{p}{,} \PY{l+s+s1}{\PYZsq{}}\PY{l+s+s1}{transaction\PYZus{}quarter}\PY{l+s+s1}{\PYZsq{}}\PY{p}{,} 
            \PY{l+s+s1}{\PYZsq{}}\PY{l+s+s1}{airconditioningtypeid}\PY{l+s+s1}{\PYZsq{}}\PY{p}{,} \PY{l+s+s1}{\PYZsq{}}\PY{l+s+s1}{architecturalstyletypeid}\PY{l+s+s1}{\PYZsq{}}\PY{p}{,} \PY{l+s+s1}{\PYZsq{}}\PY{l+s+s1}{buildingclasstypeid}\PY{l+s+s1}{\PYZsq{}}\PY{p}{,} \PY{l+s+s1}{\PYZsq{}}\PY{l+s+s1}{buildingqualitytypeid}\PY{l+s+s1}{\PYZsq{}}\PY{p}{,} 
            \PY{l+s+s1}{\PYZsq{}}\PY{l+s+s1}{decktypeid}\PY{l+s+s1}{\PYZsq{}}\PY{p}{,} \PY{l+s+s1}{\PYZsq{}}\PY{l+s+s1}{fips}\PY{l+s+s1}{\PYZsq{}}\PY{p}{,}  \PY{l+s+s1}{\PYZsq{}}\PY{l+s+s1}{hashottuborspa}\PY{l+s+s1}{\PYZsq{}}\PY{p}{,} \PY{l+s+s1}{\PYZsq{}}\PY{l+s+s1}{heatingorsystemtypeid}\PY{l+s+s1}{\PYZsq{}}\PY{p}{,}  \PY{l+s+s1}{\PYZsq{}}\PY{l+s+s1}{pooltypeid10}\PY{l+s+s1}{\PYZsq{}}\PY{p}{,} \PY{l+s+s1}{\PYZsq{}}\PY{l+s+s1}{pooltypeid2}\PY{l+s+s1}{\PYZsq{}}\PY{p}{,} 
            \PY{l+s+s1}{\PYZsq{}}\PY{l+s+s1}{pooltypeid7}\PY{l+s+s1}{\PYZsq{}}\PY{p}{,} \PY{l+s+s1}{\PYZsq{}}\PY{l+s+s1}{propertycountylandusecode}\PY{l+s+s1}{\PYZsq{}}\PY{p}{,} \PY{l+s+s1}{\PYZsq{}}\PY{l+s+s1}{propertylandusetypeid}\PY{l+s+s1}{\PYZsq{}}\PY{p}{,} \PY{l+s+s1}{\PYZsq{}}\PY{l+s+s1}{propertyzoningdesc}\PY{l+s+s1}{\PYZsq{}}\PY{p}{,} 
            \PY{l+s+s1}{\PYZsq{}}\PY{l+s+s1}{rawcensustractandblock}\PY{l+s+s1}{\PYZsq{}}\PY{p}{,} \PY{l+s+s1}{\PYZsq{}}\PY{l+s+s1}{regionidcity}\PY{l+s+s1}{\PYZsq{}}\PY{p}{,} \PY{l+s+s1}{\PYZsq{}}\PY{l+s+s1}{regionidcounty}\PY{l+s+s1}{\PYZsq{}}\PY{p}{,} \PY{l+s+s1}{\PYZsq{}}\PY{l+s+s1}{regionidneighborhood}\PY{l+s+s1}{\PYZsq{}}\PY{p}{,} \PY{l+s+s1}{\PYZsq{}}\PY{l+s+s1}{regionidzip}\PY{l+s+s1}{\PYZsq{}}\PY{p}{,} 
            \PY{l+s+s1}{\PYZsq{}}\PY{l+s+s1}{storytypeid}\PY{l+s+s1}{\PYZsq{}}\PY{p}{,}  \PY{l+s+s1}{\PYZsq{}}\PY{l+s+s1}{typeconstructiontypeid}\PY{l+s+s1}{\PYZsq{}}\PY{p}{,} \PY{l+s+s1}{\PYZsq{}}\PY{l+s+s1}{fireplaceflag}\PY{l+s+s1}{\PYZsq{}}\PY{p}{,}  \PY{l+s+s1}{\PYZsq{}}\PY{l+s+s1}{assessmentyear}\PY{l+s+s1}{\PYZsq{}}\PY{p}{,} 
            \PY{l+s+s1}{\PYZsq{}}\PY{l+s+s1}{taxdelinquencyflag}\PY{l+s+s1}{\PYZsq{}}\PY{p}{,} \PY{l+s+s1}{\PYZsq{}}\PY{l+s+s1}{taxdelinquencyyear}\PY{l+s+s1}{\PYZsq{}}\PY{p}{,} \PY{l+s+s1}{\PYZsq{}}\PY{l+s+s1}{censustractandblock}\PY{l+s+s1}{\PYZsq{}}\PY{p}{,} \PY{c+c1}{\PYZsh{}\PYZsq{}N\PYZhy{}n\PYZus{}gar\PYZus{}pool\PYZus{}ac\PYZsq{},\PYZsq{}N\PYZhy{}PropType\PYZsq{},\PYZsq{}N\PYZhy{}HeatInd\PYZsq{},\PYZsq{}N\PYZhy{}ACInd\PYZsq{}}
           \PY{p}{]}
\PY{n}{feature\PYZus{}encoder} \PY{o}{=} \PY{n}{utils}\PY{o}{.}\PY{n}{ColumnTransformer}\PY{p}{(}\PY{p}{[}
    \PY{p}{(}\PY{l+s+s2}{\PYZdq{}}\PY{l+s+s2}{ohe\PYZus{}cats}\PY{l+s+s2}{\PYZdq{}}\PY{p}{,} \PY{n}{OneHotEncoder}\PY{p}{(}\PY{n}{handle\PYZus{}unknown}\PY{o}{=}\PY{l+s+s1}{\PYZsq{}}\PY{l+s+s1}{ignore}\PY{l+s+s1}{\PYZsq{}}\PY{p}{)}\PY{p}{,} \PY{n}{cat\PYZus{}vars}\PY{p}{)}
\PY{p}{]}\PY{p}{,}
    \PY{n}{remainder}\PY{o}{=}\PY{l+s+s1}{\PYZsq{}}\PY{l+s+s1}{passthrough}\PY{l+s+s1}{\PYZsq{}}
\PY{p}{)}
\end{Verbatim}
\end{tcolorbox}

    \begin{tcolorbox}[breakable, size=fbox, boxrule=1pt, pad at break*=1mm,colback=cellbackground, colframe=cellborder]
\prompt{In}{incolor}{75}{\boxspacing}
\begin{Verbatim}[commandchars=\\\{\}]
\PY{n}{xgb\PYZus{}preprocessor} \PY{o}{=} \PY{n}{Pipeline}\PY{p}{(}\PY{p}{[}
    \PY{p}{(}\PY{l+s+s1}{\PYZsq{}}\PY{l+s+s1}{feature\PYZus{}dropper}\PY{l+s+s1}{\PYZsq{}}\PY{p}{,} \PY{n}{feature\PYZus{}dropper}\PY{p}{)}\PY{p}{,}
    \PY{p}{(}\PY{l+s+s1}{\PYZsq{}}\PY{l+s+s1}{date\PYZus{}feat\PYZus{}creator}\PY{l+s+s1}{\PYZsq{}}\PY{p}{,} \PY{n}{date\PYZus{}feat\PYZus{}creator}\PY{p}{)}\PY{p}{,}
    \PY{p}{(}\PY{l+s+s1}{\PYZsq{}}\PY{l+s+s1}{year\PYZus{}feat\PYZus{}creator}\PY{l+s+s1}{\PYZsq{}}\PY{p}{,} \PY{n}{year\PYZus{}feat\PYZus{}creator}\PY{p}{)}\PY{p}{,}
    \PY{p}{(}\PY{l+s+s1}{\PYZsq{}}\PY{l+s+s1}{feature\PYZus{}encoder}\PY{l+s+s1}{\PYZsq{}}\PY{p}{,} \PY{n}{feature\PYZus{}encoder}\PY{p}{)}\PY{p}{,}
\PY{p}{]}\PY{p}{)}

\PY{n}{data\PYZus{}prep\PYZus{}pipe} \PY{o}{=} \PY{n}{xgb\PYZus{}preprocessor}\PY{o}{.}\PY{n}{fit}\PY{p}{(}\PY{n}{X\PYZus{}prepared}\PY{p}{)}
\PY{n}{X\PYZus{}prepared} \PY{o}{=} \PY{n}{xgb\PYZus{}preprocessor}\PY{o}{.}\PY{n}{transform}\PY{p}{(}\PY{n}{X\PYZus{}prepared}\PY{p}{)}
\PY{n}{X\PYZus{}prepared\PYZus{}val} \PY{o}{=} \PY{n}{xgb\PYZus{}preprocessor}\PY{o}{.}\PY{n}{transform}\PY{p}{(}\PY{n}{X\PYZus{}prepared\PYZus{}val}\PY{p}{)}
\end{Verbatim}
\end{tcolorbox}

    \begin{tcolorbox}[breakable, size=fbox, boxrule=1pt, pad at break*=1mm,colback=cellbackground, colframe=cellborder]
\prompt{In}{incolor}{76}{\boxspacing}
\begin{Verbatim}[commandchars=\\\{\}]
\PY{n}{X\PYZus{}xgb} \PY{o}{=} \PY{n}{X\PYZus{}prepared}\PY{o}{.}\PY{n}{copy}\PY{p}{(}\PY{p}{)}
\PY{n}{X\PYZus{}xgb\PYZus{}val} \PY{o}{=} \PY{n}{X\PYZus{}prepared\PYZus{}val}\PY{o}{.}\PY{n}{copy}\PY{p}{(}\PY{p}{)}
\end{Verbatim}
\end{tcolorbox}

    \hypertarget{tuning-parameters}{%
\subsection{Tuning Parameters}\label{tuning-parameters}}

The most importnant parameters to tune for Gradient Boosting are: -
\texttt{max\_depth}: How deep to build the trees. This is a very
important parameter and performance may change dramatically for
different values. Larger values are more likely to overfit, smaller
values more likely to underfit.

\begin{itemize}
\tightlist
\item
  \texttt{learning\_rate}, \texttt{n\_estimators}: These parameters are
  also very important and interact highly with one another (and with
  \texttt{max\_depth}). Typically, the smaller your ``step\_size''
  (learning\_rate), the more steps you will need to take to reach
  maximum performance. However, unlike random forests, if you continue
  to build trees in boosting, you will start overfitting, and
  performance (measured on the test set) will get worse.
\end{itemize}

    \begin{tcolorbox}[breakable, size=fbox, boxrule=1pt, pad at break*=1mm,colback=cellbackground, colframe=cellborder]
\prompt{In}{incolor}{77}{\boxspacing}
\begin{Verbatim}[commandchars=\\\{\}]
\PY{k+kn}{from} \PY{n+nn}{sklearn}\PY{n+nn}{.}\PY{n+nn}{model\PYZus{}selection} \PY{k+kn}{import} \PY{n}{cross\PYZus{}val\PYZus{}score}\PY{p}{,} \PY{n}{KFold}
\PY{k+kn}{from} \PY{n+nn}{sklearn}\PY{n+nn}{.}\PY{n+nn}{metrics} \PY{k+kn}{import} \PY{n}{mean\PYZus{}squared\PYZus{}error}\PY{p}{,} \PY{n}{mean\PYZus{}absolute\PYZus{}error}\PY{p}{,} \PY{n}{make\PYZus{}scorer}
\PY{k+kn}{import} \PY{n+nn}{optuna}
\PY{k+kn}{from} \PY{n+nn}{optuna}\PY{n+nn}{.}\PY{n+nn}{integration} \PY{k+kn}{import} \PY{n}{XGBoostPruningCallback}
\end{Verbatim}
\end{tcolorbox}

    \begin{tcolorbox}[breakable, size=fbox, boxrule=1pt, pad at break*=1mm,colback=cellbackground, colframe=cellborder]
\prompt{In}{incolor}{78}{\boxspacing}
\begin{Verbatim}[commandchars=\\\{\}]
\PY{k}{def} \PY{n+nf}{objective}\PY{p}{(}\PY{n}{trial}\PY{p}{,} \PY{n}{X}\PY{p}{,} \PY{n}{y}\PY{p}{)}\PY{p}{:}
    \PY{n}{param\PYZus{}grid} \PY{o}{=} \PY{p}{\PYZob{}}
    \PY{l+s+s1}{\PYZsq{}}\PY{l+s+s1}{max\PYZus{}depth}\PY{l+s+s1}{\PYZsq{}}\PY{p}{:}\PY{n}{trial}\PY{o}{.}\PY{n}{suggest\PYZus{}int}\PY{p}{(}\PY{l+s+s1}{\PYZsq{}}\PY{l+s+s1}{max\PYZus{}depth}\PY{l+s+s1}{\PYZsq{}}\PY{p}{,} \PY{l+m+mi}{1}\PY{p}{,} \PY{l+m+mi}{7}\PY{p}{)}\PY{p}{,} 
    \PY{l+s+s1}{\PYZsq{}}\PY{l+s+s1}{colsample\PYZus{}bynode}\PY{l+s+s1}{\PYZsq{}}\PY{p}{:} \PY{n}{trial}\PY{o}{.}\PY{n}{suggest\PYZus{}uniform}\PY{p}{(}\PY{l+s+s1}{\PYZsq{}}\PY{l+s+s1}{colsample\PYZus{}bynode}\PY{l+s+s1}{\PYZsq{}}\PY{p}{,}\PY{l+m+mf}{.3}\PY{p}{,}\PY{l+m+mi}{1}\PY{p}{)}\PY{p}{,}
    \PY{l+s+s1}{\PYZsq{}}\PY{l+s+s1}{subsample}\PY{l+s+s1}{\PYZsq{}}\PY{p}{:} \PY{n}{trial}\PY{o}{.}\PY{n}{suggest\PYZus{}uniform}\PY{p}{(}\PY{l+s+s1}{\PYZsq{}}\PY{l+s+s1}{subsample}\PY{l+s+s1}{\PYZsq{}}\PY{p}{,}\PY{l+m+mf}{.3}\PY{p}{,} \PY{l+m+mi}{1}\PY{p}{)}\PY{p}{,}
    \PY{l+s+s1}{\PYZsq{}}\PY{l+s+s1}{gamma}\PY{l+s+s1}{\PYZsq{}}\PY{p}{:}\PY{n}{trial}\PY{o}{.}\PY{n}{suggest\PYZus{}uniform}\PY{p}{(}\PY{l+s+s1}{\PYZsq{}}\PY{l+s+s1}{gamma}\PY{l+s+s1}{\PYZsq{}}\PY{p}{,}\PY{l+m+mf}{.2}\PY{p}{,} \PY{l+m+mi}{5}\PY{p}{)}\PY{p}{,}
    \PY{l+s+s1}{\PYZsq{}}\PY{l+s+s1}{tree\PYZus{}method}\PY{l+s+s1}{\PYZsq{}}\PY{p}{:} \PY{n}{trial}\PY{o}{.}\PY{n}{suggest\PYZus{}categorical}\PY{p}{(}\PY{l+s+s1}{\PYZsq{}}\PY{l+s+s1}{tree\PYZus{}method}\PY{l+s+s1}{\PYZsq{}}\PY{p}{,} \PY{p}{[}\PY{l+s+s1}{\PYZsq{}}\PY{l+s+s1}{approx}\PY{l+s+s1}{\PYZsq{}}\PY{p}{,} \PY{l+s+s1}{\PYZsq{}}\PY{l+s+s1}{exact}\PY{l+s+s1}{\PYZsq{}}\PY{p}{]}\PY{p}{)}\PY{p}{,}
    \PY{l+s+s1}{\PYZsq{}}\PY{l+s+s1}{n\PYZus{}estimators}\PY{l+s+s1}{\PYZsq{}}\PY{p}{:} \PY{n}{trial}\PY{o}{.}\PY{n}{suggest\PYZus{}categorical}\PY{p}{(}\PY{l+s+s2}{\PYZdq{}}\PY{l+s+s2}{n\PYZus{}estimators}\PY{l+s+s2}{\PYZdq{}}\PY{p}{,} \PY{p}{[}\PY{l+m+mi}{10000}\PY{p}{]}\PY{p}{)}\PY{p}{,}
    \PY{l+s+s1}{\PYZsq{}}\PY{l+s+s1}{learning\PYZus{}rate}\PY{l+s+s1}{\PYZsq{}}\PY{p}{:} \PY{n}{trial}\PY{o}{.}\PY{n}{suggest\PYZus{}float}\PY{p}{(}\PY{l+s+s2}{\PYZdq{}}\PY{l+s+s2}{learning\PYZus{}rate}\PY{l+s+s2}{\PYZdq{}}\PY{p}{,} \PY{l+m+mf}{0.01}\PY{p}{,} \PY{l+m+mf}{0.3}\PY{p}{)}\PY{p}{,}
    \PY{l+s+s1}{\PYZsq{}}\PY{l+s+s1}{random\PYZus{}state}\PY{l+s+s1}{\PYZsq{}}\PY{p}{:} \PY{l+m+mi}{42}\PY{p}{,}
    \PY{p}{\PYZcb{}}
    
    \PY{n}{cv} \PY{o}{=} \PY{n}{KFold}\PY{p}{(}\PY{n}{n\PYZus{}splits}\PY{o}{=}\PY{l+m+mi}{5}\PY{p}{,} \PY{n}{shuffle}\PY{o}{=}\PY{k+kc}{True}\PY{p}{,} \PY{n}{random\PYZus{}state}\PY{o}{=}\PY{l+m+mi}{42}\PY{p}{)}

    \PY{n}{cv\PYZus{}scores} \PY{o}{=} \PY{n}{np}\PY{o}{.}\PY{n}{empty}\PY{p}{(}\PY{l+m+mi}{5}\PY{p}{)}
    \PY{k}{for} \PY{n}{idx}\PY{p}{,} \PY{p}{(}\PY{n}{train\PYZus{}idx}\PY{p}{,} \PY{n}{test\PYZus{}idx}\PY{p}{)} \PY{o+ow}{in} \PY{n+nb}{enumerate}\PY{p}{(}\PY{n}{cv}\PY{o}{.}\PY{n}{split}\PY{p}{(}\PY{n}{X}\PY{p}{,} \PY{n}{y}\PY{p}{)}\PY{p}{)}\PY{p}{:}
        \PY{n}{X\PYZus{}train}\PY{p}{,} \PY{n}{X\PYZus{}test} \PY{o}{=} \PY{n}{X}\PY{p}{[}\PY{n}{train\PYZus{}idx}\PY{p}{]}\PY{p}{,} \PY{n}{X}\PY{p}{[}\PY{n}{test\PYZus{}idx}\PY{p}{]}
        \PY{n}{y\PYZus{}train}\PY{p}{,} \PY{n}{y\PYZus{}test} \PY{o}{=} \PY{n}{y}\PY{p}{[}\PY{n}{train\PYZus{}idx}\PY{p}{]}\PY{p}{,} \PY{n}{y}\PY{p}{[}\PY{n}{test\PYZus{}idx}\PY{p}{]}

        \PY{n}{model} \PY{o}{=} \PY{n}{xgb}\PY{o}{.}\PY{n}{XGBRegressor}\PY{p}{(}\PY{o}{*}\PY{o}{*}\PY{n}{param\PYZus{}grid}\PY{p}{)}
        \PY{n}{model}\PY{o}{.}\PY{n}{fit}\PY{p}{(}
            \PY{n}{X\PYZus{}train}\PY{p}{,}
            \PY{n}{y\PYZus{}train}\PY{p}{,}
            \PY{n}{eval\PYZus{}set}\PY{o}{=}\PY{p}{[}\PY{p}{(}\PY{n}{X\PYZus{}test}\PY{p}{,} \PY{n}{y\PYZus{}test}\PY{p}{)}\PY{p}{]}\PY{p}{,}
            \PY{n}{eval\PYZus{}metric}\PY{o}{=}\PY{l+s+s2}{\PYZdq{}}\PY{l+s+s2}{mae}\PY{l+s+s2}{\PYZdq{}}\PY{p}{,}
            \PY{n}{verbose}\PY{o}{=}\PY{k+kc}{False}\PY{p}{,}
            \PY{n}{early\PYZus{}stopping\PYZus{}rounds}\PY{o}{=}\PY{l+m+mi}{25}\PY{p}{,}
            \PY{c+c1}{\PYZsh{}callbacks=[}
            \PY{c+c1}{\PYZsh{}    XGBoostPruningCallback(trial, \PYZdq{}l1\PYZdq{})}
            \PY{c+c1}{\PYZsh{}],  }
        \PY{p}{)}
        \PY{n}{preds} \PY{o}{=} \PY{n}{model}\PY{o}{.}\PY{n}{predict}\PY{p}{(}\PY{n}{X\PYZus{}test}\PY{p}{)}
        \PY{n}{cv\PYZus{}scores}\PY{p}{[}\PY{n}{idx}\PY{p}{]} \PY{o}{=} \PY{n}{mean\PYZus{}absolute\PYZus{}error}\PY{p}{(}\PY{n}{y\PYZus{}test}\PY{p}{,} \PY{n}{preds}\PY{p}{)}

    \PY{k}{return} \PY{n}{np}\PY{o}{.}\PY{n}{mean}\PY{p}{(}\PY{n}{cv\PYZus{}scores}\PY{p}{)}
\end{Verbatim}
\end{tcolorbox}

    \begin{tcolorbox}[breakable, size=fbox, boxrule=1pt, pad at break*=1mm,colback=cellbackground, colframe=cellborder]
\prompt{In}{incolor}{79}{\boxspacing}
\begin{Verbatim}[commandchars=\\\{\}]
\PY{c+c1}{\PYZsh{} Similar to Hyperopt \PYZhy{} this code creates an experiment using the objective function and parameter grid above}
\PY{c+c1}{\PYZsh{}study = optuna.create\PYZus{}study(direction=\PYZdq{}minimize\PYZdq{}, study\PYZus{}name=\PYZdq{}XGB Regressor\PYZdq{})}
\PY{c+c1}{\PYZsh{}func = lambda trial: objective(trial, X\PYZus{}xgb, y\PYZus{}train.to\PYZus{}numpy())}
\PY{c+c1}{\PYZsh{}study.optimize(func, n\PYZus{}trials=10000)}
\end{Verbatim}
\end{tcolorbox}

    \begin{tcolorbox}[breakable, size=fbox, boxrule=1pt, pad at break*=1mm,colback=cellbackground, colframe=cellborder]
\prompt{In}{incolor}{80}{\boxspacing}
\begin{Verbatim}[commandchars=\\\{\}]
\PY{c+c1}{\PYZsh{}print(f\PYZdq{}\PYZbs{}tBest value (mae): \PYZob{}study.best\PYZus{}value:.5f\PYZcb{}\PYZdq{})}
\PY{c+c1}{\PYZsh{}print(f\PYZdq{}\PYZbs{}tBest params:\PYZdq{})}

\PY{c+c1}{\PYZsh{}for key, value in study.best\PYZus{}params.items():}
    \PY{c+c1}{\PYZsh{}print(f\PYZdq{}\PYZbs{}t\PYZbs{}t\PYZob{}key\PYZcb{}: \PYZob{}value\PYZcb{}\PYZdq{})}
\end{Verbatim}
\end{tcolorbox}

    \hypertarget{best-params-model}{%
\subsubsection{Best Params Model}\label{best-params-model}}

Based on the 1200 \texttt{optuna} trials, the following hyperparameter
values had the best loss:

\begin{verbatim}
{'learning_rate': 0.2,
 'n_estimators': 10000,
 'random_state': 42,
 'colsample_bynode': 0.382,
 'gamma': 0.201,
 'max_depth': 5,
 'subsample': 0.95,
 'tree_method': 'exact'}
\end{verbatim}

    \begin{tcolorbox}[breakable, size=fbox, boxrule=1pt, pad at break*=1mm,colback=cellbackground, colframe=cellborder]
\prompt{In}{incolor}{81}{\boxspacing}
\begin{Verbatim}[commandchars=\\\{\}]
\PY{o}{\PYZpc{}\PYZpc{}time}
\PY{n}{fit\PYZus{}params}\PY{o}{=}\PY{p}{\PYZob{}}
    \PY{l+s+s1}{\PYZsq{}}\PY{l+s+s1}{early\PYZus{}stopping\PYZus{}rounds}\PY{l+s+s1}{\PYZsq{}}\PY{p}{:} \PY{l+m+mi}{15}\PY{p}{,} 
    \PY{l+s+s1}{\PYZsq{}}\PY{l+s+s1}{eval\PYZus{}metric}\PY{l+s+s1}{\PYZsq{}}\PY{p}{:} \PY{l+s+s1}{\PYZsq{}}\PY{l+s+s1}{mae}\PY{l+s+s1}{\PYZsq{}}\PY{p}{,}
    \PY{l+s+s1}{\PYZsq{}}\PY{l+s+s1}{verbose}\PY{l+s+s1}{\PYZsq{}}\PY{p}{:} \PY{k+kc}{False}\PY{p}{,}
    \PY{l+s+s1}{\PYZsq{}}\PY{l+s+s1}{eval\PYZus{}set}\PY{l+s+s1}{\PYZsq{}}\PY{p}{:} \PY{p}{[}\PY{p}{[}\PY{n}{X\PYZus{}prepared\PYZus{}val}\PY{p}{,} \PY{n}{y\PYZus{}val}\PY{p}{]}\PY{p}{]}\PY{p}{,}
\PY{p}{\PYZcb{}}

\PY{n}{best\PYZus{}params} \PY{o}{=} \PY{p}{\PYZob{}}
    \PY{l+s+s1}{\PYZsq{}}\PY{l+s+s1}{colsample\PYZus{}bynode}\PY{l+s+s1}{\PYZsq{}}\PY{p}{:} \PY{l+m+mf}{0.382}\PY{p}{,}   
    \PY{l+s+s1}{\PYZsq{}}\PY{l+s+s1}{gamma}\PY{l+s+s1}{\PYZsq{}}\PY{p}{:} \PY{l+m+mf}{0.201}\PY{p}{,}
    \PY{l+s+s1}{\PYZsq{}}\PY{l+s+s1}{max\PYZus{}depth}\PY{l+s+s1}{\PYZsq{}}\PY{p}{:} \PY{l+m+mi}{5}\PY{p}{,}   
    \PY{l+s+s1}{\PYZsq{}}\PY{l+s+s1}{subsample}\PY{l+s+s1}{\PYZsq{}}\PY{p}{:} \PY{l+m+mf}{0.95}\PY{p}{,} 
    \PY{l+s+s1}{\PYZsq{}}\PY{l+s+s1}{tree\PYZus{}method}\PY{l+s+s1}{\PYZsq{}}\PY{p}{:} \PY{l+s+s1}{\PYZsq{}}\PY{l+s+s1}{exact}\PY{l+s+s1}{\PYZsq{}}\PY{p}{,}
    \PY{l+s+s1}{\PYZsq{}}\PY{l+s+s1}{learning\PYZus{}rate}\PY{l+s+s1}{\PYZsq{}}\PY{p}{:} \PY{l+m+mf}{0.01}\PY{p}{,}
    \PY{l+s+s1}{\PYZsq{}}\PY{l+s+s1}{n\PYZus{}estimators}\PY{l+s+s1}{\PYZsq{}}\PY{p}{:} \PY{l+m+mi}{10000}\PY{p}{,}
    \PY{l+s+s1}{\PYZsq{}}\PY{l+s+s1}{random\PYZus{}state}\PY{l+s+s1}{\PYZsq{}}\PY{p}{:} \PY{l+m+mi}{42}\PY{p}{,}
\PY{p}{\PYZcb{}}
\PY{n}{xgb\PYZus{}base} \PY{o}{=} \PY{n}{xgb}\PY{o}{.}\PY{n}{XGBRegressor}\PY{p}{(}\PY{o}{*}\PY{o}{*}\PY{n}{best\PYZus{}params}\PY{p}{)}
\PY{n}{xgb\PYZus{}base}\PY{o}{.}\PY{n}{fit}\PY{p}{(}\PY{n}{X\PYZus{}xgb}\PY{p}{,} \PY{n}{y\PYZus{}train}\PY{p}{,} \PY{o}{*}\PY{o}{*}\PY{n}{fit\PYZus{}params}\PY{p}{)}
\end{Verbatim}
\end{tcolorbox}

    \begin{Verbatim}[commandchars=\\\{\}]
CPU times: total: 16min 36s
Wall time: 2min 35s
    \end{Verbatim}

            \begin{tcolorbox}[breakable, size=fbox, boxrule=.5pt, pad at break*=1mm, opacityfill=0]
\prompt{Out}{outcolor}{81}{\boxspacing}
\begin{Verbatim}[commandchars=\\\{\}]
XGBRegressor(base\_score=0.5, booster='gbtree', colsample\_bylevel=1,
             colsample\_bynode=0.382, colsample\_bytree=1,
             enable\_categorical=False, gamma=0.201, gpu\_id=-1,
             importance\_type=None, interaction\_constraints='',
             learning\_rate=0.01, max\_delta\_step=0, max\_depth=5,
             min\_child\_weight=1, missing=nan, monotone\_constraints='()',
             n\_estimators=10000, n\_jobs=8, num\_parallel\_tree=1,
             predictor='auto', random\_state=42, reg\_alpha=0, reg\_lambda=1,
             scale\_pos\_weight=1, subsample=0.95, tree\_method='exact',
             validate\_parameters=1, verbosity=None)
\end{Verbatim}
\end{tcolorbox}
        
    \begin{tcolorbox}[breakable, size=fbox, boxrule=1pt, pad at break*=1mm,colback=cellbackground, colframe=cellborder]
\prompt{In}{incolor}{82}{\boxspacing}
\begin{Verbatim}[commandchars=\\\{\}]
\PY{o}{\PYZpc{}\PYZpc{}time} 
\PY{n}{utils}\PY{o}{.}\PY{n}{get\PYZus{}eval\PYZus{}metrics}\PY{p}{(}\PY{p}{[}\PY{n}{xgb\PYZus{}base}\PY{p}{]}\PY{p}{,} \PY{n}{X\PYZus{}xgb\PYZus{}val}\PY{p}{,} \PY{n}{y\PYZus{}val}\PY{p}{)}
\PY{c+c1}{\PYZsh{}utils.get\PYZus{}cross\PYZus{}val\PYZus{}scores([xgb\PYZus{}base], X\PYZus{}prepared, y\PYZus{}train, cv=3, fit\PYZus{}params=fit\PYZus{}params)}
\end{Verbatim}
\end{tcolorbox}

    \begin{Verbatim}[commandchars=\\\{\}]
Model: XGBRegressor(base\_score=0.5, booster='gbtree', colsample\_bylevel=1,
             colsample\_bynode=0.382, colsample\_bytree=1,
             enable\_categorical=False, gamma=0.201, gpu\_id=-1,
             importance\_type=None, interaction\_constraints='',
             learning\_rate=0.01, max\_delta\_step=0, max\_depth=5,
             min\_child\_weight=1, missing=nan, monotone\_constraints='()',
             n\_estimators=10000, n\_jobs=8, num\_parallel\_tree=1,
             predictor='auto', random\_state=42, reg\_alpha=0, reg\_lambda=1,
             scale\_pos\_weight=1, subsample=0.95, tree\_method='exact',
             validate\_parameters=1, verbosity=None)
MAE: 0.04974848215922578, RMSE: 0.07560463923585851
CPU times: total: 438 ms
Wall time: 70.2 ms
    \end{Verbatim}

            \begin{tcolorbox}[breakable, size=fbox, boxrule=.5pt, pad at break*=1mm, opacityfill=0]
\prompt{Out}{outcolor}{82}{\boxspacing}
\begin{Verbatim}[commandchars=\\\{\}]
0.04974848215922578
\end{Verbatim}
\end{tcolorbox}
        
    \begin{tcolorbox}[breakable, size=fbox, boxrule=1pt, pad at break*=1mm,colback=cellbackground, colframe=cellborder]
\prompt{In}{incolor}{83}{\boxspacing}
\begin{Verbatim}[commandchars=\\\{\}]
\PY{n}{result} \PY{o}{=} \PY{n}{utils}\PY{o}{.}\PY{n}{get\PYZus{}eval\PYZus{}metrics}\PY{p}{(}\PY{p}{[}\PY{n}{xgb\PYZus{}base}\PY{p}{]}\PY{p}{,} \PY{n}{X\PYZus{}xgb\PYZus{}val}\PY{p}{,} \PY{n}{y\PYZus{}val}\PY{p}{)}
\PY{n}{results}\PY{p}{[}\PY{l+s+s1}{\PYZsq{}}\PY{l+s+s1}{XGB}\PY{l+s+s1}{\PYZsq{}}\PY{p}{]} \PY{o}{=} \PY{n}{result}
\end{Verbatim}
\end{tcolorbox}

    \begin{Verbatim}[commandchars=\\\{\}]
Model: XGBRegressor(base\_score=0.5, booster='gbtree', colsample\_bylevel=1,
             colsample\_bynode=0.382, colsample\_bytree=1,
             enable\_categorical=False, gamma=0.201, gpu\_id=-1,
             importance\_type=None, interaction\_constraints='',
             learning\_rate=0.01, max\_delta\_step=0, max\_depth=5,
             min\_child\_weight=1, missing=nan, monotone\_constraints='()',
             n\_estimators=10000, n\_jobs=8, num\_parallel\_tree=1,
             predictor='auto', random\_state=42, reg\_alpha=0, reg\_lambda=1,
             scale\_pos\_weight=1, subsample=0.95, tree\_method='exact',
             validate\_parameters=1, verbosity=None)
MAE: 0.04974848215922578, RMSE: 0.07560463923585851
    \end{Verbatim}

    \hypertarget{lightgbm}{%
\section{7 - LightGBM}\label{lightgbm}}

    \begin{itemize}
\tightlist
\item
  Smarter techniques to avoid searching all splits and speeding things
  up (ignoring small gradients to reduce data at each iteration)
\item
  ``looks for'' mutually exclusive features to handle them better
\item
  Instead of building decision trees one level at a time like XGBoost,
  LightGBM uses a leaf-wise tree growth approach which results in fewer
  unnecesary nodes.
\end{itemize}

\hypertarget{lightgbm-resources}{%
\subsubsection{LightGBM Resources:}\label{lightgbm-resources}}

\begin{itemize}
\tightlist
\item
  \href{https://neptune.ai/blog/lightgbm-parameters-guide}{Understanding
  LightGBM Parameters - Detailed Guide}
\item
  \href{https://towardsdatascience.com/kagglers-guide-to-lightgbm-hyperparameter-tuning-with-optuna-in-2021-ed048d9838b5}{Guide
  to tuning LightGBM using Optuna}
\item
  \href{https://medium.com/optuna/lightgbm-tuner-new-optuna-integration-for-hyperparameter-optimization-8b7095e99258}{LightGBM
  Tuner: New Optuna Integration for Hyperparameter Optimization}
\end{itemize}

    \begin{tcolorbox}[breakable, size=fbox, boxrule=1pt, pad at break*=1mm,colback=cellbackground, colframe=cellborder]
\prompt{In}{incolor}{84}{\boxspacing}
\begin{Verbatim}[commandchars=\\\{\}]
\PY{k+kn}{import} \PY{n+nn}{lightgbm} \PY{k}{as} \PY{n+nn}{lgbm}
\PY{k+kn}{from} \PY{n+nn}{sklearn}\PY{n+nn}{.}\PY{n+nn}{model\PYZus{}selection} \PY{k+kn}{import} \PY{n}{cross\PYZus{}val\PYZus{}score}\PY{p}{,} \PY{n}{KFold}
\PY{k+kn}{from} \PY{n+nn}{sklearn}\PY{n+nn}{.}\PY{n+nn}{metrics} \PY{k+kn}{import} \PY{n}{mean\PYZus{}squared\PYZus{}error}\PY{p}{,} \PY{n}{mean\PYZus{}absolute\PYZus{}error}\PY{p}{,} \PY{n}{make\PYZus{}scorer}
\PY{k+kn}{import} \PY{n+nn}{optuna}
\PY{k+kn}{from} \PY{n+nn}{optuna}\PY{n+nn}{.}\PY{n+nn}{integration} \PY{k+kn}{import} \PY{n}{LightGBMPruningCallback}
\end{Verbatim}
\end{tcolorbox}

    \begin{Verbatim}[commandchars=\\\{\}, frame=single, framerule=2mm, rulecolor=\color{outerrorbackground}]
\textcolor{ansi-red-intense}{\textbf{---------------------------------------------------------------------------}}
\textcolor{ansi-red-intense}{\textbf{AttributeError}}                            Traceback (most recent call last)
Input \textcolor{ansi-green-intense}{\textbf{In [84]}}, in \textcolor{ansi-cyan}{<cell line: 1>}\textcolor{ansi-blue-intense}{\textbf{()}}
\textcolor{ansi-green-intense}{\textbf{----> 1}} \def\tcRGB{\textcolor[RGB]}\expandafter\tcRGB\expandafter{\detokenize{0,135,0}}{\textbf{import}} \def\tcRGB{\textcolor[RGB]}\expandafter\tcRGB\expandafter{\detokenize{0,0,255}}{\textbf{lightgbm}} \def\tcRGB{\textcolor[RGB]}\expandafter\tcRGB\expandafter{\detokenize{0,135,0}}{\textbf{as}} \def\tcRGB{\textcolor[RGB]}\expandafter\tcRGB\expandafter{\detokenize{0,0,255}}{\textbf{lgbm}}
\textcolor{ansi-green}{      2} \def\tcRGB{\textcolor[RGB]}\expandafter\tcRGB\expandafter{\detokenize{0,135,0}}{\textbf{from}} \def\tcRGB{\textcolor[RGB]}\expandafter\tcRGB\expandafter{\detokenize{0,0,255}}{\textbf{sklearn}}\def\tcRGB{\textcolor[RGB]}\expandafter\tcRGB\expandafter{\detokenize{0,0,255}}{\textbf{.}}\def\tcRGB{\textcolor[RGB]}\expandafter\tcRGB\expandafter{\detokenize{0,0,255}}{\textbf{model\_selection}} \def\tcRGB{\textcolor[RGB]}\expandafter\tcRGB\expandafter{\detokenize{0,135,0}}{\textbf{import}} cross\_val\_score, KFold
\textcolor{ansi-green}{      3} \def\tcRGB{\textcolor[RGB]}\expandafter\tcRGB\expandafter{\detokenize{0,135,0}}{\textbf{from}} \def\tcRGB{\textcolor[RGB]}\expandafter\tcRGB\expandafter{\detokenize{0,0,255}}{\textbf{sklearn}}\def\tcRGB{\textcolor[RGB]}\expandafter\tcRGB\expandafter{\detokenize{0,0,255}}{\textbf{.}}\def\tcRGB{\textcolor[RGB]}\expandafter\tcRGB\expandafter{\detokenize{0,0,255}}{\textbf{metrics}} \def\tcRGB{\textcolor[RGB]}\expandafter\tcRGB\expandafter{\detokenize{0,135,0}}{\textbf{import}} mean\_squared\_error, mean\_absolute\_error, make\_scorer

File \textcolor{ansi-green-intense}{\textbf{\textasciitilde{}\textbackslash{}anaconda3\textbackslash{}lib\textbackslash{}site-packages\textbackslash{}lightgbm\textbackslash{}\_\_init\_\_.py:8}}, in \textcolor{ansi-cyan}{<module>}
\textcolor{ansi-green}{      2} \def\tcRGB{\textcolor[RGB]}\expandafter\tcRGB\expandafter{\detokenize{175,0,0}}{"""LightGBM, Light Gradient Boosting Machine.}
\textcolor{ansi-green}{      3} 
\textcolor{ansi-green}{      4} \def\tcRGB{\textcolor[RGB]}\expandafter\tcRGB\expandafter{\detokenize{175,0,0}}{Contributors: https://github.com/microsoft/LightGBM/graphs/contributors.}
\textcolor{ansi-green}{      5} \def\tcRGB{\textcolor[RGB]}\expandafter\tcRGB\expandafter{\detokenize{175,0,0}}{"""}
\textcolor{ansi-green}{      6} \def\tcRGB{\textcolor[RGB]}\expandafter\tcRGB\expandafter{\detokenize{0,135,0}}{\textbf{from}} \def\tcRGB{\textcolor[RGB]}\expandafter\tcRGB\expandafter{\detokenize{0,0,255}}{\textbf{pathlib}} \def\tcRGB{\textcolor[RGB]}\expandafter\tcRGB\expandafter{\detokenize{0,135,0}}{\textbf{import}} Path
\textcolor{ansi-green-intense}{\textbf{----> 8}} \def\tcRGB{\textcolor[RGB]}\expandafter\tcRGB\expandafter{\detokenize{0,135,0}}{\textbf{from}} \def\tcRGB{\textcolor[RGB]}\expandafter\tcRGB\expandafter{\detokenize{0,0,255}}{\textbf{.}}\def\tcRGB{\textcolor[RGB]}\expandafter\tcRGB\expandafter{\detokenize{0,0,255}}{\textbf{basic}} \def\tcRGB{\textcolor[RGB]}\expandafter\tcRGB\expandafter{\detokenize{0,135,0}}{\textbf{import}} Booster, Dataset, Sequence, register\_logger
\textcolor{ansi-green}{      9} \def\tcRGB{\textcolor[RGB]}\expandafter\tcRGB\expandafter{\detokenize{0,135,0}}{\textbf{from}} \def\tcRGB{\textcolor[RGB]}\expandafter\tcRGB\expandafter{\detokenize{0,0,255}}{\textbf{.}}\def\tcRGB{\textcolor[RGB]}\expandafter\tcRGB\expandafter{\detokenize{0,0,255}}{\textbf{callback}} \def\tcRGB{\textcolor[RGB]}\expandafter\tcRGB\expandafter{\detokenize{0,135,0}}{\textbf{import}} early\_stopping, log\_evaluation, print\_evaluation, record\_evaluation, reset\_parameter
\textcolor{ansi-green}{     10} \def\tcRGB{\textcolor[RGB]}\expandafter\tcRGB\expandafter{\detokenize{0,135,0}}{\textbf{from}} \def\tcRGB{\textcolor[RGB]}\expandafter\tcRGB\expandafter{\detokenize{0,0,255}}{\textbf{.}}\def\tcRGB{\textcolor[RGB]}\expandafter\tcRGB\expandafter{\detokenize{0,0,255}}{\textbf{engine}} \def\tcRGB{\textcolor[RGB]}\expandafter\tcRGB\expandafter{\detokenize{0,135,0}}{\textbf{import}} CVBooster, cv, train

File \textcolor{ansi-green-intense}{\textbf{\textasciitilde{}\textbackslash{}anaconda3\textbackslash{}lib\textbackslash{}site-packages\textbackslash{}lightgbm\textbackslash{}basic.py:20}}, in \textcolor{ansi-cyan}{<module>}
\textcolor{ansi-green}{     17} \def\tcRGB{\textcolor[RGB]}\expandafter\tcRGB\expandafter{\detokenize{0,135,0}}{\textbf{import}} \def\tcRGB{\textcolor[RGB]}\expandafter\tcRGB\expandafter{\detokenize{0,0,255}}{\textbf{numpy}} \def\tcRGB{\textcolor[RGB]}\expandafter\tcRGB\expandafter{\detokenize{0,135,0}}{\textbf{as}} \def\tcRGB{\textcolor[RGB]}\expandafter\tcRGB\expandafter{\detokenize{0,0,255}}{\textbf{np}}
\textcolor{ansi-green}{     18} \def\tcRGB{\textcolor[RGB]}\expandafter\tcRGB\expandafter{\detokenize{0,135,0}}{\textbf{import}} \def\tcRGB{\textcolor[RGB]}\expandafter\tcRGB\expandafter{\detokenize{0,0,255}}{\textbf{scipy}}\def\tcRGB{\textcolor[RGB]}\expandafter\tcRGB\expandafter{\detokenize{0,0,255}}{\textbf{.}}\def\tcRGB{\textcolor[RGB]}\expandafter\tcRGB\expandafter{\detokenize{0,0,255}}{\textbf{sparse}}
\textcolor{ansi-green-intense}{\textbf{---> 20}} \def\tcRGB{\textcolor[RGB]}\expandafter\tcRGB\expandafter{\detokenize{0,135,0}}{\textbf{from}} \def\tcRGB{\textcolor[RGB]}\expandafter\tcRGB\expandafter{\detokenize{0,0,255}}{\textbf{.}}\def\tcRGB{\textcolor[RGB]}\expandafter\tcRGB\expandafter{\detokenize{0,0,255}}{\textbf{compat}} \def\tcRGB{\textcolor[RGB]}\expandafter\tcRGB\expandafter{\detokenize{0,135,0}}{\textbf{import}} PANDAS\_INSTALLED, concat, dt\_DataTable, is\_dtype\_sparse, pd\_DataFrame, pd\_Series
\textcolor{ansi-green}{     21} \def\tcRGB{\textcolor[RGB]}\expandafter\tcRGB\expandafter{\detokenize{0,135,0}}{\textbf{from}} \def\tcRGB{\textcolor[RGB]}\expandafter\tcRGB\expandafter{\detokenize{0,0,255}}{\textbf{.}}\def\tcRGB{\textcolor[RGB]}\expandafter\tcRGB\expandafter{\detokenize{0,0,255}}{\textbf{libpath}} \def\tcRGB{\textcolor[RGB]}\expandafter\tcRGB\expandafter{\detokenize{0,135,0}}{\textbf{import}} find\_lib\_path
\textcolor{ansi-green}{     23} ZERO\_THRESHOLD \def\tcRGB{\textcolor[RGB]}\expandafter\tcRGB\expandafter{\detokenize{98,98,98}}{=} \def\tcRGB{\textcolor[RGB]}\expandafter\tcRGB\expandafter{\detokenize{98,98,98}}{1e-35}

File \textcolor{ansi-green-intense}{\textbf{\textasciitilde{}\textbackslash{}anaconda3\textbackslash{}lib\textbackslash{}site-packages\textbackslash{}lightgbm\textbackslash{}compat.py:36}}, in \textcolor{ansi-cyan}{<module>}
\textcolor{ansi-green}{     34} \def\tcRGB{\textcolor[RGB]}\expandafter\tcRGB\expandafter{\detokenize{175,0,0}}{"""graphviz"""}
\textcolor{ansi-green}{     35} \def\tcRGB{\textcolor[RGB]}\expandafter\tcRGB\expandafter{\detokenize{0,135,0}}{\textbf{try}}:
\textcolor{ansi-green-intense}{\textbf{---> 36}}     \def\tcRGB{\textcolor[RGB]}\expandafter\tcRGB\expandafter{\detokenize{0,135,0}}{\textbf{import}} \def\tcRGB{\textcolor[RGB]}\expandafter\tcRGB\expandafter{\detokenize{0,0,255}}{\textbf{graphviz}}
\textcolor{ansi-green}{     37}     GRAPHVIZ\_INSTALLED \def\tcRGB{\textcolor[RGB]}\expandafter\tcRGB\expandafter{\detokenize{98,98,98}}{=} \def\tcRGB{\textcolor[RGB]}\expandafter\tcRGB\expandafter{\detokenize{0,135,0}}{\textbf{True}}
\textcolor{ansi-green}{     38} \def\tcRGB{\textcolor[RGB]}\expandafter\tcRGB\expandafter{\detokenize{0,135,0}}{\textbf{except}} \def\tcRGB{\textcolor[RGB]}\expandafter\tcRGB\expandafter{\detokenize{215,95,95}}{\textbf{ImportError}}:

File \textcolor{ansi-green-intense}{\textbf{\textasciitilde{}\textbackslash{}anaconda3\textbackslash{}lib\textbackslash{}site-packages\textbackslash{}graphviz\textbackslash{}\_\_init\_\_.py:27}}, in \textcolor{ansi-cyan}{<module>}
\textcolor{ansi-green}{      1} \def\tcRGB{\textcolor[RGB]}\expandafter\tcRGB\expandafter{\detokenize{95,135,135}}{\# graphviz - create dot, save, render, view}
\textcolor{ansi-green}{      3} \def\tcRGB{\textcolor[RGB]}\expandafter\tcRGB\expandafter{\detokenize{175,0,0}}{"""Assemble DOT source code and render it with Graphviz.}
\textcolor{ansi-green}{      4} 
\textcolor{ansi-green}{      5} \def\tcRGB{\textcolor[RGB]}\expandafter\tcRGB\expandafter{\detokenize{175,0,0}}{>>> dot = Digraph(comment='The Round Table')}
\textcolor{ansi-green-intense}{\textbf{   ({\ldots})}}
\textcolor{ansi-green}{     24} \def\tcRGB{\textcolor[RGB]}\expandafter\tcRGB\expandafter{\detokenize{175,0,0}}{\}}
\textcolor{ansi-green}{     25} \def\tcRGB{\textcolor[RGB]}\expandafter\tcRGB\expandafter{\detokenize{175,0,0}}{"""}
\textcolor{ansi-green-intense}{\textbf{---> 27}} \def\tcRGB{\textcolor[RGB]}\expandafter\tcRGB\expandafter{\detokenize{0,135,0}}{\textbf{from}} \def\tcRGB{\textcolor[RGB]}\expandafter\tcRGB\expandafter{\detokenize{0,0,255}}{\textbf{.}}\def\tcRGB{\textcolor[RGB]}\expandafter\tcRGB\expandafter{\detokenize{0,0,255}}{\textbf{dot}} \def\tcRGB{\textcolor[RGB]}\expandafter\tcRGB\expandafter{\detokenize{0,135,0}}{\textbf{import}} Graph, Digraph
\textcolor{ansi-green}{     28} \def\tcRGB{\textcolor[RGB]}\expandafter\tcRGB\expandafter{\detokenize{0,135,0}}{\textbf{from}} \def\tcRGB{\textcolor[RGB]}\expandafter\tcRGB\expandafter{\detokenize{0,0,255}}{\textbf{.}}\def\tcRGB{\textcolor[RGB]}\expandafter\tcRGB\expandafter{\detokenize{0,0,255}}{\textbf{files}} \def\tcRGB{\textcolor[RGB]}\expandafter\tcRGB\expandafter{\detokenize{0,135,0}}{\textbf{import}} Source
\textcolor{ansi-green}{     29} \def\tcRGB{\textcolor[RGB]}\expandafter\tcRGB\expandafter{\detokenize{0,135,0}}{\textbf{from}} \def\tcRGB{\textcolor[RGB]}\expandafter\tcRGB\expandafter{\detokenize{0,0,255}}{\textbf{.}}\def\tcRGB{\textcolor[RGB]}\expandafter\tcRGB\expandafter{\detokenize{0,0,255}}{\textbf{lang}} \def\tcRGB{\textcolor[RGB]}\expandafter\tcRGB\expandafter{\detokenize{0,135,0}}{\textbf{import}} escape, nohtml

File \textcolor{ansi-green-intense}{\textbf{\textasciitilde{}\textbackslash{}anaconda3\textbackslash{}lib\textbackslash{}site-packages\textbackslash{}graphviz\textbackslash{}dot.py:32}}, in \textcolor{ansi-cyan}{<module>}
\textcolor{ansi-green}{      3} \def\tcRGB{\textcolor[RGB]}\expandafter\tcRGB\expandafter{\detokenize{175,0,0}}{r}\def\tcRGB{\textcolor[RGB]}\expandafter\tcRGB\expandafter{\detokenize{175,0,0}}{"""Assemble DOT source code objects.}
\textcolor{ansi-green}{      4} 
\textcolor{ansi-green}{      5} \def\tcRGB{\textcolor[RGB]}\expandafter\tcRGB\expandafter{\detokenize{175,0,0}}{>>> dot = Graph(comment=u'M\textbackslash{}xf8nti Pyth\textbackslash{}xf8n ik den H\textbackslash{}xf8lie Grailen')}
\textcolor{ansi-green-intense}{\textbf{   ({\ldots})}}
\textcolor{ansi-green}{     28} \def\tcRGB{\textcolor[RGB]}\expandafter\tcRGB\expandafter{\detokenize{175,0,0}}{'test-output/m00se.gv.pdf'}
\textcolor{ansi-green}{     29} \def\tcRGB{\textcolor[RGB]}\expandafter\tcRGB\expandafter{\detokenize{175,0,0}}{"""}
\textcolor{ansi-green}{     31} \def\tcRGB{\textcolor[RGB]}\expandafter\tcRGB\expandafter{\detokenize{0,135,0}}{\textbf{from}} \def\tcRGB{\textcolor[RGB]}\expandafter\tcRGB\expandafter{\detokenize{0,0,255}}{\textbf{.}} \def\tcRGB{\textcolor[RGB]}\expandafter\tcRGB\expandafter{\detokenize{0,135,0}}{\textbf{import}} backend
\textcolor{ansi-green-intense}{\textbf{---> 32}} \def\tcRGB{\textcolor[RGB]}\expandafter\tcRGB\expandafter{\detokenize{0,135,0}}{\textbf{from}} \def\tcRGB{\textcolor[RGB]}\expandafter\tcRGB\expandafter{\detokenize{0,0,255}}{\textbf{.}} \def\tcRGB{\textcolor[RGB]}\expandafter\tcRGB\expandafter{\detokenize{0,135,0}}{\textbf{import}} files
\textcolor{ansi-green}{     33} \def\tcRGB{\textcolor[RGB]}\expandafter\tcRGB\expandafter{\detokenize{0,135,0}}{\textbf{from}} \def\tcRGB{\textcolor[RGB]}\expandafter\tcRGB\expandafter{\detokenize{0,0,255}}{\textbf{.}} \def\tcRGB{\textcolor[RGB]}\expandafter\tcRGB\expandafter{\detokenize{0,135,0}}{\textbf{import}} lang
\textcolor{ansi-green}{     35} \_\_all\_\_ \def\tcRGB{\textcolor[RGB]}\expandafter\tcRGB\expandafter{\detokenize{98,98,98}}{=} [\def\tcRGB{\textcolor[RGB]}\expandafter\tcRGB\expandafter{\detokenize{175,0,0}}{'}\def\tcRGB{\textcolor[RGB]}\expandafter\tcRGB\expandafter{\detokenize{175,0,0}}{Graph}\def\tcRGB{\textcolor[RGB]}\expandafter\tcRGB\expandafter{\detokenize{175,0,0}}{'}, \def\tcRGB{\textcolor[RGB]}\expandafter\tcRGB\expandafter{\detokenize{175,0,0}}{'}\def\tcRGB{\textcolor[RGB]}\expandafter\tcRGB\expandafter{\detokenize{175,0,0}}{Digraph}\def\tcRGB{\textcolor[RGB]}\expandafter\tcRGB\expandafter{\detokenize{175,0,0}}{'}]

File \textcolor{ansi-green-intense}{\textbf{\textasciitilde{}\textbackslash{}anaconda3\textbackslash{}lib\textbackslash{}site-packages\textbackslash{}graphviz\textbackslash{}files.py:22}}, in \textcolor{ansi-cyan}{<module>}
\textcolor{ansi-green}{     16} \_\_all\_\_ \def\tcRGB{\textcolor[RGB]}\expandafter\tcRGB\expandafter{\detokenize{98,98,98}}{=} [\def\tcRGB{\textcolor[RGB]}\expandafter\tcRGB\expandafter{\detokenize{175,0,0}}{'}\def\tcRGB{\textcolor[RGB]}\expandafter\tcRGB\expandafter{\detokenize{175,0,0}}{File}\def\tcRGB{\textcolor[RGB]}\expandafter\tcRGB\expandafter{\detokenize{175,0,0}}{'}, \def\tcRGB{\textcolor[RGB]}\expandafter\tcRGB\expandafter{\detokenize{175,0,0}}{'}\def\tcRGB{\textcolor[RGB]}\expandafter\tcRGB\expandafter{\detokenize{175,0,0}}{Source}\def\tcRGB{\textcolor[RGB]}\expandafter\tcRGB\expandafter{\detokenize{175,0,0}}{'}]
\textcolor{ansi-green}{     19} log \def\tcRGB{\textcolor[RGB]}\expandafter\tcRGB\expandafter{\detokenize{98,98,98}}{=} logging\def\tcRGB{\textcolor[RGB]}\expandafter\tcRGB\expandafter{\detokenize{98,98,98}}{.}getLogger(\def\tcRGB{\textcolor[RGB]}\expandafter\tcRGB\expandafter{\detokenize{0,0,135}}{\_\_name\_\_})
\textcolor{ansi-green-intense}{\textbf{---> 22}} \def\tcRGB{\textcolor[RGB]}\expandafter\tcRGB\expandafter{\detokenize{0,135,0}}{\textbf{class}} \def\tcRGB{\textcolor[RGB]}\expandafter\tcRGB\expandafter{\detokenize{0,0,255}}{\textbf{Base}}(\def\tcRGB{\textcolor[RGB]}\expandafter\tcRGB\expandafter{\detokenize{0,135,0}}{object}):
\textcolor{ansi-green}{     24}     \_engine \def\tcRGB{\textcolor[RGB]}\expandafter\tcRGB\expandafter{\detokenize{98,98,98}}{=} \def\tcRGB{\textcolor[RGB]}\expandafter\tcRGB\expandafter{\detokenize{175,0,0}}{'}\def\tcRGB{\textcolor[RGB]}\expandafter\tcRGB\expandafter{\detokenize{175,0,0}}{dot}\def\tcRGB{\textcolor[RGB]}\expandafter\tcRGB\expandafter{\detokenize{175,0,0}}{'}
\textcolor{ansi-green}{     26}     \_format \def\tcRGB{\textcolor[RGB]}\expandafter\tcRGB\expandafter{\detokenize{98,98,98}}{=} \def\tcRGB{\textcolor[RGB]}\expandafter\tcRGB\expandafter{\detokenize{175,0,0}}{'}\def\tcRGB{\textcolor[RGB]}\expandafter\tcRGB\expandafter{\detokenize{175,0,0}}{pdf}\def\tcRGB{\textcolor[RGB]}\expandafter\tcRGB\expandafter{\detokenize{175,0,0}}{'}

File \textcolor{ansi-green-intense}{\textbf{\textasciitilde{}\textbackslash{}anaconda3\textbackslash{}lib\textbackslash{}site-packages\textbackslash{}graphviz\textbackslash{}files.py:28}}, in \textcolor{ansi-cyan}{Base}\textcolor{ansi-blue-intense}{\textbf{()}}
\textcolor{ansi-green}{     24} \_engine \def\tcRGB{\textcolor[RGB]}\expandafter\tcRGB\expandafter{\detokenize{98,98,98}}{=} \def\tcRGB{\textcolor[RGB]}\expandafter\tcRGB\expandafter{\detokenize{175,0,0}}{'}\def\tcRGB{\textcolor[RGB]}\expandafter\tcRGB\expandafter{\detokenize{175,0,0}}{dot}\def\tcRGB{\textcolor[RGB]}\expandafter\tcRGB\expandafter{\detokenize{175,0,0}}{'}
\textcolor{ansi-green}{     26} \_format \def\tcRGB{\textcolor[RGB]}\expandafter\tcRGB\expandafter{\detokenize{98,98,98}}{=} \def\tcRGB{\textcolor[RGB]}\expandafter\tcRGB\expandafter{\detokenize{175,0,0}}{'}\def\tcRGB{\textcolor[RGB]}\expandafter\tcRGB\expandafter{\detokenize{175,0,0}}{pdf}\def\tcRGB{\textcolor[RGB]}\expandafter\tcRGB\expandafter{\detokenize{175,0,0}}{'}
\textcolor{ansi-green-intense}{\textbf{---> 28}} \_encoding \def\tcRGB{\textcolor[RGB]}\expandafter\tcRGB\expandafter{\detokenize{98,98,98}}{=} \setlength{\fboxsep}{0pt}\colorbox{ansi-yellow}{backend\strut}\def\tcRGB{\textcolor[RGB]}\expandafter\tcRGB\expandafter{\detokenize{98,98,98}}{\setlength{\fboxsep}{0pt}\colorbox{ansi-yellow}{.\strut}}\setlength{\fboxsep}{0pt}\colorbox{ansi-yellow}{ENCODING\strut}
\textcolor{ansi-green}{     30} \def\tcRGB{\textcolor[RGB]}\expandafter\tcRGB\expandafter{\detokenize{175,0,255}}{@property}
\textcolor{ansi-green}{     31} \def\tcRGB{\textcolor[RGB]}\expandafter\tcRGB\expandafter{\detokenize{0,135,0}}{\textbf{def}} \def\tcRGB{\textcolor[RGB]}\expandafter\tcRGB\expandafter{\detokenize{0,0,255}}{engine}(\def\tcRGB{\textcolor[RGB]}\expandafter\tcRGB\expandafter{\detokenize{0,135,0}}{self}):
\textcolor{ansi-green}{     32}     \def\tcRGB{\textcolor[RGB]}\expandafter\tcRGB\expandafter{\detokenize{175,0,0}}{"""The layout commmand used for rendering (``'dot'``, ``'neato'``, {\ldots})."""}

\textcolor{ansi-red-intense}{\textbf{AttributeError}}: module 'graphviz.backend' has no attribute 'ENCODING'
    \end{Verbatim}

    \begin{tcolorbox}[breakable, size=fbox, boxrule=1pt, pad at break*=1mm,colback=cellbackground, colframe=cellborder]
\prompt{In}{incolor}{ }{\boxspacing}
\begin{Verbatim}[commandchars=\\\{\}]
\PY{n}{X\PYZus{}prepared} \PY{o}{=} \PY{n}{X\PYZus{}train}\PY{o}{.}\PY{n}{copy}\PY{p}{(}\PY{p}{)}
\PY{n}{X\PYZus{}prepared\PYZus{}val} \PY{o}{=} \PY{n}{X\PYZus{}val}\PY{o}{.}\PY{n}{copy}\PY{p}{(}\PY{p}{)}
\end{Verbatim}
\end{tcolorbox}

    \begin{tcolorbox}[breakable, size=fbox, boxrule=1pt, pad at break*=1mm,colback=cellbackground, colframe=cellborder]
\prompt{In}{incolor}{ }{\boxspacing}
\begin{Verbatim}[commandchars=\\\{\}]
\PY{c+c1}{\PYZsh{} Feature Dropper Pipeline }
\PY{n}{var\PYZus{}drop} \PY{o}{=} \PY{p}{[}\PY{l+s+s1}{\PYZsq{}}\PY{l+s+s1}{parcelid}\PY{l+s+s1}{\PYZsq{}}\PY{p}{,}\PY{l+s+s1}{\PYZsq{}}\PY{l+s+s1}{censustractandblock}\PY{l+s+s1}{\PYZsq{}}\PY{p}{]}
\PY{n}{feature\PYZus{}dropper} \PY{o}{=} \PY{n}{utils}\PY{o}{.}\PY{n}{FeatureDropper}\PY{p}{(}\PY{n}{features\PYZus{}to\PYZus{}drop}\PY{o}{=}\PY{n}{var\PYZus{}drop}\PY{p}{)}

\PY{c+c1}{\PYZsh{} Convert Date Features Pipeline}
\PY{n}{year\PYZus{}feat\PYZus{}creator} \PY{o}{=} \PY{n}{utils}\PY{o}{.}\PY{n}{CreateYearFeatures}\PY{p}{(}\PY{n}{date\PYZus{}features}\PY{o}{=}\PY{n}{date\PYZus{}features}\PY{p}{)}

\PY{c+c1}{\PYZsh{} Date Feature Creator}
\PY{n}{date\PYZus{}feat\PYZus{}creator} \PY{o}{=} \PY{n}{utils}\PY{o}{.}\PY{n}{CreateDateFeatures}\PY{p}{(}\PY{p}{)}

\PY{c+c1}{\PYZsh{} Derived Features Creator}
\PY{n}{derived\PYZus{}feat\PYZus{}creator} \PY{o}{=} \PY{n}{utils}\PY{o}{.}\PY{n}{CreateDerivedFeatures}\PY{p}{(}\PY{p}{)}

\PY{c+c1}{\PYZsh{} Feature Encoding Pipeline}
\PY{n}{cat\PYZus{}vars} \PY{o}{=} \PY{p}{[}\PY{l+s+s1}{\PYZsq{}}\PY{l+s+s1}{transaction\PYZus{}year}\PY{l+s+s1}{\PYZsq{}}\PY{p}{,} \PY{l+s+s1}{\PYZsq{}}\PY{l+s+s1}{transaction\PYZus{}month}\PY{l+s+s1}{\PYZsq{}}\PY{p}{,} \PY{l+s+s1}{\PYZsq{}}\PY{l+s+s1}{transaction\PYZus{}day}\PY{l+s+s1}{\PYZsq{}}\PY{p}{,} \PY{l+s+s1}{\PYZsq{}}\PY{l+s+s1}{transaction\PYZus{}quarter}\PY{l+s+s1}{\PYZsq{}}\PY{p}{,} \PY{l+s+s1}{\PYZsq{}}\PY{l+s+s1}{airconditioningtypeid}\PY{l+s+s1}{\PYZsq{}}\PY{p}{,} 
            \PY{l+s+s1}{\PYZsq{}}\PY{l+s+s1}{buildingqualitytypeid}\PY{l+s+s1}{\PYZsq{}}\PY{p}{,} \PY{l+s+s1}{\PYZsq{}}\PY{l+s+s1}{fips}\PY{l+s+s1}{\PYZsq{}}\PY{p}{,} \PY{l+s+s1}{\PYZsq{}}\PY{l+s+s1}{heatingorsystemtypeid}\PY{l+s+s1}{\PYZsq{}}\PY{p}{,} \PY{l+s+s1}{\PYZsq{}}\PY{l+s+s1}{propertylandusetypeid}\PY{l+s+s1}{\PYZsq{}}\PY{p}{,} \PY{l+s+s1}{\PYZsq{}}\PY{l+s+s1}{regionidcity}\PY{l+s+s1}{\PYZsq{}}\PY{p}{,} \PY{l+s+s1}{\PYZsq{}}\PY{l+s+s1}{regionidcounty}\PY{l+s+s1}{\PYZsq{}}\PY{p}{,} 
            \PY{l+s+s1}{\PYZsq{}}\PY{l+s+s1}{regionidneighborhood}\PY{l+s+s1}{\PYZsq{}}\PY{p}{,} \PY{l+s+s1}{\PYZsq{}}\PY{l+s+s1}{regionidzip}\PY{l+s+s1}{\PYZsq{}}\PY{p}{,} \PY{l+s+s1}{\PYZsq{}}\PY{l+s+s1}{assessmentyear}\PY{l+s+s1}{\PYZsq{}}\PY{p}{,} \PY{l+s+s1}{\PYZsq{}}\PY{l+s+s1}{typeconstructiontypeid}\PY{l+s+s1}{\PYZsq{}}\PY{p}{,} \PY{l+s+s1}{\PYZsq{}}\PY{l+s+s1}{architecturalstyletypeid}\PY{l+s+s1}{\PYZsq{}}\PY{p}{,} 
            \PY{l+s+s1}{\PYZsq{}}\PY{l+s+s1}{buildingclasstypeid}\PY{l+s+s1}{\PYZsq{}}\PY{p}{,} \PY{l+s+s1}{\PYZsq{}}\PY{l+s+s1}{pooltypeid2}\PY{l+s+s1}{\PYZsq{}}\PY{p}{,} \PY{l+s+s1}{\PYZsq{}}\PY{l+s+s1}{pooltypeid7}\PY{l+s+s1}{\PYZsq{}}\PY{p}{,} \PY{l+s+s1}{\PYZsq{}}\PY{l+s+s1}{storytypeid}\PY{l+s+s1}{\PYZsq{}}\PY{p}{,}  \PY{l+s+s1}{\PYZsq{}}\PY{l+s+s1}{hashottuborspa}\PY{l+s+s1}{\PYZsq{}}\PY{p}{,} \PY{l+s+s1}{\PYZsq{}}\PY{l+s+s1}{pooltypeid2}\PY{l+s+s1}{\PYZsq{}}\PY{p}{,} 
            \PY{l+s+s1}{\PYZsq{}}\PY{l+s+s1}{taxdelinquencyyear}\PY{l+s+s1}{\PYZsq{}}\PY{p}{,}  \PY{l+s+s1}{\PYZsq{}}\PY{l+s+s1}{taxdelinquencyflag}\PY{l+s+s1}{\PYZsq{}}\PY{p}{,} \PY{l+s+s1}{\PYZsq{}}\PY{l+s+s1}{fireplaceflag}\PY{l+s+s1}{\PYZsq{}}\PY{p}{,} \PY{l+s+s1}{\PYZsq{}}\PY{l+s+s1}{decktypeid}\PY{l+s+s1}{\PYZsq{}}\PY{p}{,} \PY{l+s+s1}{\PYZsq{}}\PY{l+s+s1}{pooltypeid10}\PY{l+s+s1}{\PYZsq{}}\PY{p}{,} 
            \PY{l+s+s1}{\PYZsq{}}\PY{l+s+s1}{propertycountylandusecode}\PY{l+s+s1}{\PYZsq{}}\PY{p}{,} \PY{l+s+s1}{\PYZsq{}}\PY{l+s+s1}{propertyzoningdesc}\PY{l+s+s1}{\PYZsq{}}\PY{p}{,} \PY{l+s+s1}{\PYZsq{}}\PY{l+s+s1}{rawcensustractandblock}\PY{l+s+s1}{\PYZsq{}}\PY{p}{,} 
            \PY{c+c1}{\PYZsh{}\PYZsq{}N\PYZhy{}n\PYZus{}gar\PYZus{}pool\PYZus{}ac\PYZsq{},\PYZsq{}N\PYZhy{}PropType\PYZsq{},\PYZsq{}N\PYZhy{}HeatInd\PYZsq{},\PYZsq{}N\PYZhy{}ACInd\PYZsq{}}
           \PY{p}{]}
\PY{c+c1}{\PYZsh{} Feature Encoding Pipeline}
\PY{n}{feature\PYZus{}encoder} \PY{o}{=} \PY{n}{utils}\PY{o}{.}\PY{n}{ColumnTransformer}\PY{p}{(}\PY{p}{[}
    \PY{p}{(}\PY{l+s+s2}{\PYZdq{}}\PY{l+s+s2}{ohe\PYZus{}cats}\PY{l+s+s2}{\PYZdq{}}\PY{p}{,} \PY{n}{OneHotEncoder}\PY{p}{(}\PY{n}{handle\PYZus{}unknown}\PY{o}{=}\PY{l+s+s1}{\PYZsq{}}\PY{l+s+s1}{ignore}\PY{l+s+s1}{\PYZsq{}}\PY{p}{)}\PY{p}{,} \PY{n}{cat\PYZus{}vars}\PY{p}{)}\PY{p}{]}\PY{p}{,}
    \PY{n}{remainder}\PY{o}{=}\PY{l+s+s1}{\PYZsq{}}\PY{l+s+s1}{passthrough}\PY{l+s+s1}{\PYZsq{}}
\PY{p}{)}
\end{Verbatim}
\end{tcolorbox}

    \hypertarget{lightgbm-categorical-handling}{%
\subsubsection{LightGBM Categorical
Handling}\label{lightgbm-categorical-handling}}

LightGBM handles categorical variables different from other models which
mainly use One-Hot Encoding. It handles categorical variables by ranking
their marginal target value in each node.

For this problem, we tested using both One-Hot Encoding and LightGBM's
approach and decided to use OHE which performed much better.

    \begin{tcolorbox}[breakable, size=fbox, boxrule=1pt, pad at break*=1mm,colback=cellbackground, colframe=cellborder]
\prompt{In}{incolor}{ }{\boxspacing}
\begin{Verbatim}[commandchars=\\\{\}]
\PY{n}{lgbm\PYZus{}preprocessor} \PY{o}{=} \PY{n}{Pipeline}\PY{p}{(}\PY{p}{[}
    \PY{c+c1}{\PYZsh{}(\PYZsq{}derived\PYZus{}feat\PYZus{}creator\PYZsq{}, derived\PYZus{}feat\PYZus{}creator),}
    \PY{p}{(}\PY{l+s+s1}{\PYZsq{}}\PY{l+s+s1}{feature\PYZus{}dropper}\PY{l+s+s1}{\PYZsq{}}\PY{p}{,} \PY{n}{feature\PYZus{}dropper}\PY{p}{)}\PY{p}{,}
    \PY{p}{(}\PY{l+s+s1}{\PYZsq{}}\PY{l+s+s1}{date\PYZus{}feat\PYZus{}creator}\PY{l+s+s1}{\PYZsq{}}\PY{p}{,} \PY{n}{date\PYZus{}feat\PYZus{}creator}\PY{p}{)}\PY{p}{,}
    \PY{p}{(}\PY{l+s+s1}{\PYZsq{}}\PY{l+s+s1}{year\PYZus{}feat\PYZus{}creator}\PY{l+s+s1}{\PYZsq{}}\PY{p}{,} \PY{n}{year\PYZus{}feat\PYZus{}creator}\PY{p}{)}\PY{p}{,}
    \PY{p}{(}\PY{l+s+s1}{\PYZsq{}}\PY{l+s+s1}{feature\PYZus{}encoder}\PY{l+s+s1}{\PYZsq{}}\PY{p}{,} \PY{n}{feature\PYZus{}encoder}\PY{p}{)}\PY{p}{,}
\PY{p}{]}\PY{p}{)}

\PY{n}{data\PYZus{}prep\PYZus{}pipe} \PY{o}{=} \PY{n}{lgbm\PYZus{}preprocessor}\PY{o}{.}\PY{n}{fit}\PY{p}{(}\PY{n}{X\PYZus{}prepared}\PY{p}{)}
\PY{n}{X\PYZus{}prepared} \PY{o}{=} \PY{n}{lgbm\PYZus{}preprocessor}\PY{o}{.}\PY{n}{transform}\PY{p}{(}\PY{n}{X\PYZus{}prepared}\PY{p}{)}
\PY{n}{X\PYZus{}prepared\PYZus{}val} \PY{o}{=} \PY{n}{lgbm\PYZus{}preprocessor}\PY{o}{.}\PY{n}{transform}\PY{p}{(}\PY{n}{X\PYZus{}prepared\PYZus{}val}\PY{p}{)}
\end{Verbatim}
\end{tcolorbox}

    \begin{tcolorbox}[breakable, size=fbox, boxrule=1pt, pad at break*=1mm,colback=cellbackground, colframe=cellborder]
\prompt{In}{incolor}{ }{\boxspacing}
\begin{Verbatim}[commandchars=\\\{\}]
\PY{n}{X\PYZus{}lgbm} \PY{o}{=} \PY{n}{X\PYZus{}prepared}\PY{o}{.}\PY{n}{copy}\PY{p}{(}\PY{p}{)}
\PY{n}{X\PYZus{}lgbm\PYZus{}val} \PY{o}{=} \PY{n}{X\PYZus{}prepared\PYZus{}val}\PY{o}{.}\PY{n}{copy}\PY{p}{(}\PY{p}{)}
\end{Verbatim}
\end{tcolorbox}

    \hypertarget{lightgbm-hyperparameter-tuning-using-optuna}{%
\subsection{LightGBM Hyperparameter Tuning (Using
Optuna)}\label{lightgbm-hyperparameter-tuning-using-optuna}}

By the time I reached LightGBM for this project, I encountered another
hyperparameter tuning package called \texttt{Optuna} which is much newer
and more maintained than \texttt{hyperopt}. Thus, I decided to use
Optuna for LightGBM tuning. Optuna claims to perform better tuning than
TPE (Tree-structured Parzem Estimator) algorithms which is used by
\texttt{hyperopt} - I am unable to speak to it's comparative performance
but did find the package usage and documentation better than hyperopt.

    \begin{tcolorbox}[breakable, size=fbox, boxrule=1pt, pad at break*=1mm,colback=cellbackground, colframe=cellborder]
\prompt{In}{incolor}{ }{\boxspacing}
\begin{Verbatim}[commandchars=\\\{\}]
\PY{k}{def} \PY{n+nf}{objective}\PY{p}{(}\PY{n}{trial}\PY{p}{,} \PY{n}{X}\PY{p}{,} \PY{n}{y}\PY{p}{)}\PY{p}{:}
    \PY{n}{param\PYZus{}grid} \PY{o}{=} \PY{p}{\PYZob{}}
        \PY{l+s+s2}{\PYZdq{}}\PY{l+s+s2}{n\PYZus{}estimators}\PY{l+s+s2}{\PYZdq{}}\PY{p}{:} \PY{n}{trial}\PY{o}{.}\PY{n}{suggest\PYZus{}categorical}\PY{p}{(}\PY{l+s+s2}{\PYZdq{}}\PY{l+s+s2}{n\PYZus{}estimators}\PY{l+s+s2}{\PYZdq{}}\PY{p}{,} \PY{p}{[}\PY{l+m+mi}{10000}\PY{p}{]}\PY{p}{)}\PY{p}{,}
        \PY{l+s+s2}{\PYZdq{}}\PY{l+s+s2}{learning\PYZus{}rate}\PY{l+s+s2}{\PYZdq{}}\PY{p}{:} \PY{n}{trial}\PY{o}{.}\PY{n}{suggest\PYZus{}float}\PY{p}{(}\PY{l+s+s2}{\PYZdq{}}\PY{l+s+s2}{learning\PYZus{}rate}\PY{l+s+s2}{\PYZdq{}}\PY{p}{,} \PY{l+m+mf}{0.01}\PY{p}{,} \PY{l+m+mf}{0.3}\PY{p}{)}\PY{p}{,}
        \PY{l+s+s2}{\PYZdq{}}\PY{l+s+s2}{num\PYZus{}leaves}\PY{l+s+s2}{\PYZdq{}}\PY{p}{:} \PY{n}{trial}\PY{o}{.}\PY{n}{suggest\PYZus{}int}\PY{p}{(}\PY{l+s+s2}{\PYZdq{}}\PY{l+s+s2}{num\PYZus{}leaves}\PY{l+s+s2}{\PYZdq{}}\PY{p}{,} \PY{l+m+mi}{20}\PY{p}{,} \PY{l+m+mi}{3000}\PY{p}{,} \PY{n}{step}\PY{o}{=}\PY{l+m+mi}{20}\PY{p}{)}\PY{p}{,}
        \PY{l+s+s2}{\PYZdq{}}\PY{l+s+s2}{max\PYZus{}depth}\PY{l+s+s2}{\PYZdq{}}\PY{p}{:} \PY{n}{trial}\PY{o}{.}\PY{n}{suggest\PYZus{}int}\PY{p}{(}\PY{l+s+s2}{\PYZdq{}}\PY{l+s+s2}{max\PYZus{}depth}\PY{l+s+s2}{\PYZdq{}}\PY{p}{,} \PY{l+m+mi}{3}\PY{p}{,} \PY{l+m+mi}{12}\PY{p}{)}\PY{p}{,}
        \PY{l+s+s2}{\PYZdq{}}\PY{l+s+s2}{min\PYZus{}data\PYZus{}in\PYZus{}leaf}\PY{l+s+s2}{\PYZdq{}}\PY{p}{:} \PY{n}{trial}\PY{o}{.}\PY{n}{suggest\PYZus{}int}\PY{p}{(}\PY{l+s+s2}{\PYZdq{}}\PY{l+s+s2}{min\PYZus{}data\PYZus{}in\PYZus{}leaf}\PY{l+s+s2}{\PYZdq{}}\PY{p}{,} \PY{l+m+mi}{200}\PY{p}{,} \PY{l+m+mi}{10000}\PY{p}{,} \PY{n}{step}\PY{o}{=}\PY{l+m+mi}{100}\PY{p}{)}\PY{p}{,}
        \PY{l+s+s2}{\PYZdq{}}\PY{l+s+s2}{lambda\PYZus{}l1}\PY{l+s+s2}{\PYZdq{}}\PY{p}{:} \PY{n}{trial}\PY{o}{.}\PY{n}{suggest\PYZus{}int}\PY{p}{(}\PY{l+s+s2}{\PYZdq{}}\PY{l+s+s2}{lambda\PYZus{}l1}\PY{l+s+s2}{\PYZdq{}}\PY{p}{,} \PY{l+m+mi}{0}\PY{p}{,} \PY{l+m+mi}{100}\PY{p}{,} \PY{n}{step}\PY{o}{=}\PY{l+m+mi}{5}\PY{p}{)}\PY{p}{,}
        \PY{l+s+s2}{\PYZdq{}}\PY{l+s+s2}{lambda\PYZus{}l2}\PY{l+s+s2}{\PYZdq{}}\PY{p}{:} \PY{n}{trial}\PY{o}{.}\PY{n}{suggest\PYZus{}int}\PY{p}{(}\PY{l+s+s2}{\PYZdq{}}\PY{l+s+s2}{lambda\PYZus{}l2}\PY{l+s+s2}{\PYZdq{}}\PY{p}{,} \PY{l+m+mi}{0}\PY{p}{,} \PY{l+m+mi}{100}\PY{p}{,} \PY{n}{step}\PY{o}{=}\PY{l+m+mi}{5}\PY{p}{)}\PY{p}{,}
        \PY{l+s+s2}{\PYZdq{}}\PY{l+s+s2}{min\PYZus{}gain\PYZus{}to\PYZus{}split}\PY{l+s+s2}{\PYZdq{}}\PY{p}{:} \PY{n}{trial}\PY{o}{.}\PY{n}{suggest\PYZus{}float}\PY{p}{(}\PY{l+s+s2}{\PYZdq{}}\PY{l+s+s2}{min\PYZus{}gain\PYZus{}to\PYZus{}split}\PY{l+s+s2}{\PYZdq{}}\PY{p}{,} \PY{l+m+mi}{0}\PY{p}{,} \PY{l+m+mi}{15}\PY{p}{)}\PY{p}{,}
        \PY{l+s+s2}{\PYZdq{}}\PY{l+s+s2}{bagging\PYZus{}fraction}\PY{l+s+s2}{\PYZdq{}}\PY{p}{:} \PY{n}{trial}\PY{o}{.}\PY{n}{suggest\PYZus{}float}\PY{p}{(}\PY{l+s+s2}{\PYZdq{}}\PY{l+s+s2}{bagging\PYZus{}fraction}\PY{l+s+s2}{\PYZdq{}}\PY{p}{,} \PY{l+m+mf}{0.2}\PY{p}{,} \PY{l+m+mf}{0.95}\PY{p}{,} \PY{n}{step}\PY{o}{=}\PY{l+m+mf}{0.1}\PY{p}{)}\PY{p}{,}
        \PY{l+s+s2}{\PYZdq{}}\PY{l+s+s2}{bagging\PYZus{}freq}\PY{l+s+s2}{\PYZdq{}}\PY{p}{:} \PY{n}{trial}\PY{o}{.}\PY{n}{suggest\PYZus{}categorical}\PY{p}{(}\PY{l+s+s2}{\PYZdq{}}\PY{l+s+s2}{bagging\PYZus{}freq}\PY{l+s+s2}{\PYZdq{}}\PY{p}{,} \PY{p}{[}\PY{l+m+mi}{1}\PY{p}{]}\PY{p}{)}\PY{p}{,}
        \PY{l+s+s2}{\PYZdq{}}\PY{l+s+s2}{feature\PYZus{}fraction}\PY{l+s+s2}{\PYZdq{}}\PY{p}{:} \PY{n}{trial}\PY{o}{.}\PY{n}{suggest\PYZus{}float}\PY{p}{(}\PY{l+s+s2}{\PYZdq{}}\PY{l+s+s2}{feature\PYZus{}fraction}\PY{l+s+s2}{\PYZdq{}}\PY{p}{,} \PY{l+m+mf}{0.2}\PY{p}{,} \PY{l+m+mf}{0.95}\PY{p}{,} \PY{n}{step}\PY{o}{=}\PY{l+m+mf}{0.1}\PY{p}{)}\PY{p}{,}
    \PY{p}{\PYZcb{}}
    
    \PY{n}{cv} \PY{o}{=} \PY{n}{KFold}\PY{p}{(}\PY{n}{n\PYZus{}splits}\PY{o}{=}\PY{l+m+mi}{5}\PY{p}{,} \PY{n}{shuffle}\PY{o}{=}\PY{k+kc}{True}\PY{p}{,} \PY{n}{random\PYZus{}state}\PY{o}{=}\PY{l+m+mi}{42}\PY{p}{)}

    \PY{n}{cv\PYZus{}scores} \PY{o}{=} \PY{n}{np}\PY{o}{.}\PY{n}{empty}\PY{p}{(}\PY{l+m+mi}{5}\PY{p}{)}
    \PY{k}{for} \PY{n}{idx}\PY{p}{,} \PY{p}{(}\PY{n}{train\PYZus{}idx}\PY{p}{,} \PY{n}{test\PYZus{}idx}\PY{p}{)} \PY{o+ow}{in} \PY{n+nb}{enumerate}\PY{p}{(}\PY{n}{cv}\PY{o}{.}\PY{n}{split}\PY{p}{(}\PY{n}{X}\PY{p}{,} \PY{n}{y}\PY{p}{)}\PY{p}{)}\PY{p}{:}
        \PY{n}{X\PYZus{}train}\PY{p}{,} \PY{n}{X\PYZus{}test} \PY{o}{=} \PY{n}{X}\PY{o}{.}\PY{n}{iloc}\PY{p}{[}\PY{n}{train\PYZus{}idx}\PY{p}{]}\PY{p}{,} \PY{n}{X}\PY{o}{.}\PY{n}{iloc}\PY{p}{[}\PY{n}{test\PYZus{}idx}\PY{p}{]}
        \PY{n}{y\PYZus{}train}\PY{p}{,} \PY{n}{y\PYZus{}test} \PY{o}{=} \PY{n}{y}\PY{p}{[}\PY{n}{train\PYZus{}idx}\PY{p}{]}\PY{p}{,} \PY{n}{y}\PY{p}{[}\PY{n}{test\PYZus{}idx}\PY{p}{]}

        \PY{n}{model} \PY{o}{=} \PY{n}{lgbm}\PY{o}{.}\PY{n}{LGBMRegressor}\PY{p}{(}\PY{o}{*}\PY{o}{*}\PY{n}{param\PYZus{}grid}\PY{p}{)}
        \PY{n}{model}\PY{o}{.}\PY{n}{fit}\PY{p}{(}
            \PY{n}{X\PYZus{}train}\PY{p}{,}
            \PY{n}{y\PYZus{}train}\PY{p}{,}
            \PY{n}{eval\PYZus{}set}\PY{o}{=}\PY{p}{[}\PY{p}{(}\PY{n}{X\PYZus{}test}\PY{p}{,} \PY{n}{y\PYZus{}test}\PY{p}{)}\PY{p}{]}\PY{p}{,}
            \PY{n}{eval\PYZus{}metric}\PY{o}{=}\PY{l+s+s2}{\PYZdq{}}\PY{l+s+s2}{mae}\PY{l+s+s2}{\PYZdq{}}\PY{p}{,}
            \PY{n}{verbose}\PY{o}{=}\PY{k+kc}{False}\PY{p}{,}
            \PY{n}{early\PYZus{}stopping\PYZus{}rounds}\PY{o}{=}\PY{l+m+mi}{25}\PY{p}{,}
            \PY{n}{callbacks}\PY{o}{=}\PY{p}{[}
                \PY{n}{LightGBMPruningCallback}\PY{p}{(}\PY{n}{trial}\PY{p}{,} \PY{l+s+s2}{\PYZdq{}}\PY{l+s+s2}{l1}\PY{l+s+s2}{\PYZdq{}}\PY{p}{)}
            \PY{p}{]}\PY{p}{,}  \PY{c+c1}{\PYZsh{} Add a pruning callback}
        \PY{p}{)}
        \PY{n}{preds} \PY{o}{=} \PY{n}{model}\PY{o}{.}\PY{n}{predict}\PY{p}{(}\PY{n}{X\PYZus{}test}\PY{p}{)}
        \PY{n}{cv\PYZus{}scores}\PY{p}{[}\PY{n}{idx}\PY{p}{]} \PY{o}{=} \PY{n}{mean\PYZus{}absolute\PYZus{}error}\PY{p}{(}\PY{n}{y\PYZus{}test}\PY{p}{,} \PY{n}{preds}\PY{p}{)}

    \PY{k}{return} \PY{n}{np}\PY{o}{.}\PY{n}{mean}\PY{p}{(}\PY{n}{cv\PYZus{}scores}\PY{p}{)}
\end{Verbatim}
\end{tcolorbox}

    \begin{tcolorbox}[breakable, size=fbox, boxrule=1pt, pad at break*=1mm,colback=cellbackground, colframe=cellborder]
\prompt{In}{incolor}{ }{\boxspacing}
\begin{Verbatim}[commandchars=\\\{\}]
\PY{c+c1}{\PYZsh{} Similar to Hyperopt \PYZhy{} this code creates an experiment using the objective function and parameter grid above}
\PY{c+c1}{\PYZsh{}study = optuna.create\PYZus{}study(direction=\PYZdq{}minimize\PYZdq{}, study\PYZus{}name=\PYZdq{}LGBM Regressor\PYZdq{})}
\PY{c+c1}{\PYZsh{}func = lambda trial: objective(trial, X\PYZus{}prepared, y\PYZus{}train.to\PYZus{}numpy())}
\PY{c+c1}{\PYZsh{}study.optimize(func, n\PYZus{}trials=10000)}
\end{Verbatim}
\end{tcolorbox}

    \begin{tcolorbox}[breakable, size=fbox, boxrule=1pt, pad at break*=1mm,colback=cellbackground, colframe=cellborder]
\prompt{In}{incolor}{ }{\boxspacing}
\begin{Verbatim}[commandchars=\\\{\}]
\PY{c+c1}{\PYZsh{}print(f\PYZdq{}\PYZbs{}tBest value (mae): \PYZob{}study.best\PYZus{}value:.5f\PYZcb{}\PYZdq{})}
\PY{c+c1}{\PYZsh{}print(f\PYZdq{}\PYZbs{}tBest params:\PYZdq{})}

\PY{c+c1}{\PYZsh{}for key, value in study.best\PYZus{}params.items():}
    \PY{c+c1}{\PYZsh{}print(f\PYZdq{}\PYZbs{}t\PYZbs{}t\PYZob{}key\PYZcb{}: \PYZob{}value\PYZcb{}\PYZdq{})}
\end{Verbatim}
\end{tcolorbox}

    \begin{tcolorbox}[breakable, size=fbox, boxrule=1pt, pad at break*=1mm,colback=cellbackground, colframe=cellborder]
\prompt{In}{incolor}{ }{\boxspacing}
\begin{Verbatim}[commandchars=\\\{\}]
\PY{o}{\PYZpc{}\PYZpc{}time}

\PY{n}{fit\PYZus{}params}\PY{o}{=}\PY{p}{\PYZob{}}
    \PY{l+s+s1}{\PYZsq{}}\PY{l+s+s1}{early\PYZus{}stopping\PYZus{}rounds}\PY{l+s+s1}{\PYZsq{}}\PY{p}{:} \PY{l+m+mi}{30}\PY{p}{,} 
    \PY{l+s+s1}{\PYZsq{}}\PY{l+s+s1}{eval\PYZus{}metric}\PY{l+s+s1}{\PYZsq{}}\PY{p}{:} \PY{l+s+s1}{\PYZsq{}}\PY{l+s+s1}{mae}\PY{l+s+s1}{\PYZsq{}}\PY{p}{,}
    \PY{l+s+s1}{\PYZsq{}}\PY{l+s+s1}{verbose}\PY{l+s+s1}{\PYZsq{}}\PY{p}{:} \PY{k+kc}{False}\PY{p}{,}
    \PY{l+s+s1}{\PYZsq{}}\PY{l+s+s1}{eval\PYZus{}set}\PY{l+s+s1}{\PYZsq{}}\PY{p}{:} \PY{p}{[}\PY{p}{[}\PY{n}{X\PYZus{}prepared\PYZus{}val}\PY{p}{,} \PY{n}{y\PYZus{}val}\PY{p}{]}\PY{p}{]}
\PY{p}{\PYZcb{}}

\PY{n}{best\PYZus{}params} \PY{o}{=} \PY{p}{\PYZob{}}
    \PY{l+s+s1}{\PYZsq{}}\PY{l+s+s1}{num\PYZus{}leaves}\PY{l+s+s1}{\PYZsq{}}\PY{p}{:} \PY{l+m+mi}{512}\PY{p}{,}
    \PY{l+s+s1}{\PYZsq{}}\PY{l+s+s1}{max\PYZus{}depth}\PY{l+s+s1}{\PYZsq{}}\PY{p}{:} \PY{l+m+mi}{9}\PY{p}{,}
    \PY{l+s+s1}{\PYZsq{}}\PY{l+s+s1}{lambda\PYZus{}l2}\PY{l+s+s1}{\PYZsq{}}\PY{p}{:} \PY{l+m+mi}{15}\PY{p}{,}
    \PY{l+s+s1}{\PYZsq{}}\PY{l+s+s1}{bagging\PYZus{}fraction}\PY{l+s+s1}{\PYZsq{}}\PY{p}{:} \PY{l+m+mf}{0.9}\PY{p}{,}
    \PY{l+s+s1}{\PYZsq{}}\PY{l+s+s1}{feature\PYZus{}fraction}\PY{l+s+s1}{\PYZsq{}}\PY{p}{:} \PY{l+m+mf}{0.6}\PY{p}{,}
    \PY{l+s+s1}{\PYZsq{}}\PY{l+s+s1}{learning\PYZus{}rate}\PY{l+s+s1}{\PYZsq{}}\PY{p}{:} \PY{l+m+mf}{0.01}\PY{p}{,}
    \PY{l+s+s1}{\PYZsq{}}\PY{l+s+s1}{n\PYZus{}estimators}\PY{l+s+s1}{\PYZsq{}}\PY{p}{:} \PY{l+m+mi}{10000}\PY{p}{,}
    \PY{l+s+s1}{\PYZsq{}}\PY{l+s+s1}{random\PYZus{}state}\PY{l+s+s1}{\PYZsq{}}\PY{p}{:} \PY{l+m+mi}{42}\PY{p}{,}
\PY{p}{\PYZcb{}}


\PY{n}{lgbm\PYZus{}base} \PY{o}{=} \PY{n}{lgbm}\PY{o}{.}\PY{n}{LGBMRegressor}\PY{p}{(}\PY{o}{*}\PY{o}{*}\PY{n}{best\PYZus{}params}\PY{p}{)}
\PY{n}{lgbm\PYZus{}base}\PY{o}{.}\PY{n}{fit}\PY{p}{(}\PY{n}{X\PYZus{}prepared}\PY{p}{,} \PY{n}{y\PYZus{}train}\PY{p}{,} \PY{o}{*}\PY{o}{*}\PY{n}{fit\PYZus{}params}\PY{p}{)}
\PY{n}{utils}\PY{o}{.}\PY{n}{get\PYZus{}cross\PYZus{}val\PYZus{}scores}\PY{p}{(}\PY{p}{[}\PY{n}{lgbm\PYZus{}base}\PY{p}{]}\PY{p}{,} \PY{n}{X\PYZus{}prepared}\PY{p}{,} \PY{n}{y\PYZus{}train}\PY{p}{,} \PY{n}{cv}\PY{o}{=}\PY{l+m+mi}{3}\PY{p}{,} \PY{n}{fit\PYZus{}params}\PY{o}{=}\PY{n}{fit\PYZus{}params}\PY{p}{)}
\end{Verbatim}
\end{tcolorbox}

    \begin{tcolorbox}[breakable, size=fbox, boxrule=1pt, pad at break*=1mm,colback=cellbackground, colframe=cellborder]
\prompt{In}{incolor}{ }{\boxspacing}
\begin{Verbatim}[commandchars=\\\{\}]
\PY{o}{\PYZpc{}\PYZpc{}time}
\PY{n}{result} \PY{o}{=} \PY{n}{utils}\PY{o}{.}\PY{n}{get\PYZus{}eval\PYZus{}metrics}\PY{p}{(}\PY{p}{[}\PY{n}{lgbm\PYZus{}base}\PY{p}{]}\PY{p}{,} \PY{n}{X\PYZus{}prepared\PYZus{}val}\PY{p}{,} \PY{n}{y\PYZus{}val}\PY{p}{)}
\PY{n}{utils}\PY{o}{.}\PY{n}{get\PYZus{}cross\PYZus{}val\PYZus{}scores}\PY{p}{(}\PY{p}{[}\PY{n}{lgbm\PYZus{}base}\PY{p}{]}\PY{p}{,} \PY{n}{X\PYZus{}prepared}\PY{p}{,} \PY{n}{y\PYZus{}train}\PY{p}{,} \PY{n}{cv}\PY{o}{=}\PY{l+m+mi}{3}\PY{p}{,} \PY{n}{fit\PYZus{}params}\PY{o}{=}\PY{n}{fit\PYZus{}params}\PY{p}{)}
\PY{n}{results}\PY{p}{[}\PY{l+s+s1}{\PYZsq{}}\PY{l+s+s1}{LGBM}\PY{l+s+s1}{\PYZsq{}}\PY{p}{]} \PY{o}{=} \PY{n}{result}
\end{Verbatim}
\end{tcolorbox}

    \hypertarget{catboost}{%
\section{8 - CATBoost}\label{catboost}}

    \begin{tcolorbox}[breakable, size=fbox, boxrule=1pt, pad at break*=1mm,colback=cellbackground, colframe=cellborder]
\prompt{In}{incolor}{85}{\boxspacing}
\begin{Verbatim}[commandchars=\\\{\}]
\PY{k+kn}{import} \PY{n+nn}{catboost} \PY{k}{as} \PY{n+nn}{cb}
\PY{k+kn}{import} \PY{n+nn}{optuna} 
\PY{k+kn}{from} \PY{n+nn}{sklearn}\PY{n+nn}{.}\PY{n+nn}{model\PYZus{}selection} \PY{k+kn}{import} \PY{n}{cross\PYZus{}val\PYZus{}score}\PY{p}{,} \PY{n}{KFold}
\PY{k+kn}{from} \PY{n+nn}{sklearn}\PY{n+nn}{.}\PY{n+nn}{metrics} \PY{k+kn}{import} \PY{n}{mean\PYZus{}squared\PYZus{}error}\PY{p}{,} \PY{n}{mean\PYZus{}absolute\PYZus{}error}\PY{p}{,} \PY{n}{make\PYZus{}scorer}
\end{Verbatim}
\end{tcolorbox}

    \begin{tcolorbox}[breakable, size=fbox, boxrule=1pt, pad at break*=1mm,colback=cellbackground, colframe=cellborder]
\prompt{In}{incolor}{86}{\boxspacing}
\begin{Verbatim}[commandchars=\\\{\}]
\PY{n}{X\PYZus{}prepared} \PY{o}{=} \PY{n}{X\PYZus{}train}\PY{o}{.}\PY{n}{copy}\PY{p}{(}\PY{p}{)}
\PY{n}{X\PYZus{}prepared\PYZus{}val} \PY{o}{=} \PY{n}{X\PYZus{}val}\PY{o}{.}\PY{n}{copy}\PY{p}{(}\PY{p}{)}
\end{Verbatim}
\end{tcolorbox}

    \begin{tcolorbox}[breakable, size=fbox, boxrule=1pt, pad at break*=1mm,colback=cellbackground, colframe=cellborder]
\prompt{In}{incolor}{87}{\boxspacing}
\begin{Verbatim}[commandchars=\\\{\}]
\PY{c+c1}{\PYZsh{} Feature Dropper Pipeline}
\PY{n}{var\PYZus{}drop} \PY{o}{=} \PY{p}{[}\PY{l+s+s1}{\PYZsq{}}\PY{l+s+s1}{parcelid}\PY{l+s+s1}{\PYZsq{}}\PY{p}{,}\PY{l+s+s1}{\PYZsq{}}\PY{l+s+s1}{censustractandblock}\PY{l+s+s1}{\PYZsq{}}\PY{p}{,}\PY{l+s+s1}{\PYZsq{}}\PY{l+s+s1}{pooltypeid10}\PY{l+s+s1}{\PYZsq{}}\PY{p}{]}
\PY{n}{feature\PYZus{}dropper} \PY{o}{=} \PY{n}{utils}\PY{o}{.}\PY{n}{FeatureDropper}\PY{p}{(}\PY{n}{features\PYZus{}to\PYZus{}drop}\PY{o}{=}\PY{n}{var\PYZus{}drop}\PY{p}{)}

\PY{n}{date\PYZus{}features} \PY{o}{=} \PY{p}{\PYZob{}}\PY{l+s+s2}{\PYZdq{}}\PY{l+s+s2}{yearbuilt}\PY{l+s+s2}{\PYZdq{}}\PY{p}{:} \PY{l+s+s2}{\PYZdq{}}\PY{l+s+s2}{house\PYZus{}age}\PY{l+s+s2}{\PYZdq{}}\PY{p}{\PYZcb{}}
\PY{c+c1}{\PYZsh{} Convert Date Features Pipeline}
\PY{n}{year\PYZus{}feat\PYZus{}creator} \PY{o}{=} \PY{n}{utils}\PY{o}{.}\PY{n}{CreateYearFeatures}\PY{p}{(}\PY{n}{date\PYZus{}features}\PY{o}{=}\PY{n}{date\PYZus{}features}\PY{p}{)}

\PY{c+c1}{\PYZsh{} Impute 0}
\PY{n}{impute\PYZus{}0\PYZus{}vars} \PY{o}{=} \PY{p}{[}\PY{l+s+s2}{\PYZdq{}}\PY{l+s+s2}{yardbuildingsqft17}\PY{l+s+s2}{\PYZdq{}}\PY{p}{,} \PY{l+s+s2}{\PYZdq{}}\PY{l+s+s2}{fireplacecnt}\PY{l+s+s2}{\PYZdq{}}\PY{p}{,} \PY{l+s+s2}{\PYZdq{}}\PY{l+s+s2}{poolcnt}\PY{l+s+s2}{\PYZdq{}}\PY{p}{,} \PY{l+s+s2}{\PYZdq{}}\PY{l+s+s2}{garagetotalsqft}\PY{l+s+s2}{\PYZdq{}}\PY{p}{,}\PY{l+s+s2}{\PYZdq{}}\PY{l+s+s2}{garagecarcnt}\PY{l+s+s2}{\PYZdq{}}\PY{p}{,} 
                 \PY{l+s+s2}{\PYZdq{}}\PY{l+s+s2}{pooltypeid2}\PY{l+s+s2}{\PYZdq{}}\PY{p}{,} \PY{l+s+s2}{\PYZdq{}}\PY{l+s+s2}{poolsizesum}\PY{l+s+s2}{\PYZdq{}}\PY{p}{,} \PY{l+s+s2}{\PYZdq{}}\PY{l+s+s2}{decktypeid}\PY{l+s+s2}{\PYZdq{}}\PY{p}{,} \PY{l+s+s2}{\PYZdq{}}\PY{l+s+s2}{taxdelinquencyflag}\PY{l+s+s2}{\PYZdq{}}\PY{p}{,}\PY{l+s+s2}{\PYZdq{}}\PY{l+s+s2}{pooltypeid7}\PY{l+s+s2}{\PYZdq{}}\PY{p}{,}\PY{p}{]}

\PY{n}{univariate\PYZus{}impute\PYZus{}pipe} \PY{o}{=} \PY{n}{utils}\PY{o}{.}\PY{n}{ColumnTransformer}\PY{p}{(}\PY{p}{[}
        \PY{p}{(}\PY{l+s+s2}{\PYZdq{}}\PY{l+s+s2}{impute\PYZus{}0}\PY{l+s+s2}{\PYZdq{}}\PY{p}{,} \PY{n}{SimpleImputer}\PY{p}{(}\PY{n}{strategy}\PY{o}{=}\PY{l+s+s2}{\PYZdq{}}\PY{l+s+s2}{constant}\PY{l+s+s2}{\PYZdq{}}\PY{p}{,} \PY{n}{fill\PYZus{}value}\PY{o}{=}\PY{l+m+mi}{0}\PY{p}{)}\PY{p}{,} \PY{n}{impute\PYZus{}0\PYZus{}vars}\PY{p}{)}\PY{p}{,}
     \PY{p}{]}\PY{p}{,}
    \PY{n}{remainder}\PY{o}{=}\PY{l+s+s1}{\PYZsq{}}\PY{l+s+s1}{passthrough}\PY{l+s+s1}{\PYZsq{}}
\PY{p}{)}
\PY{c+c1}{\PYZsh{} Feature Encoding Pipeline}
\PY{n}{cat\PYZus{}vars} \PY{o}{=} \PY{p}{[}\PY{l+s+s1}{\PYZsq{}}\PY{l+s+s1}{transaction\PYZus{}year}\PY{l+s+s1}{\PYZsq{}}\PY{p}{,}\PY{l+s+s1}{\PYZsq{}}\PY{l+s+s1}{transaction\PYZus{}month}\PY{l+s+s1}{\PYZsq{}}\PY{p}{,} \PY{l+s+s1}{\PYZsq{}}\PY{l+s+s1}{transaction\PYZus{}day}\PY{l+s+s1}{\PYZsq{}}\PY{p}{,} \PY{l+s+s1}{\PYZsq{}}\PY{l+s+s1}{transaction\PYZus{}quarter}\PY{l+s+s1}{\PYZsq{}}\PY{p}{,} \PY{l+s+s1}{\PYZsq{}}\PY{l+s+s1}{airconditioningtypeid}\PY{l+s+s1}{\PYZsq{}}\PY{p}{,} 
            \PY{l+s+s1}{\PYZsq{}}\PY{l+s+s1}{buildingqualitytypeid}\PY{l+s+s1}{\PYZsq{}}\PY{p}{,} \PY{l+s+s1}{\PYZsq{}}\PY{l+s+s1}{fips}\PY{l+s+s1}{\PYZsq{}}\PY{p}{,} \PY{l+s+s1}{\PYZsq{}}\PY{l+s+s1}{heatingorsystemtypeid}\PY{l+s+s1}{\PYZsq{}}\PY{p}{,} \PY{l+s+s1}{\PYZsq{}}\PY{l+s+s1}{propertylandusetypeid}\PY{l+s+s1}{\PYZsq{}}\PY{p}{,} \PY{l+s+s1}{\PYZsq{}}\PY{l+s+s1}{regionidcity}\PY{l+s+s1}{\PYZsq{}}\PY{p}{,} \PY{l+s+s1}{\PYZsq{}}\PY{l+s+s1}{regionidcounty}\PY{l+s+s1}{\PYZsq{}}\PY{p}{,} 
            \PY{l+s+s1}{\PYZsq{}}\PY{l+s+s1}{regionidneighborhood}\PY{l+s+s1}{\PYZsq{}}\PY{p}{,} \PY{l+s+s1}{\PYZsq{}}\PY{l+s+s1}{regionidzip}\PY{l+s+s1}{\PYZsq{}}\PY{p}{,} \PY{l+s+s1}{\PYZsq{}}\PY{l+s+s1}{assessmentyear}\PY{l+s+s1}{\PYZsq{}}\PY{p}{,} \PY{l+s+s1}{\PYZsq{}}\PY{l+s+s1}{typeconstructiontypeid}\PY{l+s+s1}{\PYZsq{}}\PY{p}{,} \PY{l+s+s1}{\PYZsq{}}\PY{l+s+s1}{architecturalstyletypeid}\PY{l+s+s1}{\PYZsq{}}\PY{p}{,} 
            \PY{l+s+s1}{\PYZsq{}}\PY{l+s+s1}{buildingclasstypeid}\PY{l+s+s1}{\PYZsq{}}\PY{p}{,} \PY{l+s+s1}{\PYZsq{}}\PY{l+s+s1}{pooltypeid2}\PY{l+s+s1}{\PYZsq{}}\PY{p}{,} \PY{l+s+s1}{\PYZsq{}}\PY{l+s+s1}{pooltypeid7}\PY{l+s+s1}{\PYZsq{}}\PY{p}{,} \PY{l+s+s1}{\PYZsq{}}\PY{l+s+s1}{storytypeid}\PY{l+s+s1}{\PYZsq{}}\PY{p}{,}  \PY{l+s+s1}{\PYZsq{}}\PY{l+s+s1}{hashottuborspa}\PY{l+s+s1}{\PYZsq{}}\PY{p}{,}\PY{c+c1}{\PYZsh{} \PYZsq{}pooltypeid10\PYZsq{},}
            \PY{l+s+s1}{\PYZsq{}}\PY{l+s+s1}{taxdelinquencyyear}\PY{l+s+s1}{\PYZsq{}}\PY{p}{,}  \PY{l+s+s1}{\PYZsq{}}\PY{l+s+s1}{taxdelinquencyflag}\PY{l+s+s1}{\PYZsq{}}\PY{p}{,} \PY{l+s+s1}{\PYZsq{}}\PY{l+s+s1}{fireplaceflag}\PY{l+s+s1}{\PYZsq{}}\PY{p}{,} \PY{l+s+s1}{\PYZsq{}}\PY{l+s+s1}{decktypeid}\PY{l+s+s1}{\PYZsq{}} \PY{p}{,} \PY{l+s+s1}{\PYZsq{}}\PY{l+s+s1}{rawcensustractandblock}\PY{l+s+s1}{\PYZsq{}}\PY{p}{,}
            \PY{l+s+s1}{\PYZsq{}}\PY{l+s+s1}{propertycountylandusecode}\PY{l+s+s1}{\PYZsq{}}\PY{p}{,} \PY{l+s+s1}{\PYZsq{}}\PY{l+s+s1}{propertyzoningdesc}\PY{l+s+s1}{\PYZsq{}}\PY{p}{,}\PY{c+c1}{\PYZsh{}\PYZsq{}N\PYZhy{}PropType\PYZsq{},}
           \PY{p}{]}
\PY{n}{convert\PYZus{}to\PYZus{}cat} \PY{o}{=} \PY{n}{utils}\PY{o}{.}\PY{n}{ConvertToType}\PY{p}{(}\PY{n}{var\PYZus{}type}\PY{o}{=}\PY{l+s+s1}{\PYZsq{}}\PY{l+s+s1}{str}\PY{l+s+s1}{\PYZsq{}}\PY{p}{,} \PY{n}{vars\PYZus{}to\PYZus{}convert}\PY{o}{=}\PY{n}{cat\PYZus{}vars}\PY{p}{)}

\PY{c+c1}{\PYZsh{} Date Feature Creator}
\PY{n}{date\PYZus{}feat\PYZus{}creator} \PY{o}{=} \PY{n}{utils}\PY{o}{.}\PY{n}{CreateDateFeatures}\PY{p}{(}\PY{p}{)}

\PY{c+c1}{\PYZsh{} Derived Features Creator}
\PY{n}{derived\PYZus{}feat\PYZus{}creator} \PY{o}{=} \PY{n}{utils}\PY{o}{.}\PY{n}{CreateDerivedFeatures}\PY{p}{(}\PY{p}{)}

\PY{c+c1}{\PYZsh{}Split census}
\PY{n}{split\PYZus{}census} \PY{o}{=} \PY{n}{utils}\PY{o}{.}\PY{n}{SplitCensus}\PY{p}{(}\PY{p}{)}

\PY{c+c1}{\PYZsh{} Aggregated Feature Creator}
\PY{n}{group\PYZus{}col} \PY{o}{=} \PY{l+s+s1}{\PYZsq{}}\PY{l+s+s1}{regionidcity}\PY{l+s+s1}{\PYZsq{}}
\PY{n}{agg\PYZus{}cols} \PY{o}{=} \PY{p}{[}\PY{l+s+s1}{\PYZsq{}}\PY{l+s+s1}{lotsizesquarefeet}\PY{l+s+s1}{\PYZsq{}}\PY{p}{,} \PY{l+s+s1}{\PYZsq{}}\PY{l+s+s1}{yearbuilt}\PY{l+s+s1}{\PYZsq{}}\PY{p}{,} \PY{l+s+s1}{\PYZsq{}}\PY{l+s+s1}{calculatedfinishedsquarefeet}\PY{l+s+s1}{\PYZsq{}}\PY{p}{,}
            \PY{l+s+s1}{\PYZsq{}}\PY{l+s+s1}{structuretaxvaluedollarcnt}\PY{l+s+s1}{\PYZsq{}}\PY{p}{,} \PY{l+s+s1}{\PYZsq{}}\PY{l+s+s1}{landtaxvaluedollarcnt}\PY{l+s+s1}{\PYZsq{}}\PY{p}{,} \PY{l+s+s1}{\PYZsq{}}\PY{l+s+s1}{taxamount}\PY{l+s+s1}{\PYZsq{}}\PY{p}{]}
\PY{c+c1}{\PYZsh{}aggregated\PYZus{}feat\PYZus{}creator = CreateAggregatedFeatures(group\PYZus{}col=group\PYZus{}col, agg\PYZus{}cols=agg\PYZus{}cols)}
\end{Verbatim}
\end{tcolorbox}

    \begin{tcolorbox}[breakable, size=fbox, boxrule=1pt, pad at break*=1mm,colback=cellbackground, colframe=cellborder]
\prompt{In}{incolor}{88}{\boxspacing}
\begin{Verbatim}[commandchars=\\\{\}]
\PY{n}{cb\PYZus{}preprocessor} \PY{o}{=} \PY{n}{Pipeline}\PY{p}{(}\PY{p}{[}
    \PY{c+c1}{\PYZsh{}(\PYZsq{}derived\PYZus{}feat\PYZus{}creator\PYZsq{}, derived\PYZus{}feat\PYZus{}creator),}
    \PY{c+c1}{\PYZsh{}(\PYZsq{}aggregated\PYZus{}feat\PYZus{}creator\PYZsq{}, aggregated\PYZus{}feat\PYZus{}creator),}
    \PY{c+c1}{\PYZsh{}(\PYZsq{}split\PYZus{}census\PYZsq{},split\PYZus{}census),}
    \PY{p}{(}\PY{l+s+s1}{\PYZsq{}}\PY{l+s+s1}{date\PYZus{}feat\PYZus{}creator}\PY{l+s+s1}{\PYZsq{}}\PY{p}{,} \PY{n}{date\PYZus{}feat\PYZus{}creator}\PY{p}{)}\PY{p}{,}
    \PY{p}{(}\PY{l+s+s1}{\PYZsq{}}\PY{l+s+s1}{feature\PYZus{}dropper}\PY{l+s+s1}{\PYZsq{}}\PY{p}{,} \PY{n}{feature\PYZus{}dropper}\PY{p}{)}\PY{p}{,}
    \PY{p}{(}\PY{l+s+s1}{\PYZsq{}}\PY{l+s+s1}{year\PYZus{}feat\PYZus{}creator}\PY{l+s+s1}{\PYZsq{}}\PY{p}{,} \PY{n}{year\PYZus{}feat\PYZus{}creator}\PY{p}{)}\PY{p}{,}
    \PY{c+c1}{\PYZsh{}(\PYZsq{}impute0\PYZsq{},univariate\PYZus{}impute\PYZus{}pipe),}
    \PY{p}{(}\PY{l+s+s1}{\PYZsq{}}\PY{l+s+s1}{convert\PYZus{}to\PYZus{}cat}\PY{l+s+s1}{\PYZsq{}}\PY{p}{,} \PY{n}{convert\PYZus{}to\PYZus{}cat}\PY{p}{)}\PY{p}{,}
\PY{p}{]}\PY{p}{)}

\PY{n}{data\PYZus{}prep\PYZus{}pipe} \PY{o}{=} \PY{n}{cb\PYZus{}preprocessor}\PY{o}{.}\PY{n}{fit}\PY{p}{(}\PY{n}{X\PYZus{}prepared}\PY{p}{)}
\PY{n}{X\PYZus{}prepared} \PY{o}{=} \PY{n}{cb\PYZus{}preprocessor}\PY{o}{.}\PY{n}{transform}\PY{p}{(}\PY{n}{X\PYZus{}prepared}\PY{p}{)}
\PY{n}{X\PYZus{}prepared\PYZus{}val} \PY{o}{=} \PY{n}{cb\PYZus{}preprocessor}\PY{o}{.}\PY{n}{transform}\PY{p}{(}\PY{n}{X\PYZus{}prepared\PYZus{}val}\PY{p}{)}
\end{Verbatim}
\end{tcolorbox}

    \begin{tcolorbox}[breakable, size=fbox, boxrule=1pt, pad at break*=1mm,colback=cellbackground, colframe=cellborder]
\prompt{In}{incolor}{89}{\boxspacing}
\begin{Verbatim}[commandchars=\\\{\}]
\PY{n}{X\PYZus{}cb} \PY{o}{=} \PY{n}{X\PYZus{}prepared}\PY{o}{.}\PY{n}{copy}\PY{p}{(}\PY{p}{)}
\PY{n}{X\PYZus{}cb\PYZus{}val} \PY{o}{=} \PY{n}{X\PYZus{}prepared\PYZus{}val}\PY{o}{.}\PY{n}{copy}\PY{p}{(}\PY{p}{)}
\end{Verbatim}
\end{tcolorbox}

    \begin{tcolorbox}[breakable, size=fbox, boxrule=1pt, pad at break*=1mm,colback=cellbackground, colframe=cellborder]
\prompt{In}{incolor}{90}{\boxspacing}
\begin{Verbatim}[commandchars=\\\{\}]
\PY{k}{def} \PY{n+nf}{objective}\PY{p}{(}\PY{n}{trial}\PY{p}{,} \PY{n}{X}\PY{p}{,} \PY{n}{y}\PY{p}{)}\PY{p}{:}    
    \PY{n}{param\PYZus{}grid} \PY{o}{=} \PY{p}{\PYZob{}}
        \PY{c+c1}{\PYZsh{} Fixed Params}
        \PY{l+s+s2}{\PYZdq{}}\PY{l+s+s2}{eval\PYZus{}metric}\PY{l+s+s2}{\PYZdq{}}\PY{p}{:} \PY{l+s+s2}{\PYZdq{}}\PY{l+s+s2}{MAE}\PY{l+s+s2}{\PYZdq{}}\PY{p}{,}
        \PY{l+s+s2}{\PYZdq{}}\PY{l+s+s2}{n\PYZus{}estimators}\PY{l+s+s2}{\PYZdq{}}\PY{p}{:} \PY{l+m+mi}{10000}\PY{p}{,}
        \PY{l+s+s2}{\PYZdq{}}\PY{l+s+s2}{random\PYZus{}state}\PY{l+s+s2}{\PYZdq{}}\PY{p}{:} \PY{l+m+mi}{42}\PY{p}{,}
    
        \PY{c+c1}{\PYZsh{} Tuned Params}
        \PY{l+s+s2}{\PYZdq{}}\PY{l+s+s2}{learning\PYZus{}rate}\PY{l+s+s2}{\PYZdq{}}\PY{p}{:} \PY{n}{trial}\PY{o}{.}\PY{n}{suggest\PYZus{}loguniform}\PY{p}{(}\PY{l+s+s2}{\PYZdq{}}\PY{l+s+s2}{learning\PYZus{}rate}\PY{l+s+s2}{\PYZdq{}}\PY{p}{,} \PY{l+m+mf}{0.05}\PY{p}{,} \PY{l+m+mf}{0.3}\PY{p}{)}\PY{p}{,}
        \PY{l+s+s2}{\PYZdq{}}\PY{l+s+s2}{l2\PYZus{}leaf\PYZus{}reg}\PY{l+s+s2}{\PYZdq{}}\PY{p}{:} \PY{n}{trial}\PY{o}{.}\PY{n}{suggest\PYZus{}loguniform}\PY{p}{(}\PY{l+s+s2}{\PYZdq{}}\PY{l+s+s2}{l2\PYZus{}leaf\PYZus{}reg}\PY{l+s+s2}{\PYZdq{}}\PY{p}{,} \PY{l+m+mf}{1e\PYZhy{}2}\PY{p}{,} \PY{l+m+mf}{1e1}\PY{p}{)}\PY{p}{,}
        \PY{l+s+s2}{\PYZdq{}}\PY{l+s+s2}{colsample\PYZus{}bylevel}\PY{l+s+s2}{\PYZdq{}}\PY{p}{:} \PY{n}{trial}\PY{o}{.}\PY{n}{suggest\PYZus{}float}\PY{p}{(}\PY{l+s+s2}{\PYZdq{}}\PY{l+s+s2}{colsample\PYZus{}bylevel}\PY{l+s+s2}{\PYZdq{}}\PY{p}{,} \PY{l+m+mf}{0.01}\PY{p}{,} \PY{l+m+mf}{0.1}\PY{p}{)}\PY{p}{,}
        \PY{l+s+s2}{\PYZdq{}}\PY{l+s+s2}{depth}\PY{l+s+s2}{\PYZdq{}}\PY{p}{:} \PY{n}{trial}\PY{o}{.}\PY{n}{suggest\PYZus{}int}\PY{p}{(}\PY{l+s+s2}{\PYZdq{}}\PY{l+s+s2}{depth}\PY{l+s+s2}{\PYZdq{}}\PY{p}{,} \PY{l+m+mi}{1}\PY{p}{,} \PY{l+m+mi}{10}\PY{p}{)}\PY{p}{,}
        \PY{l+s+s2}{\PYZdq{}}\PY{l+s+s2}{boosting\PYZus{}type}\PY{l+s+s2}{\PYZdq{}}\PY{p}{:} \PY{n}{trial}\PY{o}{.}\PY{n}{suggest\PYZus{}categorical}\PY{p}{(}\PY{l+s+s2}{\PYZdq{}}\PY{l+s+s2}{boosting\PYZus{}type}\PY{l+s+s2}{\PYZdq{}}\PY{p}{,} \PY{p}{[}\PY{l+s+s2}{\PYZdq{}}\PY{l+s+s2}{Ordered}\PY{l+s+s2}{\PYZdq{}}\PY{p}{,} \PY{l+s+s2}{\PYZdq{}}\PY{l+s+s2}{Plain}\PY{l+s+s2}{\PYZdq{}}\PY{p}{]}\PY{p}{)}\PY{p}{,}
        \PY{l+s+s2}{\PYZdq{}}\PY{l+s+s2}{bootstrap\PYZus{}type}\PY{l+s+s2}{\PYZdq{}}\PY{p}{:} \PY{n}{trial}\PY{o}{.}\PY{n}{suggest\PYZus{}categorical}\PY{p}{(}\PY{l+s+s2}{\PYZdq{}}\PY{l+s+s2}{bootstrap\PYZus{}type}\PY{l+s+s2}{\PYZdq{}}\PY{p}{,} \PY{p}{[}\PY{l+s+s2}{\PYZdq{}}\PY{l+s+s2}{Bayesian}\PY{l+s+s2}{\PYZdq{}}\PY{p}{,} \PY{l+s+s2}{\PYZdq{}}\PY{l+s+s2}{Bernoulli}\PY{l+s+s2}{\PYZdq{}}\PY{p}{,} \PY{l+s+s2}{\PYZdq{}}\PY{l+s+s2}{MVS}\PY{l+s+s2}{\PYZdq{}}\PY{p}{]}\PY{p}{)}\PY{p}{,}
        \PY{l+s+s2}{\PYZdq{}}\PY{l+s+s2}{min\PYZus{}data\PYZus{}in\PYZus{}leaf}\PY{l+s+s2}{\PYZdq{}}\PY{p}{:} \PY{n}{trial}\PY{o}{.}\PY{n}{suggest\PYZus{}int}\PY{p}{(}\PY{l+s+s2}{\PYZdq{}}\PY{l+s+s2}{min\PYZus{}data\PYZus{}in\PYZus{}leaf}\PY{l+s+s2}{\PYZdq{}}\PY{p}{,} \PY{l+m+mi}{2}\PY{p}{,} \PY{l+m+mi}{20}\PY{p}{)}\PY{p}{,}
        \PY{l+s+s2}{\PYZdq{}}\PY{l+s+s2}{one\PYZus{}hot\PYZus{}max\PYZus{}size}\PY{l+s+s2}{\PYZdq{}}\PY{p}{:} \PY{n}{trial}\PY{o}{.}\PY{n}{suggest\PYZus{}int}\PY{p}{(}\PY{l+s+s2}{\PYZdq{}}\PY{l+s+s2}{one\PYZus{}hot\PYZus{}max\PYZus{}size}\PY{l+s+s2}{\PYZdq{}}\PY{p}{,} \PY{l+m+mi}{2}\PY{p}{,} \PY{l+m+mi}{20}\PY{p}{)}\PY{p}{,}  
    \PY{p}{\PYZcb{}}
    \PY{c+c1}{\PYZsh{} Conditional Hyper\PYZhy{}Parameters}
    \PY{k}{if} \PY{n}{param\PYZus{}grid}\PY{p}{[}\PY{l+s+s2}{\PYZdq{}}\PY{l+s+s2}{bootstrap\PYZus{}type}\PY{l+s+s2}{\PYZdq{}}\PY{p}{]} \PY{o}{==} \PY{l+s+s2}{\PYZdq{}}\PY{l+s+s2}{Bayesian}\PY{l+s+s2}{\PYZdq{}}\PY{p}{:}
        \PY{n}{param\PYZus{}grid}\PY{p}{[}\PY{l+s+s2}{\PYZdq{}}\PY{l+s+s2}{bagging\PYZus{}temperature}\PY{l+s+s2}{\PYZdq{}}\PY{p}{]} \PY{o}{=} \PY{n}{trial}\PY{o}{.}\PY{n}{suggest\PYZus{}float}\PY{p}{(}\PY{l+s+s2}{\PYZdq{}}\PY{l+s+s2}{bagging\PYZus{}temperature}\PY{l+s+s2}{\PYZdq{}}\PY{p}{,} \PY{l+m+mi}{0}\PY{p}{,} \PY{l+m+mi}{10}\PY{p}{)}
    \PY{k}{elif} \PY{n}{param\PYZus{}grid}\PY{p}{[}\PY{l+s+s2}{\PYZdq{}}\PY{l+s+s2}{bootstrap\PYZus{}type}\PY{l+s+s2}{\PYZdq{}}\PY{p}{]} \PY{o}{==} \PY{l+s+s2}{\PYZdq{}}\PY{l+s+s2}{Bernoulli}\PY{l+s+s2}{\PYZdq{}}\PY{p}{:}
        \PY{n}{param\PYZus{}grid}\PY{p}{[}\PY{l+s+s2}{\PYZdq{}}\PY{l+s+s2}{subsample}\PY{l+s+s2}{\PYZdq{}}\PY{p}{]} \PY{o}{=} \PY{n}{trial}\PY{o}{.}\PY{n}{suggest\PYZus{}float}\PY{p}{(}\PY{l+s+s2}{\PYZdq{}}\PY{l+s+s2}{subsample}\PY{l+s+s2}{\PYZdq{}}\PY{p}{,} \PY{l+m+mf}{0.1}\PY{p}{,} \PY{l+m+mi}{1}\PY{p}{)}
    
    \PY{n}{cv} \PY{o}{=} \PY{n}{KFold}\PY{p}{(}\PY{n}{n\PYZus{}splits}\PY{o}{=}\PY{l+m+mi}{3}\PY{p}{,} \PY{n}{shuffle}\PY{o}{=}\PY{k+kc}{True}\PY{p}{,} \PY{n}{random\PYZus{}state}\PY{o}{=}\PY{l+m+mi}{42}\PY{p}{)}

    \PY{n}{cv\PYZus{}scores} \PY{o}{=} \PY{n}{np}\PY{o}{.}\PY{n}{empty}\PY{p}{(}\PY{l+m+mi}{3}\PY{p}{)}
    \PY{k}{for} \PY{n}{idx}\PY{p}{,} \PY{p}{(}\PY{n}{train\PYZus{}idx}\PY{p}{,} \PY{n}{test\PYZus{}idx}\PY{p}{)} \PY{o+ow}{in} \PY{n+nb}{enumerate}\PY{p}{(}\PY{n}{cv}\PY{o}{.}\PY{n}{split}\PY{p}{(}\PY{n}{X}\PY{p}{,} \PY{n}{y}\PY{p}{)}\PY{p}{)}\PY{p}{:}
        \PY{n}{X\PYZus{}train}\PY{p}{,} \PY{n}{X\PYZus{}test} \PY{o}{=} \PY{n}{X}\PY{o}{.}\PY{n}{iloc}\PY{p}{[}\PY{n}{train\PYZus{}idx}\PY{p}{]}\PY{p}{,} \PY{n}{X}\PY{o}{.}\PY{n}{iloc}\PY{p}{[}\PY{n}{test\PYZus{}idx}\PY{p}{]}
        \PY{n}{y\PYZus{}train}\PY{p}{,} \PY{n}{y\PYZus{}test} \PY{o}{=} \PY{n}{y}\PY{p}{[}\PY{n}{train\PYZus{}idx}\PY{p}{]}\PY{p}{,} \PY{n}{y}\PY{p}{[}\PY{n}{test\PYZus{}idx}\PY{p}{]}

        \PY{n}{model} \PY{o}{=} \PY{n}{cb}\PY{o}{.}\PY{n}{CatBoostRegressor}\PY{p}{(}\PY{o}{*}\PY{o}{*}\PY{n}{param\PYZus{}grid}\PY{p}{)}
        \PY{n}{model}\PY{o}{.}\PY{n}{fit}\PY{p}{(}
            \PY{n}{X\PYZus{}train}\PY{p}{,}
            \PY{n}{y\PYZus{}train}\PY{p}{,}
            \PY{n}{eval\PYZus{}set}\PY{o}{=}\PY{p}{[}\PY{p}{(}\PY{n}{X\PYZus{}test}\PY{p}{,} \PY{n}{y\PYZus{}test}\PY{p}{)}\PY{p}{]}\PY{p}{,}
            \PY{n}{cat\PYZus{}features}\PY{o}{=}\PY{n}{cat\PYZus{}vars}\PY{p}{,}
            \PY{n}{early\PYZus{}stopping\PYZus{}rounds}\PY{o}{=}\PY{l+m+mi}{20}\PY{p}{,}
            \PY{n}{verbose}\PY{o}{=}\PY{k+kc}{False}
        \PY{p}{)}
        \PY{n}{preds} \PY{o}{=} \PY{n}{model}\PY{o}{.}\PY{n}{predict}\PY{p}{(}\PY{n}{X\PYZus{}test}\PY{p}{)}
        \PY{n}{cv\PYZus{}scores}\PY{p}{[}\PY{n}{idx}\PY{p}{]} \PY{o}{=} \PY{n}{mean\PYZus{}absolute\PYZus{}error}\PY{p}{(}\PY{n}{y\PYZus{}test}\PY{p}{,} \PY{n}{preds}\PY{p}{)}

    \PY{k}{return} \PY{n}{np}\PY{o}{.}\PY{n}{mean}\PY{p}{(}\PY{n}{cv\PYZus{}scores}\PY{p}{)}
\end{Verbatim}
\end{tcolorbox}

    \begin{tcolorbox}[breakable, size=fbox, boxrule=1pt, pad at break*=1mm,colback=cellbackground, colframe=cellborder]
\prompt{In}{incolor}{91}{\boxspacing}
\begin{Verbatim}[commandchars=\\\{\}]
\PY{c+c1}{\PYZsh{} Similar to Hyperopt \PYZhy{} this code creates an experiment using the objective function and parameter grid above}
\PY{c+c1}{\PYZsh{}study = optuna.create\PYZus{}study(direction=\PYZdq{}minimize\PYZdq{}, study\PYZus{}name=\PYZdq{}CatBoost Regressor\PYZdq{})}
\PY{c+c1}{\PYZsh{}func = lambda trial: objective(trial, X\PYZus{}prepared, y\PYZus{}train.to\PYZus{}numpy())}
\PY{c+c1}{\PYZsh{}study.optimize(func, n\PYZus{}trials=400)}
\end{Verbatim}
\end{tcolorbox}

    \begin{tcolorbox}[breakable, size=fbox, boxrule=1pt, pad at break*=1mm,colback=cellbackground, colframe=cellborder]
\prompt{In}{incolor}{92}{\boxspacing}
\begin{Verbatim}[commandchars=\\\{\}]
\PY{c+c1}{\PYZsh{}print(f\PYZdq{}\PYZbs{}tBest value (mae): \PYZob{}study.best\PYZus{}value:.5f\PYZcb{}\PYZdq{})}
\PY{c+c1}{\PYZsh{}print(f\PYZdq{}\PYZbs{}tBest params:\PYZdq{})}

\PY{c+c1}{\PYZsh{}for key, value in study.best\PYZus{}params.items():}
    \PY{c+c1}{\PYZsh{}print(f\PYZdq{}\PYZbs{}t\PYZbs{}t\PYZob{}key\PYZcb{}: \PYZob{}value\PYZcb{}\PYZdq{})}
\end{Verbatim}
\end{tcolorbox}

    \begin{tcolorbox}[breakable, size=fbox, boxrule=1pt, pad at break*=1mm,colback=cellbackground, colframe=cellborder]
\prompt{In}{incolor}{93}{\boxspacing}
\begin{Verbatim}[commandchars=\\\{\}]
\PY{n}{best\PYZus{}params} \PY{o}{=} \PY{p}{\PYZob{}}
    \PY{l+s+s1}{\PYZsq{}}\PY{l+s+s1}{learning\PYZus{}rate}\PY{l+s+s1}{\PYZsq{}}\PY{p}{:} \PY{l+m+mf}{0.03}\PY{p}{,}
    \PY{l+s+s1}{\PYZsq{}}\PY{l+s+s1}{l2\PYZus{}leaf\PYZus{}reg}\PY{l+s+s1}{\PYZsq{}}\PY{p}{:} \PY{l+m+mi}{3}\PY{p}{,}
    \PY{l+s+s1}{\PYZsq{}}\PY{l+s+s1}{depth}\PY{l+s+s1}{\PYZsq{}}\PY{p}{:} \PY{l+m+mi}{6}\PY{p}{,}
    \PY{l+s+s1}{\PYZsq{}}\PY{l+s+s1}{n\PYZus{}estimators}\PY{l+s+s1}{\PYZsq{}}\PY{p}{:} \PY{l+m+mi}{900}\PY{p}{,}
    \PY{l+s+s1}{\PYZsq{}}\PY{l+s+s1}{random\PYZus{}state}\PY{l+s+s1}{\PYZsq{}}\PY{p}{:} \PY{l+m+mi}{42}\PY{p}{,}
    \PY{l+s+s1}{\PYZsq{}}\PY{l+s+s1}{eval\PYZus{}metric}\PY{l+s+s1}{\PYZsq{}}\PY{p}{:} \PY{l+s+s2}{\PYZdq{}}\PY{l+s+s2}{MAE}\PY{l+s+s2}{\PYZdq{}}\PY{p}{,}
    \PY{l+s+s1}{\PYZsq{}}\PY{l+s+s1}{loss\PYZus{}function}\PY{l+s+s1}{\PYZsq{}}\PY{p}{:} \PY{l+s+s1}{\PYZsq{}}\PY{l+s+s1}{MAE}\PY{l+s+s1}{\PYZsq{}}\PY{p}{,}
\PY{p}{\PYZcb{}}

\PY{n}{fit\PYZus{}params}\PY{o}{=}\PY{p}{\PYZob{}}
    \PY{l+s+s1}{\PYZsq{}}\PY{l+s+s1}{cat\PYZus{}features}\PY{l+s+s1}{\PYZsq{}}\PY{p}{:} \PY{n}{cat\PYZus{}vars}\PY{p}{,}
    \PY{l+s+s1}{\PYZsq{}}\PY{l+s+s1}{verbose}\PY{l+s+s1}{\PYZsq{}}\PY{p}{:} \PY{k+kc}{False}\PY{p}{,}
\PY{p}{\PYZcb{}}
\end{Verbatim}
\end{tcolorbox}

    \begin{tcolorbox}[breakable, size=fbox, boxrule=1pt, pad at break*=1mm,colback=cellbackground, colframe=cellborder]
\prompt{In}{incolor}{94}{\boxspacing}
\begin{Verbatim}[commandchars=\\\{\}]
\PY{o}{\PYZpc{}\PYZpc{}time}
\PY{n}{cb\PYZus{}base} \PY{o}{=} \PY{n}{cb}\PY{o}{.}\PY{n}{CatBoostRegressor}\PY{p}{(}\PY{o}{*}\PY{o}{*}\PY{n}{best\PYZus{}params}\PY{p}{)}
\PY{n}{cb\PYZus{}base}\PY{o}{.}\PY{n}{fit}\PY{p}{(}\PY{n}{X\PYZus{}cb}\PY{p}{,} \PY{n}{y\PYZus{}train}\PY{p}{,} \PY{o}{*}\PY{o}{*}\PY{n}{fit\PYZus{}params}\PY{p}{)}
\end{Verbatim}
\end{tcolorbox}

    \begin{Verbatim}[commandchars=\\\{\}]
CPU times: total: 18min 58s
Wall time: 3min 24s
    \end{Verbatim}

            \begin{tcolorbox}[breakable, size=fbox, boxrule=.5pt, pad at break*=1mm, opacityfill=0]
\prompt{Out}{outcolor}{94}{\boxspacing}
\begin{Verbatim}[commandchars=\\\{\}]
<catboost.core.CatBoostRegressor at 0x23c6c0b7670>
\end{Verbatim}
\end{tcolorbox}
        
    \begin{tcolorbox}[breakable, size=fbox, boxrule=1pt, pad at break*=1mm,colback=cellbackground, colframe=cellborder]
\prompt{In}{incolor}{95}{\boxspacing}
\begin{Verbatim}[commandchars=\\\{\}]
\PY{o}{\PYZpc{}\PYZpc{}time}
\PY{n}{utils}\PY{o}{.}\PY{n}{get\PYZus{}eval\PYZus{}metrics}\PY{p}{(}\PY{p}{[}\PY{n}{cb\PYZus{}base}\PY{p}{]}\PY{p}{,} \PY{n}{X\PYZus{}cb\PYZus{}val}\PY{p}{,} \PY{n}{y\PYZus{}val}\PY{p}{)}
\end{Verbatim}
\end{tcolorbox}

    \begin{Verbatim}[commandchars=\\\{\}]
Model: <catboost.core.CatBoostRegressor object at 0x0000023C6C0B7670>
MAE: 0.049266007404430386, RMSE: 0.07530486260261454
CPU times: total: 906 ms
Wall time: 300 ms
    \end{Verbatim}

            \begin{tcolorbox}[breakable, size=fbox, boxrule=.5pt, pad at break*=1mm, opacityfill=0]
\prompt{Out}{outcolor}{95}{\boxspacing}
\begin{Verbatim}[commandchars=\\\{\}]
0.049266007404430386
\end{Verbatim}
\end{tcolorbox}
        
    \begin{tcolorbox}[breakable, size=fbox, boxrule=1pt, pad at break*=1mm,colback=cellbackground, colframe=cellborder]
\prompt{In}{incolor}{96}{\boxspacing}
\begin{Verbatim}[commandchars=\\\{\}]
\PY{o}{\PYZpc{}\PYZpc{}time}
\PY{c+c1}{\PYZsh{}get\PYZus{}cross\PYZus{}val\PYZus{}scores([cb\PYZus{}base], X\PYZus{}cb, y\PYZus{}train, cv=3, fit\PYZus{}params=fit\PYZus{}params)}
\end{Verbatim}
\end{tcolorbox}

    \begin{Verbatim}[commandchars=\\\{\}]
CPU times: total: 0 ns
Wall time: 0 ns
    \end{Verbatim}

    \begin{tcolorbox}[breakable, size=fbox, boxrule=1pt, pad at break*=1mm,colback=cellbackground, colframe=cellborder]
\prompt{In}{incolor}{97}{\boxspacing}
\begin{Verbatim}[commandchars=\\\{\}]
\PY{n}{result} \PY{o}{=} \PY{n}{utils}\PY{o}{.}\PY{n}{get\PYZus{}eval\PYZus{}metrics}\PY{p}{(}\PY{p}{[}\PY{n}{cb\PYZus{}base}\PY{p}{]}\PY{p}{,} \PY{n}{X\PYZus{}cb\PYZus{}val}\PY{p}{,} \PY{n}{y\PYZus{}val}\PY{p}{)}
\PY{n}{results}\PY{p}{[}\PY{l+s+s1}{\PYZsq{}}\PY{l+s+s1}{CB}\PY{l+s+s1}{\PYZsq{}}\PY{p}{]} \PY{o}{=} \PY{n}{result}
\end{Verbatim}
\end{tcolorbox}

    \begin{Verbatim}[commandchars=\\\{\}]
Model: <catboost.core.CatBoostRegressor object at 0x0000023C6C0B7670>
MAE: 0.049266007404430386, RMSE: 0.07530486260261454
    \end{Verbatim}

    \hypertarget{catboost-with-uncertainty}{%
\subsection{CatBoost with uncertainty}\label{catboost-with-uncertainty}}

    \begin{tcolorbox}[breakable, size=fbox, boxrule=1pt, pad at break*=1mm,colback=cellbackground, colframe=cellborder]
\prompt{In}{incolor}{98}{\boxspacing}
\begin{Verbatim}[commandchars=\\\{\}]
\PY{n}{best\PYZus{}params} \PY{o}{=} \PY{p}{\PYZob{}}
    \PY{l+s+s1}{\PYZsq{}}\PY{l+s+s1}{learning\PYZus{}rate}\PY{l+s+s1}{\PYZsq{}}\PY{p}{:} \PY{l+m+mf}{0.03}\PY{p}{,}
    \PY{l+s+s1}{\PYZsq{}}\PY{l+s+s1}{l2\PYZus{}leaf\PYZus{}reg}\PY{l+s+s1}{\PYZsq{}}\PY{p}{:} \PY{l+m+mi}{3}\PY{p}{,}
    \PY{l+s+s1}{\PYZsq{}}\PY{l+s+s1}{depth}\PY{l+s+s1}{\PYZsq{}}\PY{p}{:} \PY{l+m+mi}{6}\PY{p}{,}
    \PY{l+s+s1}{\PYZsq{}}\PY{l+s+s1}{n\PYZus{}estimators}\PY{l+s+s1}{\PYZsq{}}\PY{p}{:} \PY{l+m+mi}{900}\PY{p}{,}
    \PY{l+s+s1}{\PYZsq{}}\PY{l+s+s1}{random\PYZus{}state}\PY{l+s+s1}{\PYZsq{}}\PY{p}{:} \PY{l+m+mi}{42}\PY{p}{,}
    \PY{l+s+s1}{\PYZsq{}}\PY{l+s+s1}{eval\PYZus{}metric}\PY{l+s+s1}{\PYZsq{}}\PY{p}{:} \PY{l+s+s2}{\PYZdq{}}\PY{l+s+s2}{RMSEWithUncertainty}\PY{l+s+s2}{\PYZdq{}}\PY{p}{,}
    \PY{l+s+s1}{\PYZsq{}}\PY{l+s+s1}{loss\PYZus{}function}\PY{l+s+s1}{\PYZsq{}}\PY{p}{:} \PY{l+s+s1}{\PYZsq{}}\PY{l+s+s1}{RMSEWithUncertainty}\PY{l+s+s1}{\PYZsq{}}\PY{p}{,}
    \PY{l+s+s1}{\PYZsq{}}\PY{l+s+s1}{posterior\PYZus{}sampling}\PY{l+s+s1}{\PYZsq{}}\PY{p}{:}\PY{k+kc}{True}
\PY{p}{\PYZcb{}}

\PY{n}{fit\PYZus{}params}\PY{o}{=}\PY{p}{\PYZob{}}
    \PY{l+s+s1}{\PYZsq{}}\PY{l+s+s1}{cat\PYZus{}features}\PY{l+s+s1}{\PYZsq{}}\PY{p}{:} \PY{n}{cat\PYZus{}vars}\PY{p}{,}
    \PY{l+s+s1}{\PYZsq{}}\PY{l+s+s1}{verbose}\PY{l+s+s1}{\PYZsq{}}\PY{p}{:} \PY{k+kc}{False}\PY{p}{,}
\PY{p}{\PYZcb{}}
\end{Verbatim}
\end{tcolorbox}

    \begin{tcolorbox}[breakable, size=fbox, boxrule=1pt, pad at break*=1mm,colback=cellbackground, colframe=cellborder]
\prompt{In}{incolor}{99}{\boxspacing}
\begin{Verbatim}[commandchars=\\\{\}]
\PY{o}{\PYZpc{}\PYZpc{}time}
\PY{n}{model} \PY{o}{=} \PY{n}{cb}\PY{o}{.}\PY{n}{CatBoostRegressor}\PY{p}{(}\PY{o}{*}\PY{o}{*}\PY{n}{best\PYZus{}params}\PY{p}{)}
\PY{n}{model}\PY{o}{.}\PY{n}{fit}\PY{p}{(}\PY{n}{X\PYZus{}cb}\PY{p}{,} \PY{n}{y\PYZus{}train}\PY{p}{,}\PY{o}{*}\PY{o}{*}\PY{n}{fit\PYZus{}params}\PY{p}{)}
\PY{n}{preds} \PY{o}{=} \PY{n}{model}\PY{o}{.}\PY{n}{virtual\PYZus{}ensembles\PYZus{}predict}\PY{p}{(}\PY{n}{X\PYZus{}cb}\PY{p}{,} \PY{n}{prediction\PYZus{}type}\PY{o}{=}\PY{l+s+s1}{\PYZsq{}}\PY{l+s+s1}{TotalUncertainty}\PY{l+s+s1}{\PYZsq{}}\PY{p}{,} 
                                        \PY{n}{virtual\PYZus{}ensembles\PYZus{}count}\PY{o}{=}\PY{l+m+mi}{10}\PY{p}{)}
\PY{n}{mean\PYZus{}preds} \PY{o}{=} \PY{n}{preds}\PY{p}{[}\PY{p}{:}\PY{p}{,}\PY{l+m+mi}{0}\PY{p}{]} \PY{c+c1}{\PYZsh{} mean values predicted by a virtual ensemble}
\PY{n}{knowledge} \PY{o}{=} \PY{n}{preds}\PY{p}{[}\PY{p}{:}\PY{p}{,}\PY{l+m+mi}{1}\PY{p}{]} \PY{c+c1}{\PYZsh{} knowledge uncertainty predicted by a virtual ensemble}
\PY{n}{data} \PY{o}{=} \PY{n}{preds}\PY{p}{[}\PY{p}{:}\PY{p}{,}\PY{l+m+mi}{2}\PY{p}{]} \PY{c+c1}{\PYZsh{} average estimated data uncertainty}
\end{Verbatim}
\end{tcolorbox}

    \begin{Verbatim}[commandchars=\\\{\}]
CPU times: total: 28min 7s
Wall time: 4min 40s
    \end{Verbatim}

    \begin{tcolorbox}[breakable, size=fbox, boxrule=1pt, pad at break*=1mm,colback=cellbackground, colframe=cellborder]
\prompt{In}{incolor}{100}{\boxspacing}
\begin{Verbatim}[commandchars=\\\{\}]
\PY{n}{mean\PYZus{}preds} \PY{o}{=} \PY{n}{pd}\PY{o}{.}\PY{n}{Series}\PY{p}{(}\PY{n}{mean\PYZus{}preds}\PY{p}{,}\PY{n}{y\PYZus{}train}\PY{o}{.}\PY{n}{index}\PY{p}{)}
\PY{n}{knowledge} \PY{o}{=} \PY{n}{pd}\PY{o}{.}\PY{n}{Series}\PY{p}{(}\PY{n}{knowledge}\PY{p}{,}\PY{n}{y\PYZus{}train}\PY{o}{.}\PY{n}{index}\PY{p}{)} \PY{c+c1}{\PYZsh{}knowledge uncertainty}
\PY{n}{data} \PY{o}{=} \PY{n}{pd}\PY{o}{.}\PY{n}{Series}\PY{p}{(}\PY{n}{data}\PY{p}{,}\PY{n}{y\PYZus{}train}\PY{o}{.}\PY{n}{index}\PY{p}{)}  \PY{c+c1}{\PYZsh{}data uncertainty}

\PY{n}{df\PYZus{}preds} \PY{o}{=} \PY{n}{pd}\PY{o}{.}\PY{n}{concat}\PY{p}{(}\PY{p}{[}\PY{n}{mean\PYZus{}preds}\PY{p}{,}\PY{n}{knowledge}\PY{p}{,}\PY{n}{data}\PY{p}{]}\PY{p}{,} \PY{n}{axis}\PY{o}{=}\PY{l+m+mi}{1}\PY{p}{)}
\PY{n}{df\PYZus{}preds}
\end{Verbatim}
\end{tcolorbox}

            \begin{tcolorbox}[breakable, size=fbox, boxrule=.5pt, pad at break*=1mm, opacityfill=0]
\prompt{Out}{outcolor}{100}{\boxspacing}
\begin{Verbatim}[commandchars=\\\{\}]
               0             1         2
142446  0.002816  1.437083e-08  0.001619
32891   0.004733  9.159732e-08  0.006324
38805   0.020817  6.004848e-08  0.004715
134090 -0.000096  3.318650e-07  0.004514
48284   0.016978  1.004755e-06  0.003065
{\ldots}          {\ldots}           {\ldots}       {\ldots}
126165  0.009444  4.609577e-08  0.003952
137199  0.006842  1.434071e-06  0.005430
118642 -0.000525  2.244464e-06  0.002696
150944  0.003664  2.403237e-08  0.003616
139561  0.021562  7.957773e-07  0.009246

[132102 rows x 3 columns]
\end{Verbatim}
\end{tcolorbox}
        
    Data uncertainty arises due to the inherent complexity of the data, such
as additive noise or overlapping classes. In these cases, the model
knows that the input has attributes of multiple classes or that the
target is noisy. Importantly, data uncertainty cannot be reduced by
collecting more training data.

Knowledge uncertainty arises when the model is given an input from a
region that is either sparsely covered by the training data or far from
the training data. In these cases, the model knows very little about
this region and is likely to make a mistake. Unlike data uncertainty,
knowledge uncertainty can be reduced by collecting more training data
from a poorly understood region.

    \hypertarget{explainability}{%
\section{9 - EXPLAINABILITY}\label{explainability}}

    \begin{tcolorbox}[breakable, size=fbox, boxrule=1pt, pad at break*=1mm,colback=cellbackground, colframe=cellborder]
\prompt{In}{incolor}{108}{\boxspacing}
\begin{Verbatim}[commandchars=\\\{\}]
\PY{n}{results\PYZus{}list} \PY{o}{=} \PY{n}{results}\PY{o}{.}\PY{n}{items}\PY{p}{(}\PY{p}{)}
\PY{n}{x}\PY{p}{,} \PY{n}{y} \PY{o}{=} \PY{n+nb}{zip}\PY{p}{(}\PY{o}{*}\PY{n}{results\PYZus{}list}\PY{p}{)} 

\PY{n}{plt}\PY{o}{.}\PY{n}{plot}\PY{p}{(}\PY{n}{x}\PY{p}{,} \PY{n}{y}\PY{p}{)}
\PY{n}{plt}\PY{o}{.}\PY{n}{show}\PY{p}{(}\PY{p}{)}
\end{Verbatim}
\end{tcolorbox}

    \begin{center}
    \adjustimage{max size={0.9\linewidth}{0.9\paperheight}}{output_133_0.png}
    \end{center}
    { \hspace*{\fill} \\}
    
    \hypertarget{model-interpretability}{%
\subsection{Model Interpretability}\label{model-interpretability}}

An important aspect of machine learning model building is to be able to
understand and evaluate the models \textbf{beyond} simple metrics on
their test set performance to be able to trust the model. \textbf{This
interpretation is extremely cruicial for complex models such as gradient
boosting machines which usually perform better than easy to explain
models such as Linear Regression, and thus require greater care when
being used.}

Interpretability can include answering questions such as:

\begin{enumerate}
\def\labelenumi{\arabic{enumi}.}
\tightlist
\item
  Which variables are most important to my model \emph{in general}?
\item
  What is the nature of the relationship between the predictors and the
  target?
\item
  Are there significant interaction effects?
\item
  For a specific prediction, what were the most important reasons
  leading to that prediction?
\end{enumerate}

Explore CatBoost that is the best model:

    \hypertarget{global-feature-importance}{%
\subsection{1. Global Feature
Importance:}\label{global-feature-importance}}

Does the model make predictions based on reasonable features?

\begin{verbatim}
xgb_base.get_booster().get_score(importance_type='gain')
lgbm_base.feature_importances_
cb_base.get_feature_importance()
\end{verbatim}

    \begin{tcolorbox}[breakable, size=fbox, boxrule=1pt, pad at break*=1mm,colback=cellbackground, colframe=cellborder]
\prompt{In}{incolor}{109}{\boxspacing}
\begin{Verbatim}[commandchars=\\\{\}]
\PY{o}{\PYZpc{}\PYZpc{}time}

\PY{n}{cb\PYZus{}importances} \PY{o}{=} \PY{n}{cb\PYZus{}base}\PY{o}{.}\PY{n}{get\PYZus{}feature\PYZus{}importance}\PY{p}{(}\PY{p}{)}
\PY{n}{cb\PYZus{}importances} \PY{o}{=} \PY{n}{pd}\PY{o}{.}\PY{n}{DataFrame}\PY{p}{(}\PY{n+nb}{sorted}\PY{p}{(}\PY{n+nb}{zip}\PY{p}{(}\PY{n}{cb\PYZus{}importances}\PY{p}{,} \PY{n}{X\PYZus{}cb}\PY{o}{.}\PY{n}{columns}\PY{p}{)}\PY{p}{)}\PY{p}{,} \PY{n}{columns}\PY{o}{=}\PY{p}{[}\PY{l+s+s1}{\PYZsq{}}\PY{l+s+s1}{Value}\PY{l+s+s1}{\PYZsq{}}\PY{p}{,}\PY{l+s+s1}{\PYZsq{}}\PY{l+s+s1}{Feature}\PY{l+s+s1}{\PYZsq{}}\PY{p}{]}\PY{p}{)}

\PY{n}{cb\PYZus{}importances} \PY{o}{=} \PY{n}{cb\PYZus{}importances}\PY{o}{.}\PY{n}{sort\PYZus{}values}\PY{p}{(}\PY{n}{by}\PY{o}{=}\PY{l+s+s1}{\PYZsq{}}\PY{l+s+s1}{Value}\PY{l+s+s1}{\PYZsq{}}\PY{p}{,} \PY{n}{ascending}\PY{o}{=}\PY{k+kc}{False}\PY{p}{)}\PY{p}{[}\PY{p}{:}\PY{l+m+mi}{20}\PY{p}{]}

\PY{n}{plt}\PY{o}{.}\PY{n}{figure}\PY{p}{(}\PY{n}{figsize}\PY{o}{=}\PY{p}{(}\PY{l+m+mi}{10}\PY{p}{,} \PY{l+m+mi}{10}\PY{p}{)}\PY{p}{)}
\PY{n}{sns}\PY{o}{.}\PY{n}{barplot}\PY{p}{(}\PY{n}{x}\PY{o}{=}\PY{l+s+s2}{\PYZdq{}}\PY{l+s+s2}{Value}\PY{l+s+s2}{\PYZdq{}}\PY{p}{,} \PY{n}{y}\PY{o}{=}\PY{l+s+s2}{\PYZdq{}}\PY{l+s+s2}{Feature}\PY{l+s+s2}{\PYZdq{}}\PY{p}{,} \PY{n}{data}\PY{o}{=}\PY{n}{cb\PYZus{}importances}\PY{o}{.}\PY{n}{sort\PYZus{}values}\PY{p}{(}\PY{n}{by}\PY{o}{=}\PY{l+s+s2}{\PYZdq{}}\PY{l+s+s2}{Value}\PY{l+s+s2}{\PYZdq{}}\PY{p}{,} \PY{n}{ascending}\PY{o}{=}\PY{k+kc}{False}\PY{p}{)}\PY{p}{)}
\PY{n}{plt}\PY{o}{.}\PY{n}{title}\PY{p}{(}\PY{l+s+s1}{\PYZsq{}}\PY{l+s+s1}{CatBoost Global Feature Importances}\PY{l+s+s1}{\PYZsq{}}\PY{p}{)}
\PY{n}{plt}\PY{o}{.}\PY{n}{tight\PYZus{}layout}\PY{p}{(}\PY{p}{)}
\PY{n}{plt}\PY{o}{.}\PY{n}{show}\PY{p}{(}\PY{p}{)}
\end{Verbatim}
\end{tcolorbox}

    \begin{center}
    \adjustimage{max size={0.9\linewidth}{0.9\paperheight}}{output_136_0.png}
    \end{center}
    { \hspace*{\fill} \\}
    
    \begin{Verbatim}[commandchars=\\\{\}]
CPU times: total: 219 ms
Wall time: 216 ms
    \end{Verbatim}

    \hypertarget{permutation-importance}{%
\subsection{2. Permutation importance}\label{permutation-importance}}

    \begin{tcolorbox}[breakable, size=fbox, boxrule=1pt, pad at break*=1mm,colback=cellbackground, colframe=cellborder]
\prompt{In}{incolor}{110}{\boxspacing}
\begin{Verbatim}[commandchars=\\\{\}]
\PY{o}{\PYZpc{}\PYZpc{}time}

\PY{k+kn}{from} \PY{n+nn}{sklearn}\PY{n+nn}{.}\PY{n+nn}{inspection} \PY{k+kn}{import} \PY{n}{permutation\PYZus{}importance}
\PY{n}{result} \PY{o}{=} \PY{n}{permutation\PYZus{}importance}\PY{p}{(}\PY{n}{cb\PYZus{}base}\PY{p}{,} \PY{n}{X\PYZus{}cb\PYZus{}val}\PY{p}{,} \PY{n}{y\PYZus{}val}\PY{p}{,} \PY{n}{n\PYZus{}repeats}\PY{o}{=}\PY{l+m+mi}{10}\PY{p}{,}\PY{n}{random\PYZus{}state}\PY{o}{=}\PY{l+m+mi}{42}\PY{p}{)}
\end{Verbatim}
\end{tcolorbox}

    \begin{Verbatim}[commandchars=\\\{\}]
CPU times: total: 7min
Wall time: 1min 49s
    \end{Verbatim}

    \begin{tcolorbox}[breakable, size=fbox, boxrule=1pt, pad at break*=1mm,colback=cellbackground, colframe=cellborder]
\prompt{In}{incolor}{111}{\boxspacing}
\begin{Verbatim}[commandchars=\\\{\}]
\PY{o}{\PYZpc{}\PYZpc{}time}
\PY{n}{perm\PYZus{}sorted\PYZus{}idx} \PY{o}{=} \PY{n}{result}\PY{o}{.}\PY{n}{importances\PYZus{}mean}\PY{o}{.}\PY{n}{argsort}\PY{p}{(}\PY{p}{)}

\PY{n}{tree\PYZus{}importance\PYZus{}sorted\PYZus{}idx} \PY{o}{=} \PY{n}{np}\PY{o}{.}\PY{n}{argsort}\PY{p}{(}\PY{n}{cb\PYZus{}base}\PY{o}{.}\PY{n}{feature\PYZus{}importances\PYZus{}}\PY{p}{)}
\PY{n}{tree\PYZus{}indices} \PY{o}{=} \PY{n}{np}\PY{o}{.}\PY{n}{arange}\PY{p}{(}\PY{l+m+mi}{0}\PY{p}{,} \PY{n+nb}{len}\PY{p}{(}\PY{n}{cb\PYZus{}base}\PY{o}{.}\PY{n}{feature\PYZus{}importances\PYZus{}}\PY{p}{)}\PY{p}{)} \PY{o}{+} \PY{l+m+mf}{0.5}

\PY{n}{fig}\PY{p}{,} \PY{p}{(}\PY{n}{ax1}\PY{p}{,} \PY{n}{ax2}\PY{p}{)} \PY{o}{=} \PY{n}{plt}\PY{o}{.}\PY{n}{subplots}\PY{p}{(}\PY{l+m+mi}{1}\PY{p}{,} \PY{l+m+mi}{2}\PY{p}{,} \PY{n}{figsize}\PY{o}{=}\PY{p}{(}\PY{l+m+mi}{24}\PY{p}{,} \PY{l+m+mi}{24}\PY{p}{)}\PY{p}{)}
\PY{n}{ax1}\PY{o}{.}\PY{n}{barh}\PY{p}{(}\PY{n}{tree\PYZus{}indices}\PY{p}{,} \PY{n}{cb\PYZus{}base}\PY{o}{.}\PY{n}{feature\PYZus{}importances\PYZus{}}\PY{p}{[}\PY{n}{tree\PYZus{}importance\PYZus{}sorted\PYZus{}idx}\PY{p}{]}\PY{p}{,} \PY{n}{height}\PY{o}{=}\PY{l+m+mf}{1.5}\PY{p}{)}
\PY{n}{ax1}\PY{o}{.}\PY{n}{set\PYZus{}yticks}\PY{p}{(}\PY{n}{tree\PYZus{}indices}\PY{p}{)}
\PY{n}{ax1}\PY{o}{.}\PY{n}{set\PYZus{}yticklabels}\PY{p}{(}\PY{n}{X\PYZus{}cb\PYZus{}val}\PY{o}{.}\PY{n}{columns}\PY{p}{[}\PY{n}{tree\PYZus{}importance\PYZus{}sorted\PYZus{}idx}\PY{p}{]}\PY{p}{)}
\PY{n}{ax1}\PY{o}{.}\PY{n}{set\PYZus{}ylim}\PY{p}{(}\PY{p}{(}\PY{l+m+mi}{0}\PY{p}{,} \PY{n+nb}{len}\PY{p}{(}\PY{n}{cb\PYZus{}base}\PY{o}{.}\PY{n}{feature\PYZus{}importances\PYZus{}}\PY{p}{)}\PY{p}{)}\PY{p}{)}
\PY{n}{ax2}\PY{o}{.}\PY{n}{boxplot}\PY{p}{(}
    \PY{n}{result}\PY{o}{.}\PY{n}{importances}\PY{p}{[}\PY{n}{perm\PYZus{}sorted\PYZus{}idx}\PY{p}{]}\PY{o}{.}\PY{n}{T}\PY{p}{,}
    \PY{n}{vert}\PY{o}{=}\PY{k+kc}{False}\PY{p}{,}
    \PY{n}{labels}\PY{o}{=}\PY{n}{X\PYZus{}cb\PYZus{}val}\PY{o}{.}\PY{n}{columns}\PY{p}{[}\PY{n}{perm\PYZus{}sorted\PYZus{}idx}\PY{p}{]}\PY{p}{,}
\PY{p}{)}
\PY{n}{fig}\PY{o}{.}\PY{n}{tight\PYZus{}layout}\PY{p}{(}\PY{p}{)}
\PY{n}{plt}\PY{o}{.}\PY{n}{show}\PY{p}{(}\PY{p}{)}
\end{Verbatim}
\end{tcolorbox}

    \begin{center}
    \adjustimage{max size={0.9\linewidth}{0.9\paperheight}}{output_139_0.png}
    \end{center}
    { \hspace*{\fill} \\}
    
    \begin{Verbatim}[commandchars=\\\{\}]
CPU times: total: 1.86 s
Wall time: 1.94 s
    \end{Verbatim}

    The permutation importance plot shows that permuting a feature has
impact on MAE by at most 0.07. The permutation importance is calculated
on the training set to show how much the model relies on each feature
during training.

    \begin{tcolorbox}[breakable, size=fbox, boxrule=1pt, pad at break*=1mm,colback=cellbackground, colframe=cellborder]
\prompt{In}{incolor}{112}{\boxspacing}
\begin{Verbatim}[commandchars=\\\{\}]
\PY{k+kn}{from} \PY{n+nn}{scipy}\PY{n+nn}{.}\PY{n+nn}{stats} \PY{k+kn}{import} \PY{n}{spearmanr}
\PY{k+kn}{from} \PY{n+nn}{scipy}\PY{n+nn}{.}\PY{n+nn}{cluster} \PY{k+kn}{import} \PY{n}{hierarchy}
\PY{k+kn}{from} \PY{n+nn}{scipy}\PY{n+nn}{.}\PY{n+nn}{spatial}\PY{n+nn}{.}\PY{n+nn}{distance} \PY{k+kn}{import} \PY{n}{squareform}
\PY{k+kn}{from} \PY{n+nn}{collections} \PY{k+kn}{import} \PY{n}{defaultdict}
\end{Verbatim}
\end{tcolorbox}

    \begin{tcolorbox}[breakable, size=fbox, boxrule=1pt, pad at break*=1mm,colback=cellbackground, colframe=cellborder]
\prompt{In}{incolor}{113}{\boxspacing}
\begin{Verbatim}[commandchars=\\\{\}]
\PY{o}{\PYZpc{}\PYZpc{}time}

\PY{n}{fig}\PY{p}{,} \PY{p}{(}\PY{n}{ax1}\PY{p}{,} \PY{n}{ax2}\PY{p}{)} \PY{o}{=} \PY{n}{plt}\PY{o}{.}\PY{n}{subplots}\PY{p}{(}\PY{l+m+mi}{1}\PY{p}{,} \PY{l+m+mi}{2}\PY{p}{,} \PY{n}{figsize}\PY{o}{=}\PY{p}{(}\PY{l+m+mi}{24}\PY{p}{,} \PY{l+m+mi}{16}\PY{p}{)}\PY{p}{)}
\PY{n}{corr} \PY{o}{=} \PY{n}{spearmanr}\PY{p}{(}\PY{n}{X\PYZus{}cb\PYZus{}val}\PY{p}{)}\PY{o}{.}\PY{n}{correlation}

\PY{n}{corr} \PY{o}{=} \PY{p}{(}\PY{n}{corr} \PY{o}{+} \PY{n}{corr}\PY{o}{.}\PY{n}{T}\PY{p}{)} \PY{o}{/} \PY{l+m+mi}{2}
\PY{n}{np}\PY{o}{.}\PY{n}{fill\PYZus{}diagonal}\PY{p}{(}\PY{n}{corr}\PY{p}{,} \PY{l+m+mi}{1}\PY{p}{)}

\PY{c+c1}{\PYZsh{} We convert the correlation matrix to a distance matrix before performing}
\PY{c+c1}{\PYZsh{} hierarchical clustering using Ward\PYZsq{}s linkage.}
\PY{n}{distance\PYZus{}matrix} \PY{o}{=} \PY{l+m+mi}{1} \PY{o}{\PYZhy{}} \PY{n}{np}\PY{o}{.}\PY{n}{abs}\PY{p}{(}\PY{n}{corr}\PY{p}{)}
\PY{n}{dist\PYZus{}linkage} \PY{o}{=} \PY{n}{hierarchy}\PY{o}{.}\PY{n}{ward}\PY{p}{(}\PY{n}{squareform}\PY{p}{(}\PY{n}{distance\PYZus{}matrix}\PY{p}{)}\PY{p}{)}
\PY{n}{dendro} \PY{o}{=} \PY{n}{hierarchy}\PY{o}{.}\PY{n}{dendrogram}\PY{p}{(}
    \PY{n}{dist\PYZus{}linkage}\PY{p}{,} \PY{n}{labels}\PY{o}{=}\PY{n}{X\PYZus{}cb\PYZus{}val}\PY{o}{.}\PY{n}{columns}\PY{o}{.}\PY{n}{tolist}\PY{p}{(}\PY{p}{)}\PY{p}{,} \PY{n}{ax}\PY{o}{=}\PY{n}{ax1}\PY{p}{,} \PY{n}{leaf\PYZus{}rotation}\PY{o}{=}\PY{l+m+mi}{90}
\PY{p}{)}
\PY{n}{dendro\PYZus{}idx} \PY{o}{=} \PY{n}{np}\PY{o}{.}\PY{n}{arange}\PY{p}{(}\PY{l+m+mi}{0}\PY{p}{,} \PY{n+nb}{len}\PY{p}{(}\PY{n}{dendro}\PY{p}{[}\PY{l+s+s2}{\PYZdq{}}\PY{l+s+s2}{ivl}\PY{l+s+s2}{\PYZdq{}}\PY{p}{]}\PY{p}{)}\PY{p}{)}

\PY{n}{ax2}\PY{o}{.}\PY{n}{imshow}\PY{p}{(}\PY{n}{corr}\PY{p}{[}\PY{n}{dendro}\PY{p}{[}\PY{l+s+s2}{\PYZdq{}}\PY{l+s+s2}{leaves}\PY{l+s+s2}{\PYZdq{}}\PY{p}{]}\PY{p}{,} \PY{p}{:}\PY{p}{]}\PY{p}{[}\PY{p}{:}\PY{p}{,} \PY{n}{dendro}\PY{p}{[}\PY{l+s+s2}{\PYZdq{}}\PY{l+s+s2}{leaves}\PY{l+s+s2}{\PYZdq{}}\PY{p}{]}\PY{p}{]}\PY{p}{)}
\PY{n}{ax2}\PY{o}{.}\PY{n}{set\PYZus{}xticks}\PY{p}{(}\PY{n}{dendro\PYZus{}idx}\PY{p}{)}
\PY{n}{ax2}\PY{o}{.}\PY{n}{set\PYZus{}yticks}\PY{p}{(}\PY{n}{dendro\PYZus{}idx}\PY{p}{)}
\PY{n}{ax2}\PY{o}{.}\PY{n}{set\PYZus{}xticklabels}\PY{p}{(}\PY{n}{dendro}\PY{p}{[}\PY{l+s+s2}{\PYZdq{}}\PY{l+s+s2}{ivl}\PY{l+s+s2}{\PYZdq{}}\PY{p}{]}\PY{p}{,} \PY{n}{rotation}\PY{o}{=}\PY{l+s+s2}{\PYZdq{}}\PY{l+s+s2}{vertical}\PY{l+s+s2}{\PYZdq{}}\PY{p}{)}
\PY{n}{ax2}\PY{o}{.}\PY{n}{set\PYZus{}yticklabels}\PY{p}{(}\PY{n}{dendro}\PY{p}{[}\PY{l+s+s2}{\PYZdq{}}\PY{l+s+s2}{ivl}\PY{l+s+s2}{\PYZdq{}}\PY{p}{]}\PY{p}{)}
\PY{n}{fig}\PY{o}{.}\PY{n}{tight\PYZus{}layout}\PY{p}{(}\PY{p}{)}
\PY{n}{plt}\PY{o}{.}\PY{n}{show}\PY{p}{(}\PY{p}{)}
\end{Verbatim}
\end{tcolorbox}

    \begin{center}
    \adjustimage{max size={0.9\linewidth}{0.9\paperheight}}{output_142_0.png}
    \end{center}
    { \hspace*{\fill} \\}
    
    \begin{Verbatim}[commandchars=\\\{\}]
CPU times: total: 9min 26s
Wall time: 9min 30s
    \end{Verbatim}

    \begin{tcolorbox}[breakable, size=fbox, boxrule=1pt, pad at break*=1mm,colback=cellbackground, colframe=cellborder]
\prompt{In}{incolor}{114}{\boxspacing}
\begin{Verbatim}[commandchars=\\\{\}]
\PY{n}{cluster\PYZus{}ids} \PY{o}{=} \PY{n}{hierarchy}\PY{o}{.}\PY{n}{fcluster}\PY{p}{(}\PY{n}{dist\PYZus{}linkage}\PY{p}{,} \PY{l+m+mf}{0.0005}\PY{p}{,} \PY{n}{criterion}\PY{o}{=}\PY{l+s+s2}{\PYZdq{}}\PY{l+s+s2}{distance}\PY{l+s+s2}{\PYZdq{}}\PY{p}{)}
\PY{n}{cluster\PYZus{}id\PYZus{}to\PYZus{}feature\PYZus{}ids} \PY{o}{=} \PY{n}{defaultdict}\PY{p}{(}\PY{n+nb}{list}\PY{p}{)}
\PY{k}{for} \PY{n}{idx}\PY{p}{,} \PY{n}{cluster\PYZus{}id} \PY{o+ow}{in} \PY{n+nb}{enumerate}\PY{p}{(}\PY{n}{cluster\PYZus{}ids}\PY{p}{)}\PY{p}{:}
    \PY{n}{cluster\PYZus{}id\PYZus{}to\PYZus{}feature\PYZus{}ids}\PY{p}{[}\PY{n}{cluster\PYZus{}id}\PY{p}{]}\PY{o}{.}\PY{n}{append}\PY{p}{(}\PY{n}{idx}\PY{p}{)}
\PY{n}{selected\PYZus{}features} \PY{o}{=} \PY{p}{[}\PY{n}{v}\PY{p}{[}\PY{l+m+mi}{0}\PY{p}{]} \PY{k}{for} \PY{n}{v} \PY{o+ow}{in} \PY{n}{cluster\PYZus{}id\PYZus{}to\PYZus{}feature\PYZus{}ids}\PY{o}{.}\PY{n}{values}\PY{p}{(}\PY{p}{)}\PY{p}{]}
\end{Verbatim}
\end{tcolorbox}

    \begin{tcolorbox}[breakable, size=fbox, boxrule=1pt, pad at break*=1mm,colback=cellbackground, colframe=cellborder]
\prompt{In}{incolor}{115}{\boxspacing}
\begin{Verbatim}[commandchars=\\\{\}]
\PY{n}{X\PYZus{}train\PYZus{}sel} \PY{o}{=} \PY{n}{X\PYZus{}cb}\PY{o}{.}\PY{n}{iloc}\PY{p}{[}\PY{p}{:}\PY{p}{,}\PY{n}{selected\PYZus{}features}\PY{p}{]}
\PY{n}{X\PYZus{}val\PYZus{}sel} \PY{o}{=} \PY{n}{X\PYZus{}cb\PYZus{}val}\PY{o}{.}\PY{n}{iloc}\PY{p}{[}\PY{p}{:}\PY{p}{,}\PY{n}{selected\PYZus{}features}\PY{p}{]}
\end{Verbatim}
\end{tcolorbox}

    {[}0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22,
25, 26, 27, 28, 29, 30, 31, 32, 33, 34, 35, 36, 38, 39, 42, 43, 44, 45,
46, 47, 48, 49, 51, 52, 53, 54, 55, 56, 57, 58, 59, 60, 61, 62, 64, 66,
68, 69, 70, 71, 75, 76, 78, 79, 80, 83, 84, 85, 86, 87, 89, 90, 91,
92{]}

    \begin{tcolorbox}[breakable, size=fbox, boxrule=1pt, pad at break*=1mm,colback=cellbackground, colframe=cellborder]
\prompt{In}{incolor}{116}{\boxspacing}
\begin{Verbatim}[commandchars=\\\{\}]
\PY{n+nb}{len}\PY{p}{(}\PY{n}{selected\PYZus{}features}\PY{p}{)}
\end{Verbatim}
\end{tcolorbox}

            \begin{tcolorbox}[breakable, size=fbox, boxrule=.5pt, pad at break*=1mm, opacityfill=0]
\prompt{Out}{outcolor}{116}{\boxspacing}
\begin{Verbatim}[commandchars=\\\{\}]
48
\end{Verbatim}
\end{tcolorbox}
        
    \begin{tcolorbox}[breakable, size=fbox, boxrule=1pt, pad at break*=1mm,colback=cellbackground, colframe=cellborder]
\prompt{In}{incolor}{121}{\boxspacing}
\begin{Verbatim}[commandchars=\\\{\}]
\PY{o}{\PYZpc{}\PYZpc{}time}
\PY{n}{backup}\PY{o}{=}\PY{p}{[}\PY{p}{]}
\PY{k}{for} \PY{n}{c} \PY{o+ow}{in} \PY{n}{X\PYZus{}train\PYZus{}sel}\PY{o}{.}\PY{n}{columns}\PY{p}{:}
    \PY{k}{if} \PY{n}{c} \PY{o+ow}{in} \PY{n}{cat\PYZus{}vars}\PY{p}{:}
        \PY{n}{backup}\PY{o}{.}\PY{n}{append}\PY{p}{(}\PY{n}{c}\PY{p}{)}
\PY{n}{best\PYZus{}params} \PY{o}{=} \PY{p}{\PYZob{}}
    \PY{l+s+s1}{\PYZsq{}}\PY{l+s+s1}{learning\PYZus{}rate}\PY{l+s+s1}{\PYZsq{}}\PY{p}{:} \PY{l+m+mf}{0.03}\PY{p}{,}
    \PY{l+s+s1}{\PYZsq{}}\PY{l+s+s1}{l2\PYZus{}leaf\PYZus{}reg}\PY{l+s+s1}{\PYZsq{}}\PY{p}{:} \PY{l+m+mi}{3}\PY{p}{,}
    \PY{l+s+s1}{\PYZsq{}}\PY{l+s+s1}{depth}\PY{l+s+s1}{\PYZsq{}}\PY{p}{:} \PY{l+m+mi}{6}\PY{p}{,}
    \PY{l+s+s1}{\PYZsq{}}\PY{l+s+s1}{n\PYZus{}estimators}\PY{l+s+s1}{\PYZsq{}}\PY{p}{:} \PY{l+m+mi}{900}\PY{p}{,}
    \PY{l+s+s1}{\PYZsq{}}\PY{l+s+s1}{random\PYZus{}state}\PY{l+s+s1}{\PYZsq{}}\PY{p}{:} \PY{l+m+mi}{42}\PY{p}{,}
    \PY{l+s+s1}{\PYZsq{}}\PY{l+s+s1}{eval\PYZus{}metric}\PY{l+s+s1}{\PYZsq{}}\PY{p}{:} \PY{l+s+s2}{\PYZdq{}}\PY{l+s+s2}{MAE}\PY{l+s+s2}{\PYZdq{}}\PY{p}{,}
    \PY{l+s+s1}{\PYZsq{}}\PY{l+s+s1}{loss\PYZus{}function}\PY{l+s+s1}{\PYZsq{}}\PY{p}{:} \PY{l+s+s1}{\PYZsq{}}\PY{l+s+s1}{MAE}\PY{l+s+s1}{\PYZsq{}}\PY{p}{,}
\PY{p}{\PYZcb{}}
\PY{n}{fit\PYZus{}params}\PY{o}{=}\PY{p}{\PYZob{}}
    \PY{l+s+s1}{\PYZsq{}}\PY{l+s+s1}{cat\PYZus{}features}\PY{l+s+s1}{\PYZsq{}}\PY{p}{:} \PY{n}{backup}\PY{p}{,}
    \PY{l+s+s1}{\PYZsq{}}\PY{l+s+s1}{verbose}\PY{l+s+s1}{\PYZsq{}}\PY{p}{:} \PY{k+kc}{False}\PY{p}{,}
\PY{p}{\PYZcb{}}
\PY{n}{cb\PYZus{}base\PYZus{}sel} \PY{o}{=} \PY{n}{cb}\PY{o}{.}\PY{n}{CatBoostRegressor}\PY{p}{(}\PY{o}{*}\PY{o}{*}\PY{n}{best\PYZus{}params}\PY{p}{)}
\PY{n}{cb\PYZus{}base\PYZus{}sel}\PY{o}{.}\PY{n}{fit}\PY{p}{(}\PY{n}{X\PYZus{}train\PYZus{}sel}\PY{p}{,} \PY{n}{y\PYZus{}train}\PY{p}{,} \PY{o}{*}\PY{o}{*}\PY{n}{fit\PYZus{}params}\PY{p}{)}
\end{Verbatim}
\end{tcolorbox}

    \begin{Verbatim}[commandchars=\\\{\}]
CPU times: total: 18min 33s
Wall time: 3min 29s
    \end{Verbatim}

            \begin{tcolorbox}[breakable, size=fbox, boxrule=.5pt, pad at break*=1mm, opacityfill=0]
\prompt{Out}{outcolor}{121}{\boxspacing}
\begin{Verbatim}[commandchars=\\\{\}]
<catboost.core.CatBoostRegressor at 0x23c9a1fb100>
\end{Verbatim}
\end{tcolorbox}
        
    \begin{tcolorbox}[breakable, size=fbox, boxrule=1pt, pad at break*=1mm,colback=cellbackground, colframe=cellborder]
\prompt{In}{incolor}{122}{\boxspacing}
\begin{Verbatim}[commandchars=\\\{\}]
\PY{n}{get\PYZus{}eval\PYZus{}metrics}\PY{p}{(}\PY{p}{[}\PY{n}{cb\PYZus{}base\PYZus{}sel}\PY{p}{]}\PY{p}{,}\PY{n}{X\PYZus{}val\PYZus{}sel}\PY{p}{,}\PY{n}{y\PYZus{}val}\PY{p}{)}
\end{Verbatim}
\end{tcolorbox}

    \begin{Verbatim}[commandchars=\\\{\}]
Model: <catboost.core.CatBoostRegressor object at 0x0000023C9A1FB100>
MAE: 0.04925634001434666, RMSE: 0.07530299212821574
    \end{Verbatim}

            \begin{tcolorbox}[breakable, size=fbox, boxrule=.5pt, pad at break*=1mm, opacityfill=0]
\prompt{Out}{outcolor}{122}{\boxspacing}
\begin{Verbatim}[commandchars=\\\{\}]
0.04925634001434666
\end{Verbatim}
\end{tcolorbox}
        
    \hypertarget{local-feature-importance}{%
\subsection{3. Local Feature
Importance}\label{local-feature-importance}}

Can we trust the model's prediction for one specific data point?

Local importance tries to help explain how different feature might be
interaction and how the model makes a \textbf{specific} prediction. We
will be highlighting two different tools to help with this:

\begin{enumerate}
\def\labelenumi{\arabic{enumi}.}
\tightlist
\item
  \textbf{ICE (Individual Conditional Expectation) Plots}: Excellent
  tool to understand ``what the model is thinking''.
\item
  \textbf{SHAP}: Motivated by ``Shapley Value'' in Game Theory, this
  aims to explain why a particular instance is ``different'' from
  average and which features contribute to the \emph{specific}
  prediction.
\end{enumerate}

    \hypertarget{ice-plots}{%
\subsection{4. ICE Plots}\label{ice-plots}}

Individual Conditional Expectation (ICE) plots display one line per
instance that shows how the instance's prediction changes when a feature
changes. The values for a line can be computed by keeping all other
features the same, creating variants of this instance by replacing the
feature's value with values from a grid and making predictions with the
black box model for these newly created instances. The result is a set
of points for an instance with the feature value from the grid and the
respective predictions.

How do ICE plots work? - Take an actual data point and see what the
model predicts. - Pick a variable and change the value of that variable
(over some range of values). - Plot the model prediction as a function
of the ``altered'' value - Do this for multiple points, and plot on the
same graph - Do this for all variables of interest

    \begin{tcolorbox}[breakable, size=fbox, boxrule=1pt, pad at break*=1mm,colback=cellbackground, colframe=cellborder]
\prompt{In}{incolor}{123}{\boxspacing}
\begin{Verbatim}[commandchars=\\\{\}]
\PY{k+kn}{import} \PY{n+nn}{ml\PYZus{}insights} \PY{k}{as} \PY{n+nn}{mli}
\end{Verbatim}
\end{tcolorbox}

    \begin{tcolorbox}[breakable, size=fbox, boxrule=1pt, pad at break*=1mm,colback=cellbackground, colframe=cellborder]
\prompt{In}{incolor}{124}{\boxspacing}
\begin{Verbatim}[commandchars=\\\{\}]
\PY{n}{range\PYZus{}pts} \PY{o}{=} \PY{n}{mli}\PY{o}{.}\PY{n}{get\PYZus{}range\PYZus{}dict}\PY{p}{(}\PY{n}{X\PYZus{}cb}\PY{p}{)}
\PY{n}{test\PYZus{}pts} \PY{o}{=} \PY{n}{X\PYZus{}cb\PYZus{}val}\PY{o}{.}\PY{n}{sample}\PY{p}{(}\PY{l+m+mi}{5}\PY{p}{,} \PY{n}{random\PYZus{}state}\PY{o}{=}\PY{l+m+mi}{42}\PY{p}{)}
\PY{n}{imp\PYZus{}num\PYZus{}feat} \PY{o}{=} \PY{p}{[}
    \PY{l+s+s1}{\PYZsq{}}\PY{l+s+s1}{calculatedfinishedsquarefeet}\PY{l+s+s1}{\PYZsq{}}\PY{p}{,} \PY{l+s+s1}{\PYZsq{}}\PY{l+s+s1}{house\PYZus{}age}\PY{l+s+s1}{\PYZsq{}}\PY{p}{,}
    \PY{l+s+s1}{\PYZsq{}}\PY{l+s+s1}{taxamount}\PY{l+s+s1}{\PYZsq{}}\PY{p}{,} \PY{l+s+s1}{\PYZsq{}}\PY{l+s+s1}{structuretaxvaluedollarcnt}\PY{l+s+s1}{\PYZsq{}}\PY{p}{,} \PY{l+s+s1}{\PYZsq{}}\PY{l+s+s1}{latitude}\PY{l+s+s1}{\PYZsq{}} 
\PY{p}{]}
\end{Verbatim}
\end{tcolorbox}

    The ranges of values used for x-axis need to be updated to remove
outliers to better interpret the ICE-plot.

    \begin{tcolorbox}[breakable, size=fbox, boxrule=1pt, pad at break*=1mm,colback=cellbackground, colframe=cellborder]
\prompt{In}{incolor}{125}{\boxspacing}
\begin{Verbatim}[commandchars=\\\{\}]
\PY{c+c1}{\PYZsh{} Updating the ranges of features on x\PYZhy{}axis for better interpretation }
\PY{n}{range\PYZus{}pts}\PY{p}{[}\PY{l+s+s1}{\PYZsq{}}\PY{l+s+s1}{calculatedfinishedsquarefeet}\PY{l+s+s1}{\PYZsq{}}\PY{p}{]} \PY{o}{=} \PY{n}{np}\PY{o}{.}\PY{n}{linspace}\PY{p}{(}\PY{l+m+mi}{0}\PY{p}{,} \PY{l+m+mi}{6000}\PY{p}{,} \PY{l+m+mi}{200}\PY{p}{)}
\PY{n}{range\PYZus{}pts}\PY{p}{[}\PY{l+s+s1}{\PYZsq{}}\PY{l+s+s1}{house\PYZus{}age}\PY{l+s+s1}{\PYZsq{}}\PY{p}{]} \PY{o}{=} \PY{n}{np}\PY{o}{.}\PY{n}{linspace}\PY{p}{(}\PY{l+m+mi}{0}\PY{p}{,} \PY{l+m+mi}{130}\PY{p}{,} \PY{l+m+mi}{65}\PY{p}{)}
\PY{n}{range\PYZus{}pts}\PY{p}{[}\PY{l+s+s1}{\PYZsq{}}\PY{l+s+s1}{taxamount}\PY{l+s+s1}{\PYZsq{}}\PY{p}{]} \PY{o}{=} \PY{n}{np}\PY{o}{.}\PY{n}{linspace}\PY{p}{(}\PY{l+m+mi}{0}\PY{p}{,} \PY{l+m+mi}{25000}\PY{p}{,} \PY{l+m+mi}{200}\PY{p}{)}
\PY{n}{range\PYZus{}pts}\PY{p}{[}\PY{l+s+s1}{\PYZsq{}}\PY{l+s+s1}{structuretaxvaluedollarcnt}\PY{l+s+s1}{\PYZsq{}}\PY{p}{]} \PY{o}{=} \PY{n}{np}\PY{o}{.}\PY{n}{linspace}\PY{p}{(}\PY{l+m+mi}{0}\PY{p}{,} \PY{l+m+mi}{300000}\PY{p}{,} \PY{l+m+mi}{200}\PY{p}{)}
\PY{n}{range\PYZus{}pts}\PY{p}{[}\PY{l+s+s1}{\PYZsq{}}\PY{l+s+s1}{latitude}\PY{l+s+s1}{\PYZsq{}}\PY{p}{]} \PY{o}{=} \PY{n}{np}\PY{o}{.}\PY{n}{linspace}\PY{p}{(}\PY{l+m+mf}{3.35e+07}\PY{p}{,} \PY{l+m+mf}{3.46e+07}\PY{p}{,} \PY{l+m+mi}{200}\PY{p}{)}

\PY{n}{mli}\PY{o}{.}\PY{n}{ice\PYZus{}plot}\PY{p}{(}\PY{n}{cb\PYZus{}base}\PY{p}{,} \PY{n}{test\PYZus{}pts}\PY{p}{,} \PY{n}{imp\PYZus{}num\PYZus{}feat}\PY{p}{,} \PY{n}{range\PYZus{}pts}\PY{o}{=}\PY{n}{range\PYZus{}pts}\PY{p}{,} \PY{n}{pred\PYZus{}fn}\PY{o}{=}\PY{l+s+s1}{\PYZsq{}}\PY{l+s+s1}{predict}\PY{l+s+s1}{\PYZsq{}}\PY{p}{,} \PY{n}{figsize}\PY{o}{=}\PY{p}{(}\PY{l+m+mi}{15}\PY{p}{,}\PY{l+m+mi}{10}\PY{p}{)}\PY{p}{)}
\end{Verbatim}
\end{tcolorbox}

    \begin{center}
    \adjustimage{max size={0.9\linewidth}{0.9\paperheight}}{output_154_0.png}
    \end{center}
    { \hspace*{\fill} \\}
    
    \hypertarget{interpreting-ice-plots}{%
\subsubsection{Interpreting ICE plots}\label{interpreting-ice-plots}}

Things to look for: - When the line is flat, that means the variable is
unimportant in that range (for that particular data point) - When the
line is steep, that means the variable has a strong effect on the target
in that range. - If the line is very wiggly, this often betrays some
degree of ``overfitting'' in the model. Interestingly, this is often
\emph{not} reflected in the test set metrics. However, it is reflective
of the ``coherence'' of the model. It also may reflect a paucity of
training data in that region - If all the lines show the same basic
effect, this suggests that there is little interaction. - If some lines
have very different trajectories, this indicates a high degree of
interactivity.

ICE-plots tell us what the \emph{model} thinks. To the extent that the
model is reflective of the ``real world'' that generated the data, it
may be useful in understanding the real world. However, it may also be
demonstrating places where the model is wrong, has little data, or is
displaying artifacts of the way it was trained. This is where our
``human'' thinking can be combined with the model to try and understand
the world better.

    \hypertarget{shap-explaining-individual-predictions}{%
\subsection{5. SHAP: Explaining Individual
Predictions}\label{shap-explaining-individual-predictions}}

Goal of SHAP values is to: - Explain why a particular instance is
``different'' from average. - Which features / concepts contributed most
to its ``distinctiveness''? - Can we attribute the ``distance from
average'' of a particular case to the individual features?

Reference:
https://www.aidancooper.co.uk/a-non-technical-guide-to-interpreting-shap-analyses/

    \begin{tcolorbox}[breakable, size=fbox, boxrule=1pt, pad at break*=1mm,colback=cellbackground, colframe=cellborder]
\prompt{In}{incolor}{126}{\boxspacing}
\begin{Verbatim}[commandchars=\\\{\}]
\PY{c+c1}{\PYZsh{} !pip install shap \PYZsh{}if you don\PYZsq{}t have it installed}
\PY{k+kn}{import} \PY{n+nn}{shap}
\PY{n}{shap}\PY{o}{.}\PY{n}{initjs}\PY{p}{(}\PY{p}{)}
\end{Verbatim}
\end{tcolorbox}

    
    \begin{Verbatim}[commandchars=\\\{\}]
<IPython.core.display.HTML object>
    \end{Verbatim}

    
    \begin{tcolorbox}[breakable, size=fbox, boxrule=1pt, pad at break*=1mm,colback=cellbackground, colframe=cellborder]
\prompt{In}{incolor}{127}{\boxspacing}
\begin{Verbatim}[commandchars=\\\{\}]
\PY{o}{\PYZpc{}\PYZpc{}time}
\PY{n}{explainer} \PY{o}{=} \PY{n}{shap}\PY{o}{.}\PY{n}{TreeExplainer}\PY{p}{(}\PY{n}{cb\PYZus{}base}\PY{p}{)}
\PY{n}{shap\PYZus{}values} \PY{o}{=} \PY{n}{explainer}\PY{p}{(}\PY{n}{X\PYZus{}cb}\PY{p}{)}

\PY{c+c1}{\PYZsh{} The SHAP expected value is the median of the target variable }
\PY{n}{explainer}\PY{o}{.}\PY{n}{expected\PYZus{}value}\PY{p}{,} \PY{n}{np}\PY{o}{.}\PY{n}{mean}\PY{p}{(}\PY{n}{y\PYZus{}train}\PY{p}{)}
\end{Verbatim}
\end{tcolorbox}

    \begin{Verbatim}[commandchars=\\\{\}]
CPU times: total: 50.3 s
Wall time: 21.6 s
    \end{Verbatim}

            \begin{tcolorbox}[breakable, size=fbox, boxrule=.5pt, pad at break*=1mm, opacityfill=0]
\prompt{Out}{outcolor}{127}{\boxspacing}
\begin{Verbatim}[commandchars=\\\{\}]
(0.006088839177530406, 0.007901119285659874)
\end{Verbatim}
\end{tcolorbox}
        
    \hypertarget{shap-for-global-interpretability}{%
\subsubsection{SHAP for Global
Interpretability}\label{shap-for-global-interpretability}}

Thanks to its versatility, SHAP values can also be used to get a sense
of how ``globally'' important a feature is by aggregating the (absolute
value of) the local feature values. These numbers can be thought of as
the ``average absolute impact'' that a variable has on the prediction.

    \begin{tcolorbox}[breakable, size=fbox, boxrule=1pt, pad at break*=1mm,colback=cellbackground, colframe=cellborder]
\prompt{In}{incolor}{128}{\boxspacing}
\begin{Verbatim}[commandchars=\\\{\}]
\PY{n}{shap}\PY{o}{.}\PY{n}{plots}\PY{o}{.}\PY{n}{bar}\PY{p}{(}\PY{n}{shap\PYZus{}values}\PY{p}{,} \PY{n}{max\PYZus{}display}\PY{o}{=}\PY{l+m+mi}{20}\PY{p}{)}
\end{Verbatim}
\end{tcolorbox}

    \begin{center}
    \adjustimage{max size={0.9\linewidth}{0.9\paperheight}}{output_160_0.png}
    \end{center}
    { \hspace*{\fill} \\}
    
    The bar plot of the absolute SHAP values paints an interesting and
\emph{slightly} different picture than the
\texttt{feature\_importances\_} function earlier which said
\texttt{house\_age} was one of the most important feature. However,
according to the SHAP bar plot above, there are many other variables
that contribute greater to the final predicted value on average.

Furthermore, \texttt{rawcensustractandblock} and \texttt{poolcnt} are
within top 7 contributors according to SHAP values compared to not even
being in top 15 according to \texttt{feature\_importance\_}. This can be
a clue to further dig into these variables' impact and analyze whether
their affects are postively or negatively affecting the model.

    \hypertarget{waterfall-plots}{%
\subsubsection{Waterfall Plots}\label{waterfall-plots}}

SHAP explains how individual predictions are arrived at in terms of the
contributions from each of the model's input variables. This is a highly
intuitive approach that produces simple but informative outputs.

Waterfall plots the most complete display of a single prediction. The
waterfall structure emphasizes the additive nature of positive and
negative contributors, and how they build on the \emph{base value} to
yield the model's prediction, \(f(x)\)

Target feature values are extremely tiny (mean of 0.006), so the
contributions shown in most charts below will be zero due to rounding.
However, the positive and negative contributions can still be seen based
on colors in below charts.

    \begin{tcolorbox}[breakable, size=fbox, boxrule=1pt, pad at break*=1mm,colback=cellbackground, colframe=cellborder]
\prompt{In}{incolor}{129}{\boxspacing}
\begin{Verbatim}[commandchars=\\\{\}]
\PY{n}{i\PYZus{}med} \PY{o}{=} \PY{n}{np}\PY{o}{.}\PY{n}{argsort}\PY{p}{(}\PY{n}{y\PYZus{}train}\PY{p}{)}\PY{p}{[}\PY{n+nb}{len}\PY{p}{(}\PY{n}{y\PYZus{}train}\PY{p}{)}\PY{o}{/}\PY{o}{/}\PY{l+m+mi}{2}\PY{p}{]}    
\PY{n}{i\PYZus{}80} \PY{o}{=} \PY{n}{np}\PY{o}{.}\PY{n}{argsort}\PY{p}{(}\PY{n}{y\PYZus{}train}\PY{p}{)}\PY{p}{[}\PY{n+nb}{int}\PY{p}{(}\PY{n+nb}{len}\PY{p}{(}\PY{n}{y\PYZus{}train}\PY{p}{)}\PY{o}{*}\PY{l+m+mf}{0.80}\PY{p}{)}\PY{p}{]}  
\PY{n}{i\PYZus{}20} \PY{o}{=} \PY{n}{np}\PY{o}{.}\PY{n}{argsort}\PY{p}{(}\PY{n}{y\PYZus{}train}\PY{p}{)}\PY{p}{[}\PY{n+nb}{int}\PY{p}{(}\PY{n+nb}{len}\PY{p}{(}\PY{n}{y\PYZus{}train}\PY{p}{)}\PY{o}{*}\PY{l+m+mf}{0.20}\PY{p}{)}\PY{p}{]}  

\PY{n}{shap}\PY{o}{.}\PY{n}{plots}\PY{o}{.}\PY{n}{waterfall}\PY{p}{(}\PY{n}{shap\PYZus{}values}\PY{p}{[}\PY{n}{i\PYZus{}20}\PY{p}{]}\PY{p}{,} \PY{n}{max\PYZus{}display}\PY{o}{=}\PY{l+m+mi}{20}\PY{p}{)}
\end{Verbatim}
\end{tcolorbox}

    \begin{center}
    \adjustimage{max size={0.9\linewidth}{0.9\paperheight}}{output_163_0.png}
    \end{center}
    { \hspace*{\fill} \\}
    
    Waterfall plot display that \texttt{finishedsquarefeet12} and
\texttt{transaction\_month} are very important in this specific
prediction.

    \hypertarget{force-plots}{%
\subsubsection{Force Plots}\label{force-plots}}

Force plots are equivalent representations as Waterfall plots that
display the key information is a more condensed format.

    \begin{tcolorbox}[breakable, size=fbox, boxrule=1pt, pad at break*=1mm,colback=cellbackground, colframe=cellborder]
\prompt{In}{incolor}{136}{\boxspacing}
\begin{Verbatim}[commandchars=\\\{\}]
\PY{c+c1}{\PYZsh{} Force plot for 20th percentile y\PYZus{}train value}
\PY{n}{shap}\PY{o}{.}\PY{n}{plots}\PY{o}{.}\PY{n}{force}\PY{p}{(}\PY{n}{shap\PYZus{}values}\PY{p}{[}\PY{n}{i\PYZus{}20}\PY{p}{]}\PY{p}{)}
\end{Verbatim}
\end{tcolorbox}

            \begin{tcolorbox}[breakable, size=fbox, boxrule=.5pt, pad at break*=1mm, opacityfill=0]
\prompt{Out}{outcolor}{136}{\boxspacing}
\begin{Verbatim}[commandchars=\\\{\}]
<shap.plots.\_force.AdditiveForceVisualizer at 0x23c928f4fa0>
\end{Verbatim}
\end{tcolorbox}
        
    \begin{tcolorbox}[breakable, size=fbox, boxrule=1pt, pad at break*=1mm,colback=cellbackground, colframe=cellborder]
\prompt{In}{incolor}{131}{\boxspacing}
\begin{Verbatim}[commandchars=\\\{\}]
\PY{c+c1}{\PYZsh{} Force plot for 80th percentile y\PYZus{}train value}
\PY{n}{shap}\PY{o}{.}\PY{n}{plots}\PY{o}{.}\PY{n}{force}\PY{p}{(}\PY{n}{shap\PYZus{}values}\PY{p}{[}\PY{n}{i\PYZus{}80}\PY{p}{]}\PY{p}{)}
\end{Verbatim}
\end{tcolorbox}

            \begin{tcolorbox}[breakable, size=fbox, boxrule=.5pt, pad at break*=1mm, opacityfill=0]
\prompt{Out}{outcolor}{131}{\boxspacing}
\begin{Verbatim}[commandchars=\\\{\}]
<shap.plots.\_force.AdditiveForceVisualizer at 0x23cf88c9100>
\end{Verbatim}
\end{tcolorbox}
        
    The above explanation shows features each contributing to push the model
output from the base value (the average model output over the training
dataset we passed) to the model output. Features pushing the prediction
higher are shown in red, those pushing the prediction lower are in blue.

If we take many explanations such as the one shown above, rotate them 90
degrees, and then stack them horizontally, we can see explanations for
an entire dataset:

    \begin{tcolorbox}[breakable, size=fbox, boxrule=1pt, pad at break*=1mm,colback=cellbackground, colframe=cellborder]
\prompt{In}{incolor}{132}{\boxspacing}
\begin{Verbatim}[commandchars=\\\{\}]
\PY{n}{shap\PYZus{}values\PYZus{}expl} \PY{o}{=} \PY{n}{explainer}\PY{o}{.}\PY{n}{shap\PYZus{}values}\PY{p}{(}\PY{n}{X\PYZus{}cb}\PY{p}{)}
\end{Verbatim}
\end{tcolorbox}

    \begin{tcolorbox}[breakable, size=fbox, boxrule=1pt, pad at break*=1mm,colback=cellbackground, colframe=cellborder]
\prompt{In}{incolor}{133}{\boxspacing}
\begin{Verbatim}[commandchars=\\\{\}]
\PY{n}{n\PYZus{}samples} \PY{o}{=} \PY{l+m+mi}{10}
\PY{n}{shap}\PY{o}{.}\PY{n}{force\PYZus{}plot}\PY{p}{(}\PY{n}{explainer}\PY{o}{.}\PY{n}{expected\PYZus{}value}\PY{p}{,} \PY{n}{shap\PYZus{}values\PYZus{}expl}\PY{p}{[}\PY{l+m+mi}{0}\PY{p}{:}\PY{n}{n\PYZus{}samples}\PY{p}{]}\PY{p}{,} \PY{n}{X\PYZus{}cb}\PY{p}{[}\PY{l+m+mi}{0}\PY{p}{:}\PY{n}{n\PYZus{}samples}\PY{p}{]}\PY{p}{)}
\end{Verbatim}
\end{tcolorbox}

            \begin{tcolorbox}[breakable, size=fbox, boxrule=.5pt, pad at break*=1mm, opacityfill=0]
\prompt{Out}{outcolor}{133}{\boxspacing}
\begin{Verbatim}[commandchars=\\\{\}]
<shap.plots.\_force.AdditiveForceArrayVisualizer at 0x23cfa24b9d0>
\end{Verbatim}
\end{tcolorbox}
        
    To understand how a single feature effects the output of the model we
can plot the SHAP value of that feature vs.~the value of the feature for
all the examples in a dataset. Since SHAP values represent a feature's
responsibility for a change in the model output, the plot below
represents the change in predicted Zestimate error as `taxamount'
changes. Vertical dispersion at a single value of `taxamount' represents
interaction effects with other features. To help reveal these
interactions dependence\_plot automatically selects another feature for
coloring. In this case coloring by `taxvaluedollarcnt' highlights that
`taxamount' has less impact on home price for areas close to radial
highways.

    \begin{tcolorbox}[breakable, size=fbox, boxrule=1pt, pad at break*=1mm,colback=cellbackground, colframe=cellborder]
\prompt{In}{incolor}{134}{\boxspacing}
\begin{Verbatim}[commandchars=\\\{\}]
\PY{c+c1}{\PYZsh{} create a SHAP dependence plot to show the effect of a single feature across the whole dataset}
\PY{n}{shap}\PY{o}{.}\PY{n}{dependence\PYZus{}plot}\PY{p}{(}\PY{l+s+s2}{\PYZdq{}}\PY{l+s+s2}{taxamount}\PY{l+s+s2}{\PYZdq{}}\PY{p}{,} \PY{n}{shap\PYZus{}values\PYZus{}expl}\PY{p}{,} \PY{n}{X\PYZus{}cb}\PY{p}{,}\PY{n}{interaction\PYZus{}index}\PY{o}{=}\PY{l+s+s2}{\PYZdq{}}\PY{l+s+s2}{basementsqft}\PY{l+s+s2}{\PYZdq{}}\PY{p}{)} 
\end{Verbatim}
\end{tcolorbox}

    \begin{center}
    \adjustimage{max size={0.9\linewidth}{0.9\paperheight}}{output_172_0.png}
    \end{center}
    { \hspace*{\fill} \\}
    
    \begin{tcolorbox}[breakable, size=fbox, boxrule=1pt, pad at break*=1mm,colback=cellbackground, colframe=cellborder]
\prompt{In}{incolor}{135}{\boxspacing}
\begin{Verbatim}[commandchars=\\\{\}]
\PY{c+c1}{\PYZsh{} summarize the effects of all the features}
\PY{n}{shap}\PY{o}{.}\PY{n}{summary\PYZus{}plot}\PY{p}{(}\PY{n}{shap\PYZus{}values}\PY{p}{,} \PY{n}{X\PYZus{}cb}\PY{p}{)}
\end{Verbatim}
\end{tcolorbox}

    \begin{center}
    \adjustimage{max size={0.9\linewidth}{0.9\paperheight}}{output_173_0.png}
    \end{center}
    { \hspace*{\fill} \\}
    
    In the SHAP plot, the features are ranked based on their average
absolute SHAP and the colors represent the feature value (red high, blue
low and grey NaN). The higher the SHAP value, the larger the predictor's
attribution. In other words, the SHAP values represent a predictor's
responsibility for a change in the model output. This reveals for
example that larger `taxamount' are associated with increasing of
decreasing of error and viceversa.

    \hypertarget{future-work}{%
\section{FUTURE WORK:}\label{future-work}}

\begin{itemize}
\tightlist
\item
  MetaLearner
\item
  More investigation about explainability
\end{itemize}

    \begin{tcolorbox}[breakable, size=fbox, boxrule=1pt, pad at break*=1mm,colback=cellbackground, colframe=cellborder]
\prompt{In}{incolor}{ }{\boxspacing}
\begin{Verbatim}[commandchars=\\\{\}]

\end{Verbatim}
\end{tcolorbox}


    % Add a bibliography block to the postdoc
    
    
    
\end{document}
